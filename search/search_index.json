{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>     This site serves as a repo for my personal notes. The contents reflect neither community standards nor third-party rules. These notes are disorganized, spontaneously auto-generated, and relevant only to some rare contexts, making them meaningless for most others.          It wouldn't be abnormal if you find nothing valuable here, as these notes were not purposed for general readers. You might prefer to enjoy Felix's excellent work below or navigate your attention elsewhere.           If you need to discuss something else, leave your messages here.   </p> <p> </p> <p> </p>"},{"location":"#_1","title":"Home","text":""},{"location":"codedocs/","title":"Code Docs","text":"<p>Thatool documentation</p> <p>mediaLib documentation</p>"},{"location":"contact/","title":"contact","text":"Name:  Email:  Subject: Message: To help avoid spam, utilize a Honeypot technique with a hidden text field; must be empty to submit the form! Otherwise, we assume the user is a spam bot. <p>* Correct your email to receive the feedback.</p> Sending ... Your message has been sent.  Send another message"},{"location":"contact/#_1","title":"contact","text":""},{"location":"cv/","title":"CV","text":"<p>Loading...</p>"},{"location":"pubs/","title":"Publications","text":"<p>Loading...</p> <p> </p>"},{"location":"research/","title":"Publications","text":"<p>Loading...</p> <p> </p>"},{"location":"soft/","title":"Software","text":"<p>All downloadable softwares</p>"},{"location":"soft/#office-pdf","title":"Office-pdf","text":""},{"location":"soft/#foxitpdfeditor","title":"FoxitPDFEditor","text":"<p>FoxitPDF Editor Pro Portable 2023</p> <p>pass: taiwebs.com</p>"},{"location":"tv/","title":"tv","text":"Load URL News - US News - EU News - Asia Documentary Discovery Movie Sport Music Show Vietnamese Channels Local VTV - VTC"},{"location":"tv/#_1","title":"tv","text":""},{"location":"blog/","title":"Blog","text":""},{"location":"blog/2022/11/30/Deep-Potential/","title":"Accelerated Molecular Simulation Using Deep Potential Workflow with NGC","text":"<p>Credit: NVIDIA's blog</p> <p> </p> <p>Molecular simulation communities have faced the accuracy-versus-efficiency dilemma in modeling the potential energy surface and interatomic forces for decades. Deep Potential, the artificial neural network force field, solves this problem by combining the speed of classical molecular dynamics (MD) simulation with the accuracy of density functional theory (DFT) calculation.1 This is achieved by using the GPU-optimized package DeePMD-kit, which is a deep learning package for many-body potential energy representation and MD simulation.2</p> <p>This post provides an end-to-end demonstration of training a neural network potential for the 2D material graphene and using it to drive MD simulation in the open-source platform Large-scale Atomic/Molecular Massively Parallel Simulator (LAMMPS).3 Training data can be obtained either from the Vienna Ab initio Simulation Package (VASP)4, or Quantum ESPRESSO (QE).5</p> <p>A seamless integration of molecular modeling, machine learning, and high-performance computing (HPC) is demonstrated with the combined efficiency of molecular dynamics with ab initio accuracy \u2014 that is entirely driven through a container-based workflow. Using AI techniques to fit the interatomic forces generated by DFT, the accessible time and size scales can be boosted several orders of magnitude with linear scaling.</p> <p>Deep potential is essentially a combination of machine learning and physical principles, which start a new computing paradigm as shown in Figure 1.</p> <p>The image shows the new computing paradigm that combines molecular modeling, machine learning and high-performance computing to understand the interatomic forces of molecules compared to the traditional methods.</p> <p> Figure 1. A new computing paradigm composed of molecular modeling, AI, and HPC. (Figure courtesy: Dr. Linfeng Zhang, DP Technology) </p> <p>The entire workflow is shown in Figure 2. The data generation step is done with VASP and QE. The data preparation, model training, testing, and compression steps are done using DeePMD-kit. The model deployment is in LAMMPS.</p> <p>This figure displays the workflow of training and deploying a deep potential model. The workflow includes data generation, data preparation, model training, model testing, model compression, and model deployment.</p> <p> Figure 2. Diagram of the DeePMD workflow. </p>"},{"location":"blog/2022/11/30/Deep-Potential/#why-containers","title":"Why Containers?","text":"<p>A container is a portable unit of software that combines the application, and all its dependencies, into a single package that is agnostic to the underlying host OS.</p> <p>The workflow in this post involves AIMD, DP training, and LAMMPS MD simulation. It is nontrivial and time-consuming to install each software package from source with the correct setup of the compiler, MPI, GPU library, and optimization flags.</p> <p>Containers solve this problem by providing a highly optimized GPU-enabled computing environment for each step, and eliminates the time to install and test software.</p> <p>The NGC catalog, a hub of GPU-optimized HPC and AI software, carries a whole of HPC and AI containers that can be readily deployed on any GPU system. The HPC and AI containers from the NGC catalog are updated frequently and are tested for reliability and performance \u2014 necessary to speed up the time to solution.</p> <p>These containers are also scanned for Common Vulnerabilities and Exposure (CVEs), ensuring that they are devoid of any open ports and malware. Additionally, the HPC containers support both Docker and Singularity runtimes, and can be deployed on multi-GPU and multinode systems running in the cloud or on-premises.</p>"},{"location":"blog/2022/11/30/Deep-Potential/#training-data-generation","title":"Training data generation","text":"<p>The first step in the simulation is data generation. We will show you how you can use VASP and Quantum ESPRESSO to run AIMD simulations and generate training datasets for DeePMD. All input files can be downloaded from the GitHub repository using the following command:</p> <pre><code>git clone https://github.com/deepmodeling/SC21_DP_Tutorial.git\n</code></pre>"},{"location":"blog/2022/11/30/Deep-Potential/#vasp","title":"VASP","text":"<p>A two-dimensional graphene system with 98-atoms is used as shown in Figure 3.6 To generate the training datasets, 0.5ps NVT AIMD simulation at 300 K is performed. The time step chosen is 0.5fs. The DP model is created using 1000 time steps from a 0.5ps MD trajectory at a fixed temperature.</p> <p>Due to the short simulation time, the training dataset contains consecutive system snapshots, which are highly correlated. Generally, the training dataset should be sampled from uncorrelated snapshots with various system conditions and configurations. For this example, we used a simplified training data scheme. For production DP training, using DP-GEN is recommended to utilize the concurrent learning scheme to efficiently explore more combinations of conditions.7</p> <p>The projector-augmented wave pseudopotentials are employed to describe the interactions between the valence electrons and frozen cores. The generalized gradient approximation exchange\u2212correlation functional of Perdew\u2212Burke\u2212Ernzerhof. Only the \u0393-point was used for k-space sampling in all systems.</p> <p>This figure displays the top view of a single layer graphene system with 98 carbon atoms.</p> <p> Figure 3. A graphene system composed of 98 carbon atoms is used in AIMD simulation. </p>"},{"location":"blog/2022/11/30/Deep-Potential/#quantum-espresso","title":"Quantum Espresso","text":"<p>The AIMD simulation can also be carried out using Quantum ESPRESSO, available as a container from the NGC Catalog. Quantum ESPRESSO is an integrated suite of open-source computer codes for electronic-structure calculations and materials modeling at the nanoscale based on density-functional theory, plane waves, and pseudopotentials. The same graphene structure is used in the QE calculations. The following command can be used to start the AIMD simulation:</p> <pre><code>$ singularity exec --nv docker://nvcr.io/hpc/quantum_espresso:qe-6.8 cp.x\n&lt; c.md98.cp.in\n</code></pre>"},{"location":"blog/2022/11/30/Deep-Potential/#training-data-preparation","title":"Training data preparation","text":"<p>Once the training data is obtained from AIMD simulation, we want to convert its format using dpdata so that it can be used as input to the deep neural network. The dpdata package is a format conversion toolkit between AIMD, classical MD, and DeePMD-kit.</p> <p>You can use the convenient tool dpdata to convert data directly from the output of first-principles packages to the DeePMD-kit format. For deep potential training, the following information of a physical system has to be provided: atom type, box boundary, coordinate, force, viral, and system energy.</p> <p>A snapshot, or a frame of the system, contains all these data points for all atoms at one-time step, which can be stored in two formats, that is raw and npy.</p> <p>The first format raw is plain text with all information in one file, and each line of the file represents a snapshot. Different system information is stored in different files named as box.raw, coord.raw, force.raw, energy.raw, and virial.raw. We recommended you follow these naming conventions when preparing the training files.</p> <p>An example of force.raw:</p> <pre><code>$ cat force.raw\n-0.724  2.039 -0.951  0.841 -0.464  0.363\n 6.737  1.554 -5.587 -2.803  0.062  2.222\n-1.968 -0.163  1.020 -0.225 -0.789  0.343\n</code></pre> <p>This force.raw contains three frames, with each frame having the forces of two atoms, resulting in three lines and six columns. Each line provides all three force components of two atoms in one frame. The first three numbers are the three force components of the first atom, while the next three numbers are the force components of the second atom.</p> <p>The coordinate file coord.raw is organized similarly. In box.raw, the nine components of the box vectors should be provided on each line. In virial.raw, the nine components of the virial tensor should be provided on each line in the order XX XY XZ YX YY YZ ZX ZY ZZ. The number of lines of all raw files should be identical. We assume that the atom types do not change in all frames. It is provided by type.raw, which has one line with the types of atoms written one by one.</p> <p>The atom types should be integers. For example, the type.raw of a system that has two atoms with zero and one:</p> <pre><code>$ cat type.raw\n0 1\n</code></pre> <p>It is not a requirement to convert the data format to raw, but this process should give a sense on the types of data that can be used as inputs to DeePMD-kit for training.</p> <p>The easiest way to convert the first-principles results to the training data is to save them as numpy binary data.</p> <p>For VASP output, we have prepared an outcartodata.py script to process the VASP OUTCAR file. By running the commands:</p> <pre><code>$ cd SC21_DP_Tutorial/AIMD/VASP/\n$ singularity exec --nv docker://nvcr.io/hpc/deepmd-kit:v2.0.3 python outcartodata.py\n$ mv deepmd_data ../../DP/\n</code></pre> <p>For QE output:</p> <pre><code>$ cd SC21_DP_Tutorial/AIMD/QE/\n$ singularity exec --nv docker://nvcr.io/hpc/deepmd-kit:v2.0.3 python logtodata.py\n$ mv deepmd_data ../../DP/\n</code></pre> <p>A folder called deepmd_data is generated and moved to the training directory. It generates five sets 0/set.000, 1/set.000, 2/set.000, 3/set.000, 4/set.000, with each set containing 200 frames. It is not required to take care of the binary data files in each of the set.* directories. The path containing the set.* folder and type.raw file is called a system. If you want to train a nonperiodic system, an empty nopbc file should be placed under the system directory. box.raw is not necessary as it is a nonperiodic system.</p> <p>We are going to use three of the five sets for training, one for validating, and the remaining one for testing.</p>"},{"location":"blog/2022/11/30/Deep-Potential/#deep-potential-model-training","title":"Deep Potential model training","text":"<p>The input of the deep potential model is a descriptor vector containing the system information mentioned previously. The neural network contains several hidden layers with a composition of linear and nonlinear transformations. In this post, a three layer-neural network with 25, 50 and 100 neurons in each layer is used. The target value, or the label, for the neural network to learn is the atomic energies. The training process optimizes the weights and the bias vectors by minimizing the loss function.</p> <p>The training is initiated by the command where input.json contains the training parameters:</p> <pre><code>$ singularity exec --nv docker://nvcr.io/hpc/deepmd-kit:v2.0.3 dp train input.json\n</code></pre> <p>The DeePMD-kit prints detailed information on the training and validation data sets. The data sets are determined by training_data and validation_data as defined in the training section of the input script. The training dataset is composed of three data systems, while the validation data set is composed of one data system. The number of atoms, batch size, number of batches in the system, and the probability of using the system are all shown in Figure 4. The last column presents if the periodic boundary condition is assumed for the system.</p> <p>This image is a screenshot of the DP training output. Summaries of the training and validation dataset are shown with detailed information on the number of atoms, batch size, number of batches in the system and the probability of using the system.</p> <p> Figure 4. Screenshot of the DP training output. </p> <p>During the training, the error of the model is tested every disp_freq training step with the batch used to train the model and with numb_btch batches from the validating data. The training error and validation error are printed correspondingly in the file disp_file (default is lcurve.out). The batch size can be set in the input script by the key batch_size in the corresponding sections for training and validation data set.</p> <p>An example of the output:</p> <pre><code>#  step      rmse_val    rmse_trn    rmse_e_val  rmse_e_trn    rmse_f_val  rmse_f_trn         lr\n      0      3.33e+01    3.41e+01      1.03e+01    1.03e+01      8.39e-01    8.72e-01    1.0e-03\n    100      2.57e+01    2.56e+01      1.87e+00    1.88e+00      8.03e-01    8.02e-01    1.0e-03\n    200      2.45e+01    2.56e+01      2.26e-01    2.21e-01      7.73e-01    8.10e-01    1.0e-03\n    300      1.62e+01    1.66e+01      5.01e-02    4.46e-02      5.11e-01    5.26e-01    1.0e-03\n    400      1.36e+01    1.32e+01      1.07e-02    2.07e-03      4.29e-01    4.19e-01    1.0e-03\n    500      1.07e+01    1.05e+01      2.45e-03    4.11e-03      3.38e-01    3.31e-01    1.0e-03\n</code></pre> <p>The training error reduces monotonically with training steps as shown in Figure 5. The trained model is tested on the test dataset and compared with the AIMD simulation results. The test command is:</p> <pre><code>$ singularity exec --nv docker://nvcr.io/hpc/deepmd-kit:v2.0.3 dp test -m frozen_model.pb -s deepmd_data/4/ -n 200 -d detail.out\n</code></pre> <p>This image shows the total training loss, energy loss, force loss and learning rate decay with training steps from 0 to 1,000,000. Both the training and validation loss decrease monotonically with training steps.</p> <p> Figure 5. Training loss with steps </p> <p>The results are shown in Figure 6.</p> <p>This image displays the inferenced energy and force in the y-axis, and the ground true on the x-axis. The inferenced values soundly coincide with the ground truth with all data distributed in the diagonal direction.</p> <p> Figure 6. Test of the prediction accuracy of trained DP model with AIMD energies and forces. </p>"},{"location":"blog/2022/11/30/Deep-Potential/#model-export-and-compression","title":"Model export and compression","text":"<p>After the model has been trained, a frozen model is generated for inference in MD simulation. The process of saving neural network from a checkpoint is called \u201cfreezing\u201d a model:</p> <pre><code>$ singularity exec --nv docker://nvcr.io/hpc/deepmd-kit:v2.0.3 dp freeze -o graphene.pb\n</code></pre> <p>After the frozen model is generated, the model can be compressed without sacrificing its accuracy; while greatly speeding up the inference performance in MD. Depending on simulation and training setup, model compression can boost performance by 10X, and reduce memory consumption by 20X when running on GPUs.</p> <p>The frozen model can be compressed using the following command where -i refers to the frozen model and -o points to the output name of the compressed model:</p> <pre><code>$ singularity exec --nv docker://nvcr.io/hpc/deepmd-kit:v2.0.3 dp compress -i graphene.pb -o graphene-compress.pb\n</code></pre>"},{"location":"blog/2022/11/30/Deep-Potential/#model-deployment-in-lammps","title":"Model deployment in LAMMPS","text":"<p>A new pair-style has been implemented in LAMMPS to deploy the trained neural network in prior steps. For users familiar with the LAMMPS workflow, only minimal changes are needed to switch to deep potential. For instance, a traditional LAMMPS input with Tersoff potential has the following setting for potential setup:</p> <pre><code>pair_style      tersoff\npair_coeff      * * BNC.tersoff C\n</code></pre> <p>To use deep potential, replace previous lines with:</p> <pre><code>pair_style      deepmd graphene-compress.pb\npair_coeff      * *\n</code></pre> <p>The pair_style command in the input file uses the DeePMD model to describe the atomic interactions in the graphene system.</p> <p>The graphene-compress.pb file represents the frozen and compressed model for inference. The graphene system in MD simulation contains 1,560 atoms. Periodic boundary conditions are applied in the lateral x\u2013 and y-directions, and free boundary is applied to the z-direction. The time step is set as 1 fs. The system is placed under NVT ensemble at temperature 300 K for relaxation, which is consistent with the AIMD setup. The system configuration after NVT relaxation is shown in Figure 7. It can be observed that the deep potential can describe the atomic structures with small ripples in the cross-plane direction. After 10ps NVT relaxation, the system is placed under NVE ensemble to check system stability.</p> <p>The image displays the side view of the single layer graphene system after thermal relaxation in LAMMPS.</p> <p> Figure 7.  Atomic configuration of the graphene system after relaxation with deep potential. </p> <p>The system temperature is shown in Figure 8.</p> <p>The image displays the temperature profiles of the graphene system under NVT and NVE ensembles from 0 to 20 picoseconds. The first 10 picosecond is NVT and the second 10 picosecond is NVE.</p> <p> Figure 8. System temperature under NVT and NVE ensembles. The MD system driven by deep potential is very stable after relaxation. </p> <p>To validate the accuracy of the trained DP model, the calculated radial distribution function (RDF) from AIMD, DP and Tersoff, are plotted in Figure 9. The DP model-generated RDF is very close to that of AIMD, which indicates that the crystalline structure of graphene can be well presented by the DP model.</p> <p>This image displays the plotted radial distribution function from three different methods, including DP, Tersoff and AIMD, which are denoted in black, red and blue solid lines respectively.</p> <p> Figure 9. Radial distribution function calculated by AIMD, DP and Tersoff potential, respectively. It can be observed that the RDF calculated by DP is very close to that of AIMD. </p>"},{"location":"blog/2022/11/30/Deep-Potential/#conclusion","title":"Conclusion","text":"<p>This post demonstrates a simple case study of graphene under given conditions. The DeePMD-kit package streamlines the workflow from AIMD to classical MD with deep potential, providing the following key advantages:</p> <p>Highly automatic and efficient workflow implemented in the TensorFlow framework. APIs with popular DFT and MD packages such as VASP, QE, and LAMMPS. Broad applications in organic molecules, metals, semiconductors, insulators, and more. Highly efficient code for HPC with MPI and GPU support. Modularization for easy adoption by other deep learning potential models. Furthermore, the use of GPU-optimized containers from the NGC catalog simplifies and accelerates the overall workflow by eliminating the steps to install and configure software. To train a comprehensive model for other applications, download the DeepMD Kit Container from the NGC catalog.</p>"},{"location":"blog/2022/11/30/Deep-Potential/#references","title":"References","text":"<p>[1] Jia W, Wang H, Chen M, Lu D, Lin L, Car R, E W and Zhang L 2020 Pushing the limit of molecular dynamics with ab initio accuracy to 100 million atoms with machine learning IEEE Press 5 1-14</p> <p>[2] Wang H, Zhang L, Han J and E W 2018 DeePMD-kit: A deep learning package for many-body potential energy representation and molecular dynamics Computer Physics Communications 228 178-84</p> <p>[3] Plimpton S 1995 Fast Parallel Algorithms for Short-Range Molecular Dynamics Journal of Computational Physics 117 1-19</p> <p>[4] Kresse G and Hafner J 1993 Ab initio molecular dynamics for liquid metals Physical Review B 47 558-61</p> <p>[5] Giannozzi P, Baroni S, Bonini N, Calandra M, Car R, Cavazzoni C, Ceresoli D, Chiarotti G L, Cococcioni M, Dabo I, Dal Corso A, de Gironcoli S, Fabris S, Fratesi G, Gebauer R, Gerstmann U, Gougoussis C, Kokalj A, Lazzeri M, Martin-Samos L, Marzari N, Mauri F, Mazzarello R, Paolini S, Pasquarello A, Paulatto L, Sbraccia C, Scandolo S, Sclauzero G, Seitsonen A P, Smogunov A, Umari P and Wentzcovitch R M 2009 QUANTUM ESPRESSO: a modular and open-source software project for quantum simulations of materials Journal of Physics: Condensed Matter 21 395502</p> <p>[6] Humphrey W, Dalke A and Schulten K 1996 VMD: Visual molecular dynamics Journal of Molecular Graphics 14 33-8</p> <p>[7] Yuzhi Zhang, Haidi Wang, Weijie Chen, Jinzhe Zeng, Linfeng Zhang, Han Wang, and Weinan E, DP-GEN: A concurrent learning platform for the generation of reliable deep learning based potential energy models, Computer Physics Communications, 2020, 107206.</p>"},{"location":"blog/2024/01/25/bibtex_generator/","title":"BibTeX Generator","text":"<p>Have you ever found yourself weary and uninspired from the tedious task of manually creating BibTeX entries for your paper?</p> <p>There are, indeed, support tools and plugins that are bundled with reference managers such as Zotero, Mendeley, etc. These tools can automate the generation of a <code>.bib</code> file. To use them, you need to install a reference manager, its associated plugins, and a library of papers on your computer. However, these tools are not flawless. The BibTeX entries they generate often contain incomplete information, are poorly formatted, and include numerous unnecessary fields. You then still need to manually check and correct the entries.</p> <p>There are the times you just need to cite a paper or two, and you don't want to go through the hassle of the aforementioned complex process. In such situations, a simple tool that allows you to quickly copy and paste a BibTeX entry into your <code>.bib</code> file would be ideal. Think of such a simple tool, I have looked around the Chrome extension store to see if there is any that can pick up the Bibtex while you are browsing the paper. I found some, but they do not really work.</p> <p>Therefore, I decided to create my own tool to address this dilemma. I developed a Chrome extension that can generate the BibTeX entry for any browsing URL with just one click. I named it the 1click BibTeX. It delivers exactly what it is expected and has proven to be quite helpful. This extension, along with the Latex tools, will ensure that the manuscript's citations are properly formatted before they are delivered to the journal.</p>"},{"location":"blog/2024/01/25/bibtex_generator/#usage","title":"Usage","text":"<p>Install the 1click BibTeX extension on your Chrome browser. Then, whenever you're browsing a paper or any URL, just click on the extension icon, and the BibTeX entry will be instantly generated and copied to your clipboard. The remaining thing is just paste it to your <code>.bib</code> file.</p> <p> </p> <p>I've tested the extension on numerous publishers and websites with varying structures and it works consistently as it was designed. The tested publishers include Elsevier, Wiley, ACS, IOP, AIP, APS, arXiv,...</p> <p>Below are some examples of BibTeX entries generated by the extension 1click BibTeX:</p> <ul> <li>Article on Elsevier: 10.1016/j.commatsci.2018.10.023</li> </ul> <pre><code>@article{nguyen2019pattern,\n    title = {Pattern transformation induced by elastic instability of metallic porous structures},\n    author = {Cao Thang Nguyen and Duc Tam Ho and Seung Tae Choi and Doo-Man Chun and Sung Youb Kim },\n    year = {2019},\n    month = {2},\n    journal = {Computational Materials Science},\n    publisher = {Elsevier},\n    volume = {157},\n    pages = {17-24},\n    doi = {10.1016/j.commatsci.2018.10.023},\n    url = {https://www.sciencedirect.com/science/article/abs/pii/S0927025618306955?via%3Dihub},\n    accessDate = {Jan 25, 2024}\n}\n</code></pre> <ul> <li>Article on Wiley: 10.1002/adts.202300538</li> </ul> <pre><code>@article{nguyen2024an,\n    title = {An Enhanced Sampling Approach for Computing the Free Energy of Solid Surface and Solid\u2013Liquid Interface},\n    author = {Cao Thang Nguyen and Duc Tam Ho and Sung Youb Kim},\n    year = {2024},\n    month = {1},\n    journal = {Advanced Theory and Simulations},\n    publisher = {John Wiley &amp; Sons, Ltd},\n    volume = {7},\n    number = {1},\n    pages = {2300538},\n    doi = {10.1002/adts.202300538},\n    url = {https://onlinelibrary.wiley.com/doi/10.1002/adts.202300538},\n    accessDate = {Jan 25, 2024}\n}\n</code></pre> <ul> <li>Google Book New: America, the Vietnam War, and the World</li> </ul> <pre><code>@book{daum2003america,,\n    title = {America, the Vietnam War, and the World},\n    author = {Andreas W. Daum and Lloyd C. Gardner and Wilfried Mausbach},\n    year = {2003},\n    month = {7},\n    publisher = {Cambridge University Press},\n    isbn = {052100876X},\n    url = {https://www.google.co.kr/books/edition/America_the_Vietnam_War_and_the_World/9kn6qYwsGs4C?hl=en&amp;gbpv=0},\n    accessDate = {Jan 25, 2024}\n}\n</code></pre> <ul> <li>Google Book Classic: Currency Wars</li> </ul> <pre><code>@book{rickards2011currency,\n    title = {Currency Wars},\n    author = {James Rickards},\n    year = {2011},\n    month = {11},\n    publisher = {Penguin},\n    isbn = {110155889X},\n    url = {https://books.google.co.kr/books?id=-GDwL2s5sJoC&amp;source=gbs_book_other_versions},\n    accessDate = {Jan 25, 2024}\n}\n</code></pre> <ul> <li>Blog post: https://deci.ai/blog/decicoder-6b-the-best-multi-language-code-generation-llm-in-its-class/</li> </ul> <pre><code>@misc{deci2024introducing,\n    title = {Introducing DeciCoder-6B: The Best Multi-Language Code LLM in Its Class},\n    author = {Deci},\n    year = {2024},\n    month = {1},\n    publisher = {Deci},\n    url = {https://deci.ai/blog/decicoder-6b-the-best-multi-language-code-generation-llm-in-its-class/},\n    accessDate = {Jan 25, 2024}\n}\n</code></pre> <ul> <li>Packages on Zenodo: https://zenodo.org/records/7751762</li> </ul> <pre><code>@misc{kai2023forcefield,\n    title = {Force-field files for \"Noble gas (He, Ne and Ar) solubilities in high-pressure silicate melts calculated based on deep potential modeling\"},\n    author = {Wang, Kai and Lu, Xiancai and Liu, Xiandong and Yin, Kun},\n    year = {2023},\n    month = {3},\n    publisher = {Zenodo},\n    doi = {10.5281/zenodo.7751762},\n    url = {https://zenodo.org/records/7751762},\n    accessDate = {Jan 25, 2024}\n}\n</code></pre> <ul> <li>Bibtex this page</li> </ul> <pre><code>@misc{nguyen2024bibtex,\n    title = {BibTeX Generator},\n    author = {Cao Thang Nguyen},\n    year = {2024},\n    month = {1},\n    url = {https://thang.eu.org/blog/2024/01/25/bibtex_generator},\n    accessDate = {Jan 25, 2024}\n}\n</code></pre> <p>In summary, the new extension 1click BibTeX works well for most websites with varying data structures.</p>"},{"location":"cluster/","title":"cluster","text":""},{"location":"cluster/compile/","title":"Index","text":""},{"location":"cluster/compile/BLACS/","title":"BLACS","text":""},{"location":"cluster/compile/BLACS/#blacs-fail","title":"BLACS (fail)","text":"<p>https://thelinuxcluster.com/2011/03/27/compiling-blacs-on-centos-5/</p> <pre><code>cd /home1/p001cao/0SourceCode/tooldev\n# wget --no-check-certificate https://www.netlib.org/blacs/mpiblacs.tgz\n# wget --no-check-certificate https://www.netlib.org/blacs/mpiblacs-patch03.tgz\ntar -xvf mpiblacs.tgz\ntar -xvf mpiblacs-patch03.tgz\ncd BLACS\ncp ./BMAKES/Bmake.MPI-LINUX Bmake.inc\n</code></pre> <pre><code>module load mpi/ompi4.1.x-gcc9\n</code></pre> <ol> <li>Edit file <code>Bmake.in</code> see this</li> </ol> <pre><code>#=============================================================================\n#====================== SECTION 1: PATHS AND LIBRARIES =======================\n#=============================================================================\nBTOPdir = /home1/p001cao/0SourceCode/tooldev/BLACS\n#  -------------------------------------\n#  Name and location of the MPI library.\n#  -------------------------------------\n   MPIdir = /home1/p001cao/app/openmpi/4.1.x-gcc9\n   MPILIBdir =\n   MPIINCdir = $(MPIdir)/include\n   MPILIB =\n\n#=============================================================================\n#========================= SECTION 2: BLACS INTERNALS ========================\n#=============================================================================\n   SYSINC =\n   INTFACE = -Df77IsF2C\n   SENDIS =\n   BUFF =\n   TRANSCOMM = -DUseMpi2\n   WHATMPI =\n   SYSERRORS =\n\n#=============================================================================\n#=========================== SECTION 3: COMPILERS ============================\n#=============================================================================\n   F77            = $(MPIdir)/mpif77\n   CC             = $(MPIdir)/mpicc\n</code></pre> <ol> <li> <p>Edit <code>TESTING/Makefile</code> <pre><code>blacstest.o : blacstest.f\n    $(F77) $(F77NO_OPTFLAGS) -c $*.f\n</code></pre> to: <pre><code>blacstest.o : blacstest.f\n    $(F77) $(F77NO_OPTFLAGS) -fno-globals -fno-f90 -fugly-complex -w -c $*.f\n</code></pre></p> </li> <li> <p>Compile the Blacs tests <pre><code>cd TESTING\nmake clean &amp;&amp; make\n</code></pre> You should see <code>xCbtest_MPI-LINUX-1</code> and <code>xFbtest_MPI-LINUX-1</code></p> </li> </ol> <p>May error</p>"},{"location":"cluster/compile/CMake/","title":"CMake","text":"<ul> <li>need C++ compiler to install CMAKE, so need to load C++ compiler before install</li> <li>Source code repo: https://github.com/Kitware/CMake</li> <li>or download CMake from: https://cmake.org/download</li> </ul> <pre><code>cd /home1/p001cao/0SourceCode/tooldev\nwget https://cmake.org/files/v3.27/cmake-3.27.0.tar.gz\ntar zxvf cmake-3.27.0.tar.gz\ncd cmake-3.27.0\n</code></pre>"},{"location":"cluster/compile/CMake/#usc-1-eagle","title":"USC 1 (Eagle)","text":"<pre><code>module load compiler/gcc-10.3\n\n./configure --prefix=/uhome/p001cao/app/tooldev/cmake-3.27\n\nmake -j 20 &amp;&amp; make install\n</code></pre>"},{"location":"cluster/compile/CMake/#usc-2-tacheon","title":"USC 2 (Tacheon)","text":"<pre><code>cd /home1/p001cao/0SourceCode/tooldev\ntar zxvf cmake-3.27.0.tar.gz\ncd cmake-3.27.0\n\n# export PATH=/home1/p001cao/app/compiler/gcc-13/bin:$PATH\nmodule load compiler/gcc-13\n\n./configure --prefix=/home1/p001cao/app/tooldev/cmake-3.27\n\nmake -j 16 &amp;&amp; make install\n</code></pre>"},{"location":"cluster/compile/CMake/#create-module-file","title":"create module file","text":"<p>cd /uhome/p001cao/local/Imodfiles  \u2192  create file \"cmake-3.27\"</p> <pre><code># for Tcl script use only\nset         topdir              /uhome/p001cao/app/tooldev/cmake-3.27\n\nsetenv          cmake           $topdir\nprepend-path    PATH            $topdir/bin\nprepend-path    INCLUDE           $topdir/share/cmake-3.27/include\n</code></pre> <p>Validate installation: <pre><code>module load cmake-3.27\ncmake --version\n</code></pre></p> <p>Ref: - https://pachterlab.github.io/kallisto/local_build.html - https://github.com/Kitware/CMake</p>"},{"location":"cluster/compile/CP2K/","title":"CP2K","text":"<p>CP2K is a quantum chemistry and solid state physics software package that can perform atomistic simulations of solid state, liquid, molecular, periodic, material, crystal, and biological systems. CP2K provides a general framework for different modeling methods such as DFT using the mixed Gaussian and plane waves approaches GPW and GAPW. Supported theory levels include DFTB, LDA, GGA, MP2, RPA, semi-empirical methods (AM1, PM3, PM6, RM1, MNDO, \u2026), and classical force fields (AMBER, CHARMM, \u2026). CP2K can do simulations of molecular dynamics, metadynamics, Monte Carlo, Ehrenfest dynamics, vibrational analysis, core level spectroscopy, energy minimization, and transition state optimization using NEB or dimer method.</p> <p>\\</p>"},{"location":"cluster/compile/CP2K/#compile-cp2k","title":"Compile CP2K","text":""},{"location":"cluster/compile/CP2K/#usc2_tachyon-centos-69","title":"USC2_Tachyon - Centos 6.9","text":"Note <p>Error not found package <code>DBCSR</code> (lack of file <code>findDBCSR.cmake</code>)</p> See also <p>Build cp2k with cmake</p> <pre><code>cd /home1/p001cao/local/wSourceCode\ngit clone --recursive -b support/v2023.1 https://github.com/cp2k/cp2k.git cp2k-2023\ncd cp2k-2023\n# git pull origin master\nmkdir build_LLVM &amp;&amp; cd build_LLVM\n</code></pre> <pre><code>module load tooldev/cmake-3.24\nmodule load tooldev/binutils-2.37\nmodule load tooldev/gsl-2.7\nmodule load mpi/ompi4.1.x-clang14\nmodule load fftw/fftw3.3.10-ompi4.1.4-clang14\nmodule load tooldev/ScaLAPACK-2.2\n\nexport myCOMPILER=/home1/p001cao/local/app/openmpi/4.1.x-clang14\nexport PATH=${myCOMPILER}/bin:$PATH\nexport CC=mpicc  export CXX=mpic++  export FC=mpifort\nexport myLAPACK=/home1/p001cao/local/app/tooldev/ScaLAPACK-2.2/lib/libscalapack.a\nexport myPREFIX=/home1/p001cao/local/app/cp2k/llvmOMPI4-cp2k-2023\n\ncmake ../ -DCP2K_SCALAPACK_LINK_LIBRARIES=${myLAPACK} \\\n -DCP2K_USE_LIBXSMM=OFF -DCP2K_USE_DBCSR=OFF \\\n -DCMAKE_INSTALL_PREFIX=${myPREFIX}\n</code></pre> <pre><code>make -j 16 &amp;&amp; make install\n</code></pre>"},{"location":"cluster/compile/Dependencies/","title":"Some Dependencies","text":""},{"location":"cluster/compile/Dependencies/#lapack-blas","title":"LAPACK &amp; BLAS","text":"<p>Two of the most commonly used computational libraries are LAPACK and BLAS.  They are super fast in doing linear algebra operations involving matrices and vectors.</p> <ul> <li>BLAS (Basic Linear Algebra Subprograms) are routines that provide standard building blocks for performing basic vector and matrix operations.</li> <li>LAPACK (Linear Algebra PACKage) is written in Fortran 90 and provides routines for solving systems of simultaneous linear equations, least-squares solutions of linear systems of equations, eigenvalue problems, and singular value problems.</li> <li>BLAS is needed in LAPACK. BLAS &amp; LAPACK can be installed separately. First, you have to install BLAS before LAPACK, because LAPACK needs it. Download the packages from the following websites. (see here and here)</li> <li>BLAS, see [http://www.netlib.org/blas/]</li> <li>LAPACK, see [http://www.netlib.org/lapack/]</li> <li>Or can install LAPACK by cmake, where soureCode LAPACK also includes BLAS</li> </ul>"},{"location":"cluster/compile/Dependencies/#install-lapack-with-cmake","title":"install LAPACK with cmake","text":"<ul> <li>see CMAKE options in file CMakeLists.txt,</li> <li>This way also install BLAS, CBLAS, LAPACKE, set <code>-DCBLAS=on -DLAPACKE=on</code></li> </ul> <pre><code>tar -xvf lapack-3.10.0.tar.gz\ncd lapack-3.10.0\nmkdir build &amp;&amp; cd build\n</code></pre> <pre><code>module load tool_dev/cmake-3.21\nmodule load compiler/gcc-11.2\nexport PATH=/uhome/p001cao/local/app/compiler/gcc-11.2/bin:$PATH\nexport CC=gcc  export CXX=g++  export FC=gfortran\nexport LD_LIBRARY_PATH=/uhome/p001cao/local/app/compiler/gcc-11.2/lib64:$LD_LIBRARY_PATH\n\nexport myInstallDIR=/uhome/p001cao/local/app/lapack-3.10\n\ncmake .. -DCBLAS=on -DLAPACKE=on \\\n-DCMAKE_INSTALL_LIBDIR=${myInstallDIR} \\\n-DCMAKE_INSTALL_INCLUDEDIR=${myInstallDIR}\n\nmake -j 8\nmake install\n</code></pre>"},{"location":"cluster/compile/Dependencies/#usage","title":"usage","text":"<pre><code>export myLAPACK=/uhome/p001cao/local/app/lapack-3.10/liblapack.a\nexport myLAPACKE=/uhome/p001cao/local/app/lapack-3.10/liblapacke.a\nexport myBLAS=/uhome/p001cao/local/app/lapack-3.10/libblas.a\nexport myCBLAS=/uhome/p001cao/local/app/lapack-3.10/libcblas.a\n</code></pre>"},{"location":"cluster/compile/Dependencies/#scalapack","title":"ScaLAPACK","text":"<p>ScaLAPACK (Scalable LAPACK) is a library of high-performance linear algebra routines for parallel distributed memory machines. ScaLAPACK can be used as a replacement for both LAPACK and BLAS</p> <ul> <li>Installing ScaLAPACK needs BLAS, LAPACK and BLACS libraries. (BLACS now included inside ScaLAPACK)</li> <li>ScaLAPACK now only supports MPI.</li> <li>Installation docs of ScaLAPACK here</li> <li>Some guide here</li> <li>SouceCode</li> <li>see CMAKE options in file CMakeLists.txt</li> </ul> Note <p>ScaLAPACK just be compiled by MPI compilers</p>"},{"location":"cluster/compile/Dependencies/#download","title":"Download","text":"<pre><code>cd /home1/p001cao/local/wSourceCode/tooldev\ngit clone -b tags/v2.2.1 https://github.com/Reference-ScaLAPACK/scalapack.git ScaLAPACK-2.2.1\ncd ScaLAPACK-2.2.1\nmkdir build &amp;&amp; cd build\n</code></pre> <ul> <li>Or download release</li> </ul> <pre><code>tar -xvf scalapack-2.1.0.tar.gz\ncd scalapack-2.1.0\nmkdir build &amp;&amp; cd build\n</code></pre>"},{"location":"cluster/compile/Dependencies/#self-build-blas-and-lapack","title":"self-build BLAS and LAPACK","text":"<pre><code>module load tooldev/cmake-3.24\nmodule load mpi/ompi4.1.x-clang14\n\nexport PATH=/home1/p001cao/local/app/openmpi/4.1.x-clang14/bin:$PATH\nexport CC=mpicc  export CXX=mpic++  export F90=mpif90 export F77=mpif77\n</code></pre> <pre><code>cmake .. -DUSE_OPTIMIZED_LAPACK_BLAS=on \\\n-DCMAKE_C_COMPILER=mpicc -DCMAKE_Fortran_COMPILER=mpifort \\\n-DCMAKE_INSTALL_PREFIX=/home1/p001cao/local/app/tooldev/ScaLAPACK-2.2\n\nmake -j 16 &amp;&amp; make install\n</code></pre>"},{"location":"cluster/compile/Dependencies/#preinstall-blas-and-lapack","title":"preinstall BLAS and LAPACK","text":"<pre><code>export myLAPACK=/uhome/p001cao/local/app/lapack-3.10/liblapack.a\nexport myBLAS=/uhome/p001cao/local/app/lapack-3.10/libblas.a\n\ncmake .. -DBLAS_LIBRARIES=${myBLAS} -DLAPACK_LIBRARIES=${myLAPACK} \\\n-DCMAKE_C_COMPILER=mpicc -DCMAKE_Fortran_COMPILER=mpifort \\\n-DCMAKE_INSTALL_PREFIX=/home1/p001cao/local/app/tooldev/ScaLAPACK-2.2\n</code></pre> <p>Some options if errors</p> <pre><code>export CFLAGS=\"-Ofast -march=x86-64\"\nexport FFLAGS=\"-Ofast -march=x86-64 -fallow-argument-mismatch\"\nexport FFLAGS=\"-std=legacy\"\n</code></pre> <p>Module file</p> <pre><code>set     topdir          /home1/p001cao/local/app/tooldev/ScaLAPACK-2.2\n\nprepend-path    LD_LIBRARY_PATH     $topdir/lib\nprepend-path    PKG_CONFIG_PATH     $topdir/lib/pkgconfig\n</code></pre>"},{"location":"cluster/compile/Dependencies/#openblas","title":"OpenBLAS","text":"<p>OpenBLAS is an open source optimized BLAS (Basic Linear Algebra Subprograms) library based on GotoBLAS2 1.13 BSD version.</p> <ul> <li>Installation  here</li> <li>SouceCode</li> <li>see CMAKE options in file CMakeLists.txt</li> </ul> <pre><code>- to create dynamic link (file *.so), use: -DBUILD_SHARED_LIBS=yes\n</code></pre> <pre><code>git clone https://github.com/xianyi/OpenBLAS.git\ncd OpenBLAS\nmkdir build &amp;&amp; cd build\n</code></pre> <ul> <li>Or download release</li> </ul> <pre><code>tar -xvf OpenBLAS-0.3.19.tar.gz\ncd OpenBLAS-0.3.19\nmkdir build &amp;&amp; cd build\n</code></pre>"},{"location":"cluster/compile/Dependencies/#ucs-2","title":"UCS 2","text":"<pre><code>module load tool_dev/cmake-3.20.3\nmodule load mpi/ompi5.0.0-gcc11.2\n\ncmake .. -DCMAKE_INSTALL_PREFIX=/home1/p001cao/local/app/tool_dev/openBLAS-0.3.19\n\nmake -j 16 &amp;&amp; make install\n</code></pre> <pre><code>## Usage\nexport myBLAS=/home1/p001cao/local/app/tool_dev/openBLAS-0.3.19/lib64/libopenblas.a\ncmake .. -DBLAS_LIBRARIES=${myBLAS} -DLAPACK_LIBRARIES=${myBLAS} \\\n</code></pre>"},{"location":"cluster/compile/FFTW/","title":"FFTW","text":"<ul> <li>FFTW</li> <li>Download FFTW</li> <li>Compile with OMPI + GCC<ul> <li>USC1</li> <li>USC2</li> <li>CAN-GPU</li> </ul> </li> <li>4. Make module file</li> <li>Compile with OMPI + LLVM<ul> <li>USC2</li> </ul> </li> </ul>"},{"location":"cluster/compile/FFTW/#fftw","title":"FFTW","text":"<ul> <li>NOTE: To compile with mpi-enable, need to use openMPI-compiler: MPICC=mpicc</li> <li>Installation guide</li> </ul>"},{"location":"cluster/compile/FFTW/#download-fftw","title":"Download FFTW","text":"<p>Download FFTW-3.3.10</p> <pre><code>tar -xvzf fftw-3.3.10.tar.gz\ncd fftw-3.3.10\nmkdir build &amp;&amp; cd build\n</code></pre>"},{"location":"cluster/compile/FFTW/#compile-with-ompi-gcc","title":"Compile with OMPI + GCC","text":"<p>Compiling FFTW 3.3.10 (Single,Double)</p> <pre><code>--enable-sse2: Single, Double\n--enable-long-double : Long-Double Precision\n--enable-float : Single\n--enable-shared: fBIC\n</code></pre>"},{"location":"cluster/compile/FFTW/#usc1","title":"USC1","text":"<pre><code>module load mpi/ompi5.0.0-gcc11.2\nexport PATH=/uhome/p001cao/app/openmpi/5.0.0-gcc11.2-eagle/bin:$PATH\nexport CC=mpicc  export CXX=mpic++  export FORTRAN=mpifort  export F90=mpif90\n\n../configure --enable-sse2 \\\n--enable-threads --enable-openmp --enable-mpi --enable-shared \\\n--prefix=/uhome/p001cao/app/fftw/3.3.10-ompi5.0-gcc11.2\n</code></pre>"},{"location":"cluster/compile/FFTW/#can-gpu","title":"CAN-GPU","text":"<pre><code>module load mpi/ompi4.1-gcc7.4-cuda\nexport PATH=$PATH:/home/thang/app/openmpi/4.1.1-gcc7.4-cuda/bin\nexport CC=mpicc  export CXX=mpic++  export FORTRAN=mpifort  export F90=mpif90\n\n../configure --enable-sse2 \\\n--enable-threads --enable-openmp --enable-mpi \\\n--prefix=/home/thang/app/fftw/3.3.8-ompi4.1-gcc7.4\n</code></pre> <p>make -j 12 make install</p> <p>validate: Inside \"/uhome/p001cao/app/fftw/3.3.8-ompi4.1-gcc10.3/lib\" you should see at least the files below libfftw3.a libfftw3_mpi.a libfftw3_omp.a libfftw3_threads.a .... ....</p>"},{"location":"cluster/compile/FFTW/#4-make-module-file","title":"4. Make module file","text":"<p>at directory: /uhome/p001cao/local/share/lmodfiles/mpi\u2192 create file \"ompi4.1.1-gcc11.2-noUCX\"</p> <pre><code># for Tcl script use only\n# for Tcl script use only\nset     topdir          /uhome/p001cao/app/fftw/3.3.10-ompi5.0-gcc11.2\n\nprepend-path    PATH                $topdir/bin\nprepend-path    INCLUDE             $topdir/include\nprepend-path    LD_LIBRARY_PATH     $topdir/lib\nprepend-path    PKG_CONFIG_PATH     $topdir/lib/pkgconfig\n</code></pre>"},{"location":"cluster/compile/FFTW/#usc2","title":"USC2","text":""},{"location":"cluster/compile/FFTW/#with-ompi-llvm","title":"With OMPI + LLVM","text":"<pre><code>cd /home1/p001cao/0SourceCode/tooldev\n# tar -xvzf fftw-3.3.10.tar.gz\ncd fftw-3.3.10\nrm -rf build_LLVM &amp;&amp; mkdir build_LLVM &amp;&amp; cd build_LLVM\n\nmodule load mpi/ompi4.1.x-clang17\n\nexport PATH=/home1/p001cao/app/openmpi/4.1.x-clang17/bin:$PATH\nexport CC=mpicc  export CXX=mpic++  export FC=mpifort\nexport LDFLAGS=\"-fuse-ld=lld -lrt\"\nexport myPREFIX=/home1/p001cao/app/mpi/fftw3.3.10-ompi4.1.x-clang17\n\n../configure --enable-sse2 --enable-threads --enable-openmp --enable-mpi --enable-shared --prefix=${myPREFIX}\n\nmake -j 16 &amp;&amp; make install\n</code></pre>"},{"location":"cluster/compile/FFTW/#with-ompi-gcc","title":"With OMPI + GCC","text":"<pre><code>cd fftw-3.3.10\nrm -rf build_ase &amp;&amp; mkdir build_ase &amp;&amp; cd build_ase\n\nmodule load mpi/ompi4.1.5-gcc9\n\nOPENMPI=/home1/p001cao/app/openmpi/4.1.5-gcc9\nexport PATH=$OPENMPI/bin:$PATH\nexport CC=mpicc  export CXX=mpic++  export FC=mpifort  export F90=mpif90\nexport myPREFIX=/home1/p001cao/app/mpi/fftw3.3.10-ompi4.1.5-gcc9\n\n../configure --enable-sse2 --enable-threads --enable-openmp --enable-mpi --enable-shared --prefix=${myPREFIX}\n\nmake -j 16 &amp;&amp; make install\n</code></pre>"},{"location":"cluster/compile/GCC/","title":"GCC","text":"<ul> <li>Compile GCC</li> <li>GCC-11<ul> <li>1. Download:</li> <li>2. Install</li> <li>USC1: (eagle)</li> <li>USC 2</li> <li>CAN</li> <li>CAN_GPU</li> <li>3. Make module file</li> </ul> </li> <li>GCC-13<ul> <li>USC 2</li> </ul> </li> </ul>"},{"location":"cluster/compile/GCC/#compile-gcc","title":"Compile GCC","text":"<p>The GNU Compiler Collection includes front ends for C, C++, Objective-C, Fortran, Ada, Go, and D, as well as libraries for these languages (libstdc++,...).</p> <pre><code>- Some applications require C++11, this is only supported on GCC 4.8 or newer\n- [intel 2018 support gcc versions 4.3 - 6.3](https://software.intel.com/en-us/articles/intel-c-compiler-180-for-linux-release-notes-for-intel-parallel-studio-xe-2018)\n- compile GCC outside source-dir, to avoid modifying source code when compiling get fail\n- cuda does not support gcc &gt; 8\n</code></pre>"},{"location":"cluster/compile/GCC/#1-download","title":"1. Download:","text":"<ul> <li>check all availabe versions GCC</li> <li>at this link</li> <li>or check this:   <pre><code>svn ls svn://gcc.gnu.org/svn/gcc/tags | grep gcc | grep release\n#or http://ftp.tsukuba.wide.ad.jp/software/gcc/releases\n</code></pre></li> <li>download</li> <li>use this   <pre><code>wget http://ftp.tsukuba.wide.ad.jp/software/gcc/releases/gcc-10.3.0/gcc-10.3.0.tar.gz\ntar xvf gcc-10.3.0.tar.gz\n</code></pre></li> <li>or git   <pre><code>git clone -b releases/gcc-11.2.0 https://github.com/gcc-mirror/gcc gcc-11.2.0\n</code></pre></li> </ul>"},{"location":"cluster/compile/GCC/#2-install","title":"2. Install","text":"<p>Include 2 steps: - download prerequisites: <pre><code>cd gcc-11.2.0\n./contrib/download_prerequisites\n</code></pre> - Configure: see this link <pre><code>configure error: uint64_t or int64_t not found     --&gt; need at least gcc-4.5\n</code></pre></p>"},{"location":"cluster/compile/GCC/#eagle-centos-78","title":"Eagle - Centos 7.8","text":"<pre><code>git clone -b releases/gcc-11.2.0 https://github.com/gcc-mirror/gcc gcc-11.2.0\ncd gcc-11.2\ngit checkout releases/gcc-11.2\n./contrib/download_prerequisites\n\nmkdir build &amp;&amp; cd build\nmodule load compiler/gcc-10.3         # to avoid:  uint64_t or int64_t not found\n\n../configure --enable-languages=c,c++,objc,obj-c++,fortran \\\n  --enable-shared --disable-multilib --with-system-zlib \\\n  --enable-checking=release --prefix=/uhome/p001cao/app/compiler/gcc-11.2\n</code></pre> <pre><code>make  -j 20         # not use -j to know what error\nmake install\n# check: g++ -v\n</code></pre>"},{"location":"cluster/compile/GCC/#tachyon-centos-69","title":"Tachyon - Centos 6.9","text":"<pre><code>cd /home1/p001cao/0SourceCode\n# git clone -b releases/gcc-11 https://github.com/gcc-mirror/gcc  gcc-11\ncd gcc-11\n# git checkout releases/gcc-11\n./contrib/download_prerequisites\n</code></pre> <pre><code>rm -rf build &amp;&amp; mkdir build &amp;&amp; cd build\n\nmyGCC=/home2/app/compiler/gcc/9.5.0\nexport PATH=$myGCC/bin:$PATH\nexport LD_LIBRARY_PATH=$myGCC/lib64:$LD_LIBRARY_PATH\n\n../configure --enable-languages=c,c++,objc,obj-c++,fortran \\\n  --enable-gold=yes --enable-checking=release --enable-shared --disable-multilib --with-system-zlib \\\n  --prefix=/home1/p001cao/app/compiler/gcc-11\n\nmake -j 16 &amp;&amp; make install\n</code></pre>"},{"location":"cluster/compile/GCC/#can","title":"CAN","text":"<pre><code>--prefix=/home/thang/app/compiler/gcc-10.3\n</code></pre>"},{"location":"cluster/compile/GCC/#can_gpu","title":"CAN_GPU","text":"<pre><code>module load compiler/gcc-7.4   # cuda note support gcc &gt; 8\n--prefix=/home/thang/app/compiler/gcc-10.3'\n</code></pre>"},{"location":"cluster/compile/GCC/#3-make-module-file","title":"3. Make module file","text":"<p>at directory: /uhome/p001cao/local/share/lmodfiles/GCC \u2192 create file \"gcc-11.2\"</p> <pre><code>module load compiler/gcc/9.5.0\n\n# for Tcl script use only\nset             topdir          /uhome/p001cao/app/compiler/gcc-11.2\n\nsetenv           CC gcc\nsetenv           CXX g++\nsetenv           FC gfortran\nsetenv           F90 gfortran\n\nprepend-path    PATH                    $topdir/bin\nprepend-path    INCLUDE                   $topdir/include/c++/11.2.0\nprepend-path    LD_LIBRARY_PATH         $topdir/lib/gcc/x86_64-pc-linux-gnu/11.2.0\nprepend-path    LD_LIBRARY_PATH         $topdir/lib64\nprepend-path    LD_LIBRARY_PATH         $topdir/libexec/gcc/x86_64-pc-linux-gnu/11.2.0\nprepend-path    INFOPATH                $topdir/share/info\n</code></pre>"},{"location":"cluster/compile/LAMMPS/","title":"Compiling LAMMPS","text":"<p>This note intends to the struggling work to deploy LAMMPS on some Linux clusters</p> <p></p> <ul> <li>Compiling LAMMPS</li> <li>Preparation<ul> <li>1. Prerequisite</li> <li>2. Download</li> <li>3. Packages</li> </ul> </li> <li>I. Compiling with GCC + OMPI<ul> <li>USC1_Eagle - Centos 6.5 cluster with InfiniBand</li> <li>Module file</li> <li>USC2_Tachyon - Centos 6.9 cluster with InfiniBand</li> <li>use OMPI_5</li> <li>use OMPI_3</li> <li>Module file</li> <li>CAN2_GPU - Centos 7 cluster with GPU</li> <li>CAN3_GPU - Ubuntu 20 with GPU</li> </ul> </li> <li>GCC + OpenSHMEM</li> <li>Compile with openMPI4.0.1-gcc7.4.0 on CAN</li> <li>MVAPICH-GCC<ul> <li>USC2</li> </ul> </li> <li>Compile with IMPI-2019xe + MKL<ul> <li>USC1_Eagle - Centos 6.5 cluster with InfiniBand</li> </ul> </li> <li>Compiling with LLVM + OMPI<ul> <li>USC2_Tachyon - Centos 6.9 cluster with InfiniBand</li> </ul> </li> <li>Compile with Conda</li> </ul>"},{"location":"cluster/compile/LAMMPS/#preparation","title":"Preparation","text":""},{"location":"cluster/compile/LAMMPS/#1-prerequisite","title":"1. Prerequisite","text":"<ul> <li>Compiler: Intel, GCC, Clang,...</li> <li>MPI implementation: OMPI, IMPI, MPICH,...</li> <li>Libraries depend on which packages will be installed: FFTW, intel MKL,...</li> <li>Newer LAMMPS may be no longer compatible with an old openMPI, as well FFTW/MKL, so these libs need to be updated too.</li> <li>OpenMPI may the fastest</li> <li>There is no longer USER_ packages from Jul-2021</li> <li>Need CMAKE, newer is better (a newer Cmake version may reduce the probability of error during compiling). Basic cmake:</li> </ul> <pre><code>cmake -D OPTION_A=VALUE_A -D OPTION_B=VALUE_B ...     ../cmake make\n</code></pre> <ul> <li>Module environment</li> </ul> <pre><code>module load &lt;module_name&gt;\nmodule display &lt;module_name&gt;\n</code></pre> <ul> <li>Only one installation for <code>eagle/lion/leopard/cheetah</code>, but need to load different OpenMPI for each cluster. Also need to load Conda to overwrite the default python of the system (different Ver. of python may cause runtime error)</li> </ul>"},{"location":"cluster/compile/LAMMPS/#2-download","title":"2. Download","text":"<p>LAMMPS site Souce code</p> <pre><code>### download tar file\ntar -xvf lammps-stable_7Aug2019\ncd lammps-stable_7Aug2019\nmkdir build &amp;&amp; cd build\n\n### or download use Git:\ngit clone --branch patch_20Nov2019 https://github.com/lammps/lammps.git lammps_patch_20Nov2019\ncd lammps_patch_20Nov2019\ngit checkout patch_20Nov2019\n\ngit clone https://github.com/lammps/lammps.git    lammps_dev\ncd lammps_dev\ngit pull origin develop\n</code></pre>"},{"location":"cluster/compile/LAMMPS/#3-packages","title":"3. Packages","text":"<p>Note</p> <ul> <li>include these OPTIONS in Cmake command, to build package-lib automatically:</li> <li>python &gt; 3.7.12 require to update GCC-conda=11: <code>conda install -c conda-forge gcc=11 gxx=11</code>. But don't use this to void requiring higher GLIBC. Also, <code>zlib=1.2.12</code> require GLIBC=2.14.</li> <li>To void hidden libs by conda, need to downgrade libs versions in conda &lt; libs in linux system. So that to void these errors, use <code>conda install -c conda-forge libgcc-ng=7 zlib=1.2.8 python=3.7.12</code></li> <li>Do not use GCC-11 to avoid error: Dwarf Error: found dwarf version '5', use: export CFLAGS='-gdwarf-4 -gstrict-dwarf' not solve this error</li> <li>install openBLAS for LAPACK and BLAS, so need load GSL</li> <li>use static link for openBLAS, so need to export it and set cmake var</li> </ul> <p>1.UFM potential</p> <pre><code>cd lammps-folder/src/\ngit clone https://github.com/plrodolfo/FluidFreeEnergyforLAMMPS.git USER-FFE\ncopy new pair_ufm into /src\ncopy new pair_eam.cpp &amp; pair_eam.h into /src and delete corresponding files in /src/MANYBODY\n</code></pre> <p>2.POEMS, OPT</p> <pre><code>-D PKG_OPT=yes\n</code></pre> <p>3.MSCG</p> <pre><code>-D PKG_MSCG=yes -D DOWNLOAD_MSCG=yes\n</code></pre> <p>5.VORONOI</p> <pre><code>-D PKG_VORONOI=yes -D DOWNLOAD_VORO=yes\n</code></pre> <p>6.KSPACE</p> <ul> <li>if use MKL for FFT, then need MKL library</li> </ul> <pre><code>-D FFT=MKL  \\\n-D MKL_INCLUDE_DIRS=/uhome/p001cao/local/intel/xe2019/compilers_and_libraries_2019.5.281/linux/mkl/include  \\\n-D MKL_LIBRARY=/uhome/p001cao/local/intel/xe2019/compilers_and_libraries_2019.5.281/linux/mkl/lib/intel64  \\\n</code></pre> <ul> <li>if FTWW3, then dont need MKL_LIBRARY</li> </ul> <pre><code>-D FFT=FFTW3\n-D FFTW3_INCLUDE_DIRS=/uhome/p001cao/local/fftw/3.3.8-openmpi4.0.1-Intel2019xe-double/include \\\n-D FFTW3_LIBRARY=/uhome/p001cao/local/fftw/3.3.8-openmpi4.0.1-Intel2019xe-double/lib \\\n</code></pre> <ul> <li>or use FFTW3 from intel_mkl: (not support long-double precision)</li> </ul> <pre><code>-D FFT=FFTW3\n-D FFTW3_INCLUDE_DIRS=/uhome/p001cao/local/intel/xe2018/compilers_and_libraries_2018.0.128/linux/mkl/include/fftw\n</code></pre> <p>7.**LAPACK &amp; BLAS*</p> <ul> <li>These packages LAPACK &amp; BLAS: MSCG, ATC, AWPMD, ML-QUIP, LATTE, PLUMED (can self build its libs)</li> <li>Use \"intel/mkl\" package, then LAPACK &amp; BLAS will be found automatically</li> </ul> <pre><code>module load intel/mkl\nmodule load tooldev/gsl-2.6\n</code></pre> <ul> <li>Use external LAPACK &amp; BLAS</li> </ul> <pre><code>  export myLAPACK=/uhome/p001cao/app/lapack-3.10/liblapack.a\n  export myBLAS=/uhome/p001cao/app/lapack-3.10/libblas.a\n\n  -DLAPACK_LIBRARIES=${myLAPACK} -DBLAS_LIBRARIES=${myBLAS}\n</code></pre> <p>8.OpenMP</p> <pre><code>-D PKG_USER-OMP=yes -D BUILD_OMP=yes -D PKG_USER-INTEL=no\n</code></pre> <p>9.make no packages</p> <pre><code>-D PKG_GPU=no -D PKG_KIM=no -D PKG_LATTE=no -D PKG_MSCG=no -D PKG_KOKKOS=no \\\n-D PKG_USER-ADIOS=no -D PKG_USER-NETCDF=no -D PKG_USER-OMP=no -D PKG_USER-INTEL=no \\\n-D PKG_USER-QUIP=no -D PKG_USER-SCAFACOS=no -D PKG_USER-QMMM=no -D PKG_USER-VTK=no \\\n-D PKG_USER-H5MD=no \\\n</code></pre> <p>10.KOKKOS For multicore CPUs using OpenMP, set these 2 variables.</p> <pre><code>-DKokkos_ARCH_WSM=yes                 # HOSTARCH = HOST from list above\n-DKokkos_ENABLE_OPENMP=yes\n-DBUILD_OMP=yes\n</code></pre> <p>11.PLUMED</p> <ul> <li>pre-compile Plumed separately:</li> </ul> <pre><code>module load plumed\n</code></pre> <pre><code>-D PKG_PLUMED=yes -D DOWNLOAD_PLUMED=no -D PLUMED_MODE=static\n</code></pre> <ul> <li>self-build PLUMED:</li> <li>We will need GSL to link LAPACK, BLAS (require MKL)</li> <li> <p><code>Cmake</code> setting</p> <pre><code>-D PKG_PLUMED=yes -D DOWNLOAD_PLUMED=yes -D PLUMED_MODE=static\n</code></pre> </li> <li> <p>Can Configure Plumed to use Internal LAPACK&amp;BLAS: (no need install BLAS&amp;LAPACK or MKL+GSL). Edit file: <code>../cmake/Modules/Packages/PLUMED.cmake</code>, Comment out these lines:</p> <pre><code>  # find_package(LAPACK REQUIRED)\n  # find_package(BLAS REQUIRED)\n  # find_package(GSL REQUIRED)\n  # list(APPEND PLUMED_LINK_LIBS ${LAPACK_LIBRARIES} ${BLAS_LIBRARIES} GSL::gsl)\n</code></pre> </li> <li> <p>Edit file: <code>../cmake/Modules/Packages/PLUMED.cmake</code></p> <pre><code>###change lines:\n    # URL http...... (line 65)\n    # URL_MD5\n### into:\n      GIT_REPOSITORY https://github.com/plumed/plumed2.git\n      GIT_TAG master                            # hack-the-tree   v2.6.2   v2.7b\n\n      CONFIGURE_COMMAND &lt;SOURCE_DIR&gt;/configure  ....   ...\n                  --enable-modules=all --enable-asmjit --disable-external-blas --disable-external-lapack\n      ...\n### add this command after line 76 (inside ExternalProject_Add(...)):\n      UPDATE_COMMAND \"\"\n</code></pre> </li> <li> <p>New udate from LAMMPS: LAPACK &amp; BLAS now can be compiled internally in LAMMPS with option <code>-DUSE_INTERNAL_LINALG=yes</code>. So new setting in file: <code>../cmake/Modules/Packages/PLUMED.cmake</code> should be</p> </li> </ul> <p><code>shell       find_package(LAPACK REQUIRED)       find_package(BLAS REQUIRED)       find_package(GSL REQUIRED)       list(APPEND PLUMED_LINK_LIBS ${LAPACK_LIBRARIES} ${BLAS_LIBRARIES} GSL::gsl)</code></p> <pre><code>```shell\n###change lines:\n    # URL http...... (line 65)\n    # URL_MD5\n### into:\n      GIT_REPOSITORY https://github.com/plumed/plumed2.git\n      GIT_TAG master                            # hack-the-tree   v2.6.2   v2.7b\n\n      CONFIGURE_COMMAND &lt;SOURCE_DIR&gt;/configure  ....   ...\n                  --enable-modules=all --enable-asmjit\n      ...\n### add this command after line 76 (inside ExternalProject_Add(...)):\n      UPDATE_COMMAND \"\"\n```\n\n```sh\nmodule load tooldev/gsl-2.7\n\n-DPKG_PLUMED=yes -DUSE_INTERNAL_LINALG=yes  \\\n```\n</code></pre> <p>12.[ML_QUIP] (source code) compile QUIP the minimum requirements are:</p> <ul> <li>A working Fortran compiler. QUIP is tested with <code>gfortran 4.4</code> and later, and <code>ifort 11.1</code></li> <li>Linear algebra libraries BLAS and LAPACK. QUIP is tested with reference versions libblas-dev and liblapack-dev on Ubuntu 12.04, and mkl 11.1 with ifort.</li> <li>modify <code>ML-QUIP.cmake</code> : add this command after line 76 (inside ExternalProject_Add(...)):</li> </ul> <pre><code>    GIT_REPOSITORY \"https://github.com/libAtoms/QUIP/\"\n    GIT_TAG          5989901       #   origin/public\n    ...\n    UPDATE_COMMAND \"\"\n</code></pre> <p>13.MLIAP</p> <ul> <li>require python &gt;3.6</li> </ul> <p>14.MACHDYN</p> <ul> <li>require Eigen</li> </ul> <pre><code>-D MACHDYN=yes -D DOWNLOAD_EIGEN3=yes\n</code></pre> <p>open file: ../cmake/Modules/Packages/USER-SMD.cmake</p> <pre><code>### change:\n    URL http...... (line 12)\n    URL_MD5\n### into:\n    GIT_REPOSITORY https://github.com/eigenteam/eigen-git-mirror.git\n    GIT_TAG  3.3.7\n</code></pre> <p>14.MOLFILE package</p> <ul> <li>to dump PDB file, need install VMD-plugins</li> <li>compatible with VMD 1.9 and 1.9.1</li> <li>Compile VMD</li> <li>compile plugins (just this is need for Lammps) see this</li> </ul> <pre><code>tar zxvf vmd-1.9.src.tar.gz\ncd plugins\nmake LINUXPPC64\nexport PLUGINDIR=/uhome/p001cao/local/wSourceCode/vmd/vmd-1.9/plugins\nmake distrib\n</code></pre> <ul> <li>compile VMD</li> </ul> <pre><code>cd vmd-1.9.4a51\nmodule load compiler/gcc-10.3\nexport VMDINSTALLDIR=/uhome/p001cao/app/vmd\n./configure LINUXPPC64 OPENGL SILENT PTHREADS\ncd src\nmake\n</code></pre> <ul> <li>path in lib/molfile/Make.lammps: molfile_SYSPATH =-L/uhome/p001cao/local/wSourceCode/vmd/vmd-1.9/plugins/LINUXPPC64/molfile</li> </ul> <pre><code>export =/uhome/p001cao/local/wSourceCode/vmd/vmd-1.9/plugins/include\n</code></pre> <pre><code>-D MOLFILE_INCLUDE_DIR=${PlugIncDIR}\n-D PKG_MOLFILE=yes\n</code></pre> <p>15.PYTHON (use 1 of following ways)</p> <p>Note: new numpy require higher GLIBC</p> <ul> <li>use module load \u2192 do not need setting in Cmake (but this may intefere some libs: openmpi,lapack,blas,... - should not use)</li> </ul> <pre><code>module load conda/py37Lammps\n</code></pre> <ul> <li>use Python_ROOT_DIR (same as module load): \u2192 will encounter the error: Anaconda environments prevent CMake from generating a safe runtime search path \u2192 cannot be solved so far.</li> </ul> <pre><code>export pyROOT=/uhome/p001cao/app/miniconda3/envs/py37Lammps\n-DPython_ROOT_DIR=${pyROOT}   # this setting must be put on the head of cmake\n</code></pre> <ul> <li>use Python_EXECUTABLE # (Python_EXECUTABLE depend on cmake's version) (but this case still use system Python while compiling, so cannot use on multi-OS with different Versions )</li> </ul> <pre><code>export pyEXE=/uhome/p001cao/app/miniconda3/envs/py37Lammps/bin/python\nexport pyINC=/uhome/p001cao/app/miniconda3/envs/py37Lammps/include/python3.7m\nexport pyLIB=/uhome/p001cao/app/miniconda3/envs/py37Lammps/lib/libpython3.7m.a\n\n-DPython_EXECUTABLE=${pyEXE} -DPython_INCLUDE_DIR=${pyINC} -DPython_LIBRARY=${pyLIB}\n</code></pre>"},{"location":"cluster/compile/LAMMPS/#i-compiling-with-gcc-ompi","title":"I. Compiling with GCC + OMPI","text":"<p>Note</p> <ul> <li>must export compilers to to avoid miss matching compilers</li> </ul> <pre><code>export PATH=/uhome/p001cao/app/openmpi/4.1.1-gcc11.2-noUCX-eagle/bin:$PATH\nexport CC=mpicc  export CXX=mpic++  export FORTRAN=mpifort\n## can use: -DCMAKE_C_COMPILER=mpicc -DCMAKE_CXX_COMPILER=mpic++ -DCMAKE_Fortran_COMPILER=mpif90 \\\n</code></pre> <ul> <li>\"GCC + gold linker\" is good now</li> </ul> <pre><code>module load tooldev/binutils-2.36\n</code></pre> <pre><code>-DCMAKE_EXE_LINKER_FLAGS=\"-fuse-ld=gold -lrt\"\n</code></pre> <ul> <li>use MKL</li> </ul> <pre><code>module load intel/mkl-xe19u5\nsource mklvars.sh intel64\nmodule load tooldev/gsl-2.6\n</code></pre> <pre><code>-DFFT=MKL\n</code></pre> <ul> <li>use external BLAS&amp;LAPACK instead of MKL</li> </ul> <pre><code>module load tooldev/gsl-2.6\nexport myLAPACK=/uhome/p001cao/app/lapack-3.10/liblapack.a\nexport myBLAS=/uhome/p001cao/app/lapack-3.10/libblas.a\n\n-DBLAS_LIBRARIES=${myBLAS} -DLAPACK_LIBRARIES=${myLAPACK}\n</code></pre> <ul> <li>use FFTW instead of MKL</li> </ul> <pre><code>module load fftw/fftw3.3.8-ompi4.1-gcc11.2\n</code></pre> <pre><code>-DFFT=FFTW3\n</code></pre> <ul> <li>consider linkers</li> </ul> <pre><code>module load llvm/llvm-gcc10-lld                    ## to use lld\n-DCMAKE_EXE_LINKER_FLAGS=\"-fuse-ld=lld -lrt\" \\\nmodule load tooldev/binutils-2.35                ## gold\n-DCMAKE_EXE_LINKER_FLAGS=\"-fuse-ld=gold -lrt\" \\\n</code></pre>"},{"location":"cluster/compile/LAMMPS/#usc1_eagle-centos-65-cluster-with-infiniband","title":"USC1_Eagle - Centos 6.5 cluster with InfiniBand","text":"<p>Note</p> <ul> <li>use different openmpi for Eagle vs Lion</li> <li>Note: python&gt;3.7.9 require GLIBC new <code>conda install python=3.7.5 pandas=1.0 numpy=1.19</code></li> <li>Use GCC-11 need also update GCC-conda = 11 <code>conda install -c conda-forge libstdcxx-ng=11 libgcc-ng=11 libgfortran-ng=11</code></li> <li>install GSL, required by SCAFACOS package</li> </ul> <pre><code>cd lammps_master\nmkdir build   &amp;&amp;   cd build\n\n## module load tooldev/gsl-2.6\nmodule load tooldev/binutils-2.36         ## gold\nmodule load tooldev/cmake-3.21\nmodule load fftw/fftw3.3.10-ompi5.0-gcc11.2\nmodule load mpi/ompi5.0.0-gcc11.2\n\nexport PATH=/uhome/p001cao/app/openmpi/5.0.0-gcc11.2-eagle/bin:$PATH\nexport CC=mpicc  export CXX=mpic++  export FC=mpifort  export F90=mpif90\n## MOLFILE_plugins/ python 3/ LAPACK&amp;BLAS\nexport PlugIncDIR=/uhome/p001cao/local/wSourceCode/vmd/vmd-1.9/plugins/include\nexport pyROOT=/uhome/p001cao/app/miniconda3/envs/py37Lammps\n\ncmake ../cmake -C ../cmake/presets/all_on.cmake \\\n-DCMAKE_EXE_LINKER_FLAGS=\"-fuse-ld=gold -lrt\" \\\n-DPython_ROOT_DIR=${pyROOT} -DMOLFILE_INCLUDE_DIR=${PlugIncDIR} \\\n-DBUILD_MPI=yes -DBUILD_OMP=yes -DLAMMPS_MACHINE=mpi -DPKG_OPENMP=yes \\\n-DLAMMPS_EXCEPTIONS=yes -DBUILD_SHARED_LIBS=yes \\\n-DPKG_INTEL=no -DPKG_GPU=no -DPKG_KOKKOS=no \\\n-DPKG_LATTE=no -DPKG_MSCG=no -DPKG_ATC=no -DPKG_VTK=no -DPKG_ML-PACE=no \\\n-DPKG_ADIOS=no -DPKG_NETCDF=no -DPKG_KIM=no -DPKG_H5MD=no \\\n-DDOWNLOAD_EIGEN3=yes -DDOWNLOAD_VORO=yes -DDOWNLOAD_SCAFACOS=no -DPKG_SCAFACOS=no \\\n-DPKG_MESONT=no -DPKG_ML-QUIP=no \\\n-DPKG_PLUMED=yes -DDOWNLOAD_PLUMED=yes\\\n-DFFT=FFTW3 \\\n-DCMAKE_C_COMPILER=mpicc -DCMAKE_CXX_COMPILER=mpic++ -DCMAKE_Fortran_COMPILER=mpif90 \\\n-DCMAKE_INSTALL_PREFIX=/uhome/p001cao/app/lammps/gccOMPI5-dev\n\nmake -j 20\n## test:  mpirun -np 2 lmp_mpi\nmake install\n</code></pre>"},{"location":"cluster/compile/LAMMPS/#module-file","title":"Module file","text":"<pre><code>### Module file\nmodule load conda/py37Lammps\nmodule load fftw/fftw3.3.10-ompi5.0-gcc11.2\n## for Tcl script use only\nset     topdir          /uhome/p001cao/app/lammps/gccOMPI5-29Sep21\n\nprepend-path    PATH                    $topdir/bin\nprepend-path    LD_LIBRARY_PATH         $topdir/lib64\nprepend-path    INCLUDE                 $topdir/include/lammps\n\nprepend-path    PATH  /uhome/p001cao/local/wSourceCode/vmd/vmd-1.9/plugins/LINUXPPC64/molfile\n</code></pre>"},{"location":"cluster/compile/LAMMPS/#usc2_tachyon-centos-69-cluster-with-infiniband","title":"USC2_Tachyon - Centos 6.9 cluster with InfiniBand","text":"<pre><code>git pull origin develop\n\nmodule load tooldev/binutils-2.37                ## gold\nmodule load tooldev/cmake-3.20.3\nmodule load fftw/fftw3.3.10-ompi4.1.3-gcc10.3\nmodule load mpi/ompi4.1.3-gcc10.3\n\nexport PATH=$PATH:/home1/p001cao/app/openmpi/4.1.3-gcc10.3/bin\nexport CC=mpicc  export CXX=mpic++  export FC=mpifort  export F90=mpif90\nexport CFLAGS='-gdwarf-4 -gstrict-dwarf'\n### python (require py3) &amp; BLAS+LAPACK\nexport pyROOT=/home1/p001cao/app/miniconda3/envs/py37Lammps\n\ncmake ../cmake -C ../cmake/presets/all_on.cmake \\\n-DCMAKE_EXE_LINKER_FLAGS=\"-fuse-ld=gold -lrt\" \\\n-DPython_ROOT_DIR=${pyROOT} \\\n-DBUILD_MPI=yes -DBUILD_OMP=yes -DLAMMPS_MACHINE=mpi -DPKG_OPENMP=yes \\\n-DLAMMPS_EXCEPTIONS=yes -DBUILD_SHARED_LIBS=no \\\n-DPKG_INTEL=no -DPKG_GPU=no -DPKG_KOKKOS=no \\\n-DPKG_ADIOS=no -DPKG_NETCDF=no -DPKG_VTK=no -DPKG_H5MD=no \\\n-DPKG_MESONT=no -DPKG_LATTE=no -DPKG_MSCG=no -DPKG_ATC=no -DPKG_KIM=no -DPKG_SCAFACOS=no \\\n-DPKG_ML-PACE=yes -DPKG_ML-QUIP=no -DPKG_ML-HDNNP=no -DPKG_MDI=no \\\n-DPKG_PLUMED=yes \\\n-DFFT=FFTW3 \\\n-DCMAKE_INSTALL_PREFIX=/home1/p001cao/app/lammps/gccOMPI4-dev\n\nmake -j 16 &amp;&amp; make install\n</code></pre> <pre><code>### no need download option\n-DDOWNLOAD_EIGEN3=yes -DDOWNLOAD_VORO=yes -DDOWNLOAD_PLUMED=yes -DDOWNLOAD_QUIP=yes\\\n</code></pre>"},{"location":"cluster/compile/LAMMPS/#use-ompi_5","title":"use OMPI_5","text":"<pre><code>module load tooldev/binutils-2.37                ## gold\nmodule load tooldev/cmake-3.20.3\nmodule load fftw/fftw3.3.10-ompi5.0-gcc11.2\nmodule load mpi/ompi5.0.0-gcc10.3\n\nexport pyROOT=/home1/p001cao/app/miniconda3/envs/py37Lammps\n\ncmake ../cmake -C ../cmake/presets/all_on.cmake \\\n-DCMAKE_EXE_LINKER_FLAGS=\"-fuse-ld=gold -lrt\" \\\n-DPython_ROOT_DIR=${pyROOT} \\\n-DBUILD_MPI=yes -DBUILD_OMP=yes -DLAMMPS_MACHINE=mpi -DPKG_OPENMP=yes \\\n-DLAMMPS_EXCEPTIONS=yes -DBUILD_SHARED_LIBS=no \\\n-DPKG_INTEL=no -DPKG_GPU=no -DPKG_KOKKOS=no \\\n-DPKG_LATTE=no -DPKG_MSCG=no -DPKG_ATC=no -DPKG_VTK=no -DPKG_ML-PACE=no \\\n-DPKG_ADIOS=no -DPKG_NETCDF=no -DPKG_KIM=no -DPKG_H5MD=no \\\n-DDOWNLOAD_EIGEN3=yes -DDOWNLOAD_VORO=yes -DDOWNLOAD_SCAFACOS=no -DPKG_SCAFACOS=no \\\n-DPKG_MESONT=no -DPKG_ML-QUIP=yes -DDOWNLOAD_QUIP=yes \\\n-DPKG_PLUMED=yes -DDOWNLOAD_PLUMED=yes\\\n-DFFT=FFTW3 \\\n-DCMAKE_INSTALL_PREFIX=/home1/p001cao/app/lammps/gccOMPI5-dev\n</code></pre>"},{"location":"cluster/compile/LAMMPS/#use-ompi_3","title":"use OMPI_3","text":"<ul> <li>This does not work, due to OMPI3 error</li> </ul> <pre><code>module load tooldev/binutils-2.37                ## gold\nmodule load cmake/3.16.2\nmodule load fftw/3.3.8/gcc-7.4.0/ompi-3.1.4/double\nmodule load mpi/gcc-7.4.0/ompi/3.1.4\n\nexport pyROOT=/home1/p001cao/app/miniconda3/envs/py37Lammps\n\ncmake ../cmake -C ../cmake/presets/all_on.cmake \\\n-DCMAKE_EXE_LINKER_FLAGS=\"-fuse-ld=gold -lrt\" \\\n-DPython_ROOT_DIR=${pyROOT} \\\n-DBUILD_MPI=yes -DBUILD_OMP=yes -DLAMMPS_MACHINE=mpi -DPKG_OPENMP=yes \\\n-DLAMMPS_EXCEPTIONS=yes -DBUILD_SHARED_LIBS=yes \\\n-DPKG_INTEL=no -DPKG_GPU=no -DPKG_KOKKOS=no \\\n-DPKG_LATTE=no -DPKG_MSCG=no -DPKG_ATC=no -DPKG_VTK=no -DPKG_ML-PACE=no \\\n-DPKG_ADIOS=no -DPKG_NETCDF=no -DPKG_KIM=no -DPKG_H5MD=no \\\n-DDOWNLOAD_EIGEN3=yes -DDOWNLOAD_VORO=yes -DDOWNLOAD_SCAFACOS=no -DPKG_SCAFACOS=no \\\n-DPKG_MESONT=no -DPKG_ML-QUIP=no \\\n-DPKG_PLUMED=yes -DDOWNLOAD_PLUMED=yes\\\n-DFFT=FFTW3 \\\n-DCMAKE_INSTALL_PREFIX=/home1/p001cao/app/lammps/gccOMPI3-dev\n</code></pre> <p>## use Internal LAPACK&amp;BLAS, then no need (GSL &amp; MKL): open file: ../cmake/Modules/Packages/USER_PLUMED.cmake comment out line 9\u219212: find LAPACK, BLAS, GSL (Plumed build itself, no need GSL anymore) \u2192 then, do not need these: module load tooldev/gsl-2.6 module load intel/mkl-xe19u5 source mklvars.sh intel64 -DFFT=MKL     ## must set before Plumed ## or use openBLAS (bad performance) module load tooldev/gsl-2.6 export myBLAS=/home1/p001cao/app/tooldev/openBLAS-0.3.19/lib64/libopenblas.a -DBLAS_LIBRARIES=\\({myBLAS} -DLAPACK_LIBRARIES=\\)</p> <p>## load plumed separately (bad alloc) module load plumed2/2.7htt-gcc -DPKG_USER-PLUMED=yes -DDOWNLOAD_PLUMED=no -DPLUMED_MODE=shared \\</p> <p>##openKim: must create module file for openKim to add its PKG's path</p>"},{"location":"cluster/compile/LAMMPS/#module-file_1","title":"Module file","text":"<pre><code>module load tooldev/gsl-2.6\nmodule load conda/py37Lammps\nmodule load fftw/fftw3.3.10-ompi5.0-gcc11.2\n\n## for Tcl script use only\nset     topdir          /home1/p001cao/app/lammps/gccOMPI5-dev\n\nprepend-path    PATH                    $topdir/bin\nprepend-path    LD_LIBRARY_PATH         $topdir/lib64\nprepend-path    INCLUDE                 $topdir/include/lammps\n</code></pre>"},{"location":"cluster/compile/LAMMPS/#can2_gpu-centos-7-cluster-with-gpu","title":"CAN2_GPU - Centos 7 cluster with GPU","text":"<ul> <li>See GPU package</li> </ul> <pre><code>## cuda\nexport CUDA_PATH=/home/thang/app/cuda-10.2\nexport bin2c=/home/thang/app/cuda-10.2/bin/bin2c\n\n-DPKG_GPU=yes -DGPU_API=cuda -DGPU_ARCH=sm_61 -DBIN2C=${bin2c} -DGPU_PREC=double \\\n</code></pre> <ul> <li>for Pascal architect of GPU, use ARCH=sm_60/sm_61</li> </ul> <pre><code>module load mpi/ompi4.1-gcc7.4-cuda      ## cuda-10 only support to gcc-8\nmodule load cmake-3.20.3\nmodule load fftw/fftw3.3.8-ompi4.1-gcc7.4\n\nexport PATH=$PATH:/home/thang/app/openmpi/4.1.1-gcc7.4-cuda/bin\nexport CC=mpicc  export CXX=mpic++  export FC=mpifort  export F90=mpif90\n## python (require py3)\nexport pyROOT=/home/thang/app/miniconda3/envs/py37Lammps\n## cuda\nexport CUDA_PATH=/home/thang/app/cuda-10.2\nexport bin2c=/home/thang/app/cuda-10.2/bin/bin2c\n\ncmake ../cmake -C ../cmake/presets/all_on.cmake \\\n-DPython_ROOT_DIR=${pyROOT} \\\n-DBUILD_MPI=yes -DBUILD_OMP=yes -DLAMMPS_MACHINE=mpi -DPKG_OPENMP=yes \\\n-DLAMMPS_EXCEPTIONS=yes -DBUILD_SHARED_LIBS=no \\\n-DPKG_INTEL=no -DPKG_KOKKOS=no \\\n-DPKG_GPU=yes -DGPU_API=cuda -DGPU_ARCH=sm_61 -DBIN2C=${bin2c} -DGPU_PREC=double \\\n-DPKG_LATTE=no -DPKG_MSCG=no -DPKG_ATC=no -DPKG_VTK=no -DPKG_ML-PACE=no \\\n-DPKG_ADIOS=no -DPKG_NETCDF=no -DPKG_KIM=no -DPKG_H5MD=no \\\n-DDOWNLOAD_EIGEN3=yes -DDOWNLOAD_VORO=yes -DDOWNLOAD_SCAFACOS=no -DPKG_SCAFACOS=no \\\n-DPKG_MESONT=no -DPKG_ML-QUIP=no \\\n-DPKG_PLUMED=yes -DDOWNLOAD_PLUMED=yes\\\n-DFFT=FFTW3 \\\n-DCMAKE_INSTALL_PREFIX=/home/thang/app/lammps/gccOMPI-dev\n</code></pre>"},{"location":"cluster/compile/LAMMPS/#can3_gpu-ubuntu-20-with-gpu","title":"CAN3_GPU - Ubuntu 20 with GPU","text":"<ul> <li>python and fftw are availabe by command</li> </ul> <pre><code>sudo apt-get install -y fftw-dev\n</code></pre> <pre><code>module load ompi/4.1.0-gcc7.5-cuda10.2      ## cuda-10 only support to gcc-8\nmodule load cmake-3.18.3\n\nexport PATH=$PATH:/opt/app/openmpi/4.1.0-gcc7.5-cuda10.2/bin\nexport CC=mpicc  export CXX=mpic++  export FC=mpifort  export F90=mpif90\n## cuda (python is availabe on Ubuntu)\nexport CUDA_PATH=/usr/local/cuda-11.0\nexport bin2c=/usr/local/cuda-11.0/bin/bin2c\n\ncmake ../cmake -C ../cmake/presets/all_on.cmake \\\n-DPython_ROOT_DIR=${pyROOT} \\\n-DBUILD_MPI=yes -DBUILD_OMP=yes -DLAMMPS_MACHINE=mpi -DPKG_OPENMP=yes \\\n-DLAMMPS_EXCEPTIONS=yes -DBUILD_SHARED_LIBS=no \\\n-DPKG_INTEL=no -DPKG_KOKKOS=no \\\n-DPKG_GPU=yes -DGPU_API=cuda -DGPU_ARCH=sm_61 -DBIN2C=${bin2c} -DGPU_PREC=double \\\n-DPKG_LATTE=no -DPKG_MSCG=no -DPKG_ATC=no -DPKG_VTK=no -DPKG_ML-PACE=no \\\n-DPKG_ADIOS=no -DPKG_NETCDF=no -DPKG_KIM=no -DPKG_H5MD=no \\\n-DDOWNLOAD_EIGEN3=yes -DDOWNLOAD_VORO=yes -DDOWNLOAD_SCAFACOS=no -DPKG_SCAFACOS=no \\\n-DPKG_MESONT=no -DPKG_ML-QUIP=yes -DDOWNLOAD_QUIP=yes -DPKG_ML-IAP=no \\\n-DPKG_PLUMED=yes -DDOWNLOAD_PLUMED=yes\\\n-DFFT=FFTW3 \\\n-DCMAKE_INSTALL_PREFIX=/opt/app/lammps/master-gpu\n\nmake -j 24 &amp;&amp; sudo make install\n</code></pre> <pre><code>#######################################\n\nKOKKOS (USC 2) - 05May20 (error tbb_malloc  --&gt; change TBB folder in file TBB.cmake)\n\n-DBUILD_OMP=yes -DKokkos_ARCH_WSM=yes -DKokkos_ENABLE_OPENMP=yes  \\\n-DLMP_KOKKOS_USE_ATOMICS=yes -DKokkos_ENABLE_HWLOC=yes \\\n\n### TBB lib\n\nset     topdir          /home1/p001cao/local/wSourceCode/Tooldev/oneTBB-2020.2\nsetenv          TBBROOT                 $topdir/bin\nprepend-path    INCLUDE          $topdir/include\nprepend-path    LD_LIBRARY_PATH         $topdir/build/linux_intel64_gcc_cc9.2.0_libc2.12_kernel2.6.32_release\n\n\n###-- edit /cmake/Modules/FindTBB_MALLOC.cmake\n\nfind_path(TBB_MALLOC_INCLUDE_DIR NAMES tbb.h PATHS $ENV{TBBROOT}/include/tbb)\nfind_library(TBB_MALLOC_LIBRARY NAMES tbbmalloc PATHS $ENV{TBBROOT}/lib/intel64/gcc4.7\n$ENV{TBBROOT}/build/linux_intel64_gcc_cc9.2.0_libc2.12_kernel2.6.32_release)\n\n\nhttps://github.com/kokkos/kokkos/blob/master/BUILD.md\n###-- must use\nhttps://stackoverflow.com/questions/52018092/how-to-set-rpath-and-runpath-with-gcc-ld##52020177\nexport myGCC=/home1/p001cao/app/compiler/gcc-9.2.0\n-DCMAKE_CXX_LINK_FLAGS=\"-L${myGCC}/lib64 -Wl,-rpath,${myGCC}/lib64\" \\\n</code></pre> <pre><code>module load mpi/ompi4.0.3-gcc9.2.0\nmodule load tooldev/gsl-2.6\nmodule load tooldev/cmake-3.17.2\n\nmodule load tooldev/binutils-2.32\nmodule load tooldev/tbb-2020.2\n export TBB_MALLOC_LIBRARY\n export TBB_MALLOC_INCLUDE_DIR\ncmake ../cmake -C ../cmake/presets/all_on.cmake \\\n-DCMAKE_EXE_LINKER_FLAGS=\"-fuse-ld=gold -lrt\" \\\n-DBUILD_MPI=yes -DLAMMPS_MACHINE=mpi \\\n-DBUILD_OMP=yes -DKokkos_ARCH_WSM=yes -DKokkos_ENABLE_OPENMP=yes  \\\n-DBUILD_SHARED_LIBS=yes -DLAMMPS_EXCEPTIONS=yes \\\n-DPKG_GPU=no -DPKG_LATTE=no -DPKG_KIM=no -DPKG_MSCG=no -DPKG_USER-INTEL=no\\\n-DDOWNLOAD_VORO=yes -DDOWNLOAD_EIGEN3=yes \\\n-DPKG_USER-ADIOS=no -DPKG_USER-NETCDF=no -DPKG_USER-QUIP=no -DPKG_USER-SCAFACOS=no \\\n-DPKG_USER-QMMM=no -DPKG_USER-VTK=no -DPKG_USER-H5MD=no \\\n-DCMAKE_INSTALL_PREFIX=/home1/p001cao/app/lammps/05May20-gcc\n</code></pre>"},{"location":"cluster/compile/LAMMPS/#gcc-openshmem","title":"GCC + OpenSHMEM","text":"<pre><code>module load mpi/ompi4.1.0-gcc10.2\nmodule load tooldev/binutils-2.35                ## gold\nmodule load tooldev/cmake-3.18.0\nmodule load fftw/fftw3.3.8-ompi4.1-gcc10.2\n\nexport PATH=$PATH:/home1/p001cao/app/openmpi/4.1.0-gcc10.2/bin\nexport CC=shmemcc\nexport CXX=shmemc++\nexport FORTRAN=shmemfort\ncmake ../cmake -C ../cmake/presets/all_on.cmake \\\n-DCMAKE_EXE_LINKER_FLAGS=\"-fuse-ld=gold -lrt\" \\\n-DLAMMPS_EXCEPTIONS=yes -DBUILD_MPI=yes -DBUILD_OMP=yes -DLAMMPS_MACHINE=mpi \\\n-DPKG_USER-OMP=yes -DPKG_USER-INTEL=no -DPKG_GPU=no -DPKG_KOKKOS=no \\\n-DPKG_USER-SMD=yes -DDOWNLOAD_EIGEN3=yes -DDOWNLOAD_VORO=yes \\\n-DPKG_KIM=no -DDOWNLOAD_KIM=no -DPKG_LATTE=no -DPKG_MSCG=no -DPKG_USER-ATC=no -DPKG_USER-MESONT=no  \\\n-DPKG_USER-ADIOS=no -DPKG_USER-NETCDF=no -DPKG_USER-QUIP=no -DPKG_USER-SCAFACOS=no \\\n-DPKG_USER-VTK=no -DPKG_USER-H5MD=no \\\n-DFFT=FFTW3 \\\n-DPKG_USER-PLUMED=yes -DDOWNLOAD_PLUMED=yes\\\n-DCMAKE_C_COMPILER=mpicc -DCMAKE_CXX_COMPILER=mpic++ -DCMAKE_Fortran_COMPILER=mpifort \\\n-DCMAKE_INSTALL_PREFIX=/home1/p001cao/app/lammps/gccSHMEM-master\n</code></pre>"},{"location":"cluster/compile/LAMMPS/#compile-with-openmpi401-gcc740-on-can","title":"Compile with openMPI4.0.1-gcc7.4.0 on CAN","text":"<pre><code>module load mpi/openmpi4.0.2-gcc7.4.0\nmodule load cmake-3.12\n\n-D PKG_USER-ATC=no -D PKG_VORONOI=no -D PKG_USER-SMD=no -D PKG_USER-PLUMED=no\n\ncmake  -C ../cmake/presets/all_on.cmake \\\n-D CMAKE_INSTALL_PREFIX=/home/thang/app/lammps/20Nov19 \\\n-D BUILD_MPI=yes -D LAMMPS_MACHINE=mpi \\\n-D BUILD_LIB=yes -D BUILD_SHARED_LIBS=yes -D LAMMPS_EXCEPTIONS=yes \\\n-D PKG_GPU=no -D PKG_KIM=no -D PKG_LATTE=no -D PKG_MSCG=no -D PKG_KOKKOS=no \\\n-D PKG_USER-ATC=no -D PKG_VORONOI=no -D PKG_USER-SMD=no \\\n-D BUILD_OMP=yes -D PKG_USER-OMP=yes -D PKG_USER-INTEL=no \\\n-D PKG_USER-ADIOS=no -D PKG_USER-NETCDF=no -D PKG_USER-QUIP=no -D PKG_USER-SCAFACOS=no \\\n-D PKG_USER-QMMM=no -D PKG_USER-VTK=no -D PKG_USER-H5MD=no \\\n-D PKG_USER-PLUMED=no -D DOWNLOAD_PLUMED=no -D PLUMED_MODE=shared \\\n-D CMAKE_C_COMPILER=mpicc  -D CMAKE_CXX_COMPILER=mpic++ -D CMAKE_Fortran_COMPILER=mpifort \\\n../cmake\n</code></pre>"},{"location":"cluster/compile/LAMMPS/#mvapich-gcc","title":"MVAPICH-GCC","text":"<p>module load mpi/mvapich2-2.3.2-gcc9.2.0 module load plumed2/2.7htt-mvapich module load conda/py37mvapichSupp</p> <p>Configure</p> <pre><code>cmake ../cmake -DCMAKE_EXE_LINKER_FLAGS=\"-fuse-ld=gold -lrt\" \\\n-C ../cmake/presets/all_on.cmake \\\n-DBUILD_MPI=yes -DLAMMPS_MACHINE=mpi \\\n-DBUILD_OMP=yes -DPKG_USER-OMP=yes -DPKG_USER-INTEL=no \\\n-DBUILD_LIB=yes -DBUILD_SHARED_LIBS=yes -DLAMMPS_EXCEPTIONS=yes \\\n-DPKG_GPU=no -DPKG_LATTE=no -DPKG_KOKKOS=no -DPKG_KIM=no -DPKG_MSCG=no \\\n-DDOWNLOAD_VORO=yes -DDOWNLOAD_EIGEN3=yes \\\n-DPKG_USER-ADIOS=no -DPKG_USER-NETCDF=no -DPKG_USER-QUIP=no -DPKG_USER-SCAFACOS=no \\\n-DPKG_USER-QMMM=no -DPKG_USER-VTK=no -DPKG_USER-H5MD=no \\\n-DPKG_USER-PLUMED=yes -DDOWNLOAD_PLUMED=no -DPLUMED_MODE=shared \\\n-DCMAKE_C_COMPILER=mpicc -DCMAKE_CXX_COMPILER=mpic++ -DCMAKE_Fortran_COMPILER=mpifort \\\n-DCMAKE_INSTALL_PREFIX=/home1/p001cao/app/lammps/19Mar20-mva\n</code></pre> <p>https://github.com/lammps/lammps/blob/master/lib/message/cslib/src/STUBS_ZMQ/zmq.h</p> <p>A. Compile Lammps19 with openMPI-4.0.2, Intel2019xe and MKL (w/wt FFTW-3.3.8) (USC) II: Load modules module load mpi/ompi4.0.2-Intel2019xe-noIB module load intel/mkl-2019xe module load gcc/gcc-7.4.0 module load plumed2/2.6htt module load cmake-3.15.1 III: Compiling LAMMPS</p> <ul> <li>if occur error not found compiler, use this command to find path</li> </ul> <p>find / -name icpc find / -name ifort</p> <p>find / -name icc</p> <p>iii. Compile lammps cd  lammps-folder mkdir  build cd  build</p> <p>Step1: configuration</p> <p>Note: write CMAKE command below on single line</p> <pre><code>cmake  -C ../cmake/presets/all_on.cmake \\\n-D CMAKE_INSTALL_PREFIX=/uhome/p001cao/local/lammps/20Nov19 \\\n-D BUILD_MPI=yes -D LAMMPS_MACHINE=mpi \\\n-D BUILD_LIB=yes -D BUILD_SHARED_LIBS=yes -D LAMMPS_EXCEPTIONS=yes \\\n-D PKG_GPU=no -D PKG_KIM=no -D PKG_LATTE=no -D PKG_MSCG=no -D PKG_KOKKOS=no \\\n-D DOWNLOAD_VORO=yes -D DOWNLOAD_EIGEN3=yes \\\n-D BUILD_OMP=yes -D PKG_USER-OMP=yes -D PKG_USER-INTEL=no \\\n-D PKG_USER-ADIOS=no -D PKG_USER-NETCDF=no -D PKG_USER-QUIP=no -D PKG_USER-SCAFACOS=no \\\n-D PKG_USER-QMMM=no -D PKG_USER-VTK=no -D PKG_USER-H5MD=no \\\n-D PKG_USER-PLUMED=yes -D DOWNLOAD_PLUMED=no -D PLUMED_MODE=shared \\\n-D FFT=MKL \\\n-D MKL_LIBRARY=/uhome/p001cao/local/intel/xe2019/compilers_and_libraries_2019.5.281/linux/mkl/lib/intel64 \\\n-D CMAKE_C_COMPILER=mpicc  -D CMAKE_CXX_COMPILER=mpic++ -D CMAKE_Fortran_COMPILER=mpifort \\\n../cmake\n</code></pre> <p>Step 2: compile ( in /build) make -j 8 test: mpirun -np 2 lmp_mpi LAMMPS (19 Jul 2019) Total wall time: 0:00:21</p> <p>step 3: copy file make install</p> <p>Step 4: create module file  create file \"7Aug19\"</p> <pre><code>## for Tcl script use only\nset     topdir          /uhome/p001cao/local/lammps/7Aug19\nset     version         7Aug19\n\nmodule load  mpi/openMPI/4.0.2-Intel2018xe\nmodule load  fftw/3.3.8/openmpi4.0.2-intel2018xe-double\nmodule load  conda2-2019\nmodule load  plumed2/2.6.0\n\n\nsetenv          LAMMPS                  $topdir\n\nprepend-path    PATH                                    $topdir/bin\nprepend-path    LD_LIBRARY_PATH         $topdir/lib64\nprepend-path    INCLUDE                            $topdir/include/lammps\n</code></pre> <p>save it in: /uhome/p001cao/local/share/lmodfiles/lammps Ref: https://lammps.sandia.gov/doc/Build_basics.html</p>"},{"location":"cluster/compile/LAMMPS/#usc2","title":"USC2","text":"<p>Note: Kokkos may require TBB lib \u2192 might only Intel can work</p> <pre><code>## Download specific TAG: git clone --branch &lt;tag_name&gt; &lt;repo_url&gt;\ngit clone --branch stable_3Mar2020 https://github.com/lammps/lammps.git lammps_stable_3Mar2020\ncd lammps_stable_3Mar2020\nmkdir build\ncd build\n###--- module load mpi/ompi4.0.3-intel19u5 module load intel/mkl-xe19u5 module load plumed2/2.7htt module load tooldev/cmake-3.17.2\n</code></pre> <p>Configure</p> <pre><code>cmake ../cmake -C ../cmake/presets/all_on.cmake \\ -DBUILD_MPI=yes -DLAMMPS_MACHINE=mpi \\ -DBUILD_OMP=yes -DKokkos_ARCH_WSM=yes -DKokkos_ENABLE_OPENMP=yes \\ -DBUILD_SHARED_LIBS=yes -DLAMMPS_EXCEPTIONS=yes \\ -DPKG_GPU=no -DPKG_LATTE=no -DPKG_KIM=no -DPKG_MSCG=no -DPKG_USER-INTEL=no\\ -DDOWNLOAD_VORO=yes -DDOWNLOAD_EIGEN3=yes \\ -DPKG_USER-ADIOS=no -DPKG_USER-NETCDF=no -DPKG_USER-QUIP=no -DPKG_USER-SCAFACOS=no \\ -DPKG_USER-QMMM=no -DPKG_USER-VTK=no -DPKG_USER-H5MD=no \\ -DPKG_USER-PLUMED=yes -DDOWNLOAD_PLUMED=no -DPLUMED_MODE=shared \\ -DCMAKE_C_COMPILER=mpicc -DCMAKE_CXX_COMPILER=mpic++ \\ -DCMAKE_INSTALL_PREFIX=/home1/p001cao/app/lammps/05May20\n</code></pre>"},{"location":"cluster/compile/LAMMPS/#compile-with-impi-2019xe-mkl","title":"Compile with IMPI-2019xe + MKL","text":"<p>Note: use intelMPI can run all both centos7 &amp; centos6</p>"},{"location":"cluster/compile/LAMMPS/#usc1_eagle-centos-65-cluster-with-infiniband_1","title":"USC1_Eagle - Centos 6.5 cluster with InfiniBand","text":"<p>Load modules</p> <pre><code>module load intel/compiler-xe19u5\nmodule load mpi/impi-xe19u5\nmodule load intel/mkl-xe19u5\nmodule load plumed2/2.6httIMPI\nmodule load conda/py37\nmodule load cmake-3.15.1\n\nconfiguration\ncd lammps-folder\nmkdir build\ncd build\ncmake  -C ../cmake/presets/all_on.cmake \\\n-D CMAKE_INSTALL_PREFIX=/uhome/p001cao/app/lammps/20Nov19impi \\\n-D BUILD_MPI=yes -D LAMMPS_MACHINE=mpi \\\n-D BUILD_LIB=yes -D BUILD_SHARED_LIBS=yes -D LAMMPS_EXCEPTIONS=yes \\\n-D PKG_GPU=no -D PKG_KIM=no -D PKG_LATTE=no -D PKG_MSCG=no -D PKG_KOKKOS=no \\\n-D DOWNLOAD_VORO=yes -D DOWNLOAD_EIGEN3=yes \\\n-D BUILD_OMP=yes -D PKG_USER-OMP=yes -D PKG_USER-INTEL=no \\\n-D PKG_USER-ADIOS=no -D PKG_USER-NETCDF=no -D PKG_USER-QUIP=no -D PKG_USER-SCAFACOS=no \\\n-D PKG_USER-QMMM=no -D PKG_USER-VTK=no -D PKG_USER-H5MD=no \\\n-D PKG_USER-PLUMED=yes -D DOWNLOAD_PLUMED=no -D PLUMED_MODE=shared \\\n-D FFT=MKL \\\n-D MKL_LIBRARY=/uhome/p001cao/app/intel/xe19u5/compilers_and_libraries_2019.5.281/linux/mkl/lib/intel64_lin \\\n-D CMAKE_C_COMPILER=mpiicc -D CMAKE_CXX_COMPILER=mpiicpc -D CMAKE_Fortran_COMPILER=mpiifort \\\n../cmake\n\nmake -j 8\ntest:  mpirun -np 2 ./lmp_mpi\nmake install\n</code></pre> <p>Step 4: create module file  create file \"7Aug19-Impi\"</p>"},{"location":"cluster/compile/LAMMPS/#_1","title":"LAMMPS","text":"<p>module load intel/2019xe module load mpi/impi-2019xe module load plumed2/2.6.0-Impi module load conda2-2019 setenv          LAMMPS                  $topdir</p> <p>prepend-path    PATH                                    $topdir/bin prepend-path    LD_LIBRARY_PATH         $topdir/lib64 prepend-path    INCLUDE                            $topdir/include/lammps</p>"},{"location":"cluster/compile/LAMMPS/#_2","title":"LAMMPS","text":"<pre><code>### 2. USC 2\n\n```shell\nmodule load compiler/gcc-10.2              # must load before impi\nmodule load intel/compiler-xe19u5           # intel include lld linker  require GLIBC 2.15\nmodule load intel/mkl-xe19u5\nmodule load intel/impi-xe19u5\nsource mpivars.sh release\nmodule load tooldev/cmake-3.18.0\nmodule load tooldev/gsl-2.6\nmodule load tooldev/binutils-2.32                # gold\n\nexport PATH=$PATH:/home1/p001cao/app/intel/xe19u5/compilers_and_libraries_2019.5.281/linux/bin\nexport CC=mpiicc\nexport CXX=mpiicpc\nexport FORTRAN=mpiifort\n\ncmake ../cmake -C ../cmake/presets/all_on.cmake \\\n-DCMAKE_EXE_LINKER_FLAGS=\"-fuse-ld=gold -lrt\" \\\n-DLAMMPS_EXCEPTIONS=yes -DBUILD_MPI=yes -DBUILD_OMP=yes -DLAMMPS_MACHINE=mpi \\\n-DPKG_USER-OMP=yes -DPKG_USER-INTEL=yes -DPKG_GPU=no -DPKG_KOKKOS=no \\\n-DPKG_USER-SMD=yes -DDOWNLOAD_EIGEN3=yes -DDOWNLOAD_VORO=yes \\\n-DPKG_KIM=no -DDOWNLOAD_KIM=no -DPKG_LATTE=no -DPKG_MSCG=no -DPKG_USER-ATC=no \\\n-DPKG_USER-ADIOS=no -DPKG_USER-NETCDF=no -DPKG_USER-QUIP=no -DPKG_USER-SCAFACOS=no \\\n-DPKG_USER-VTK=no -DPKG_USER-H5MD=no \\\n-DFFT=MKL \\\n-DPKG_USER-PLUMED=yes -DDOWNLOAD_PLUMED=yes\\\n-DCMAKE_C_COMPILER=mpiicc -DCMAKE_CXX_COMPILER=mpiicpc -DCMAKE_Fortran_COMPILER=mpiifort \\\n-DCMAKE_INSTALL_PREFIX=/home1/p001cao/app/lammps/impi-master\n#-- NOTE: Kokkos require TBB lib\nmodule load intel/tbb-xe20u2\n##-- edit /cmake/Modules/FindTBB_MALLOC.cmake\nfind_path(TBB_MALLOC_INCLUDE_DIR NAMES tbb.h PATHS $ENV{TBBROOT}/include/tbb)\nfind_library(TBB_MALLOC_LIBRARY NAMES tbbmalloc PATHS $ENV{TBBROOT}/lib/intel64/gcc4.8)\n##--\n-DCMAKE_EXE_LINKER_FLAGS=\"-fuse-ld=lld -lrt\" \\\nsource compilervars.sh intel64\nsource mklvars.sh intel64\n</code></pre>"},{"location":"cluster/compile/LAMMPS/#compiling-with-llvm-ompi","title":"Compiling with LLVM + OMPI","text":""},{"location":"cluster/compile/LAMMPS/#usc2_tachyon-centos-69-cluster-with-infiniband_1","title":"USC2_Tachyon - Centos 6.9 cluster with InfiniBand","text":"<p>Note</p> <ul> <li>To void libs hidden by conda-lib, set absolute path for dynamic libs (*.so). See compile LLVM for more information</li> <li>if the error relates to conda (require new GLIBC),<ul> <li>relate to <code>zlib</code>, install lower version <code>conda install -c conda-forge zlib=1.2.11</code></li> <li>relate to <code>libstdc++</code>, use <code>export LD_LIBRARY_PATH=path/to/new/lib:$LD_LIBRARY_PATH</code></li> </ul> </li> <li>if the error relates to `openmpi/mca_pmix_pmix3x.so: undefined symbol:' \u2192 delete isntall folder and reinstall</li> </ul> <p>Info</p> <ul> <li>can use <code>export CFLAGS</code>, <code>export CXXFLAGS</code>. This same as <code>-DCMAKE_CXX_LINK_FLAGS</code> (CPPFLAG means both)</li> <li><code>LDFLAGS</code> same as <code>CMAKE_EXE_LINKER_FLAGS</code></li> <li>Some packages, such as <code>QUIP</code>, <code>LATTE</code>, <code>PLUMED</code>... requires LAPACK (and BLAS), which may not available on some systems. Then, use <code>-DUSE_INTERNAL_LINALG=yes</code> to install them, internally. With this option, we don't need to compile <code>LAPACK &amp; BLAS</code> in <code>PLUMED</code>, so this make a simplified setting for PLUMED. Note to <code>load module</code>tooldev/gsl-2.7<code>for automatically find</code>LAPACK &amp; BLAS`.</li> <li><code>LEPTON_ENABLE_JIT</code> requires 'sys/auxv.h' that is only available on newer GLIBC. So disable it.</li> </ul> <pre><code>cd /home1/p001cao/0SourceCode/lammps_dev\ngit pull origin develop\nrm -rf build_LLVM &amp;&amp; mkdir build_LLVM &amp;&amp; cd build_LLVM\n</code></pre> <pre><code>module load tooldev/cmake-3.27\nmodule load tooldev/binutils-2.40\nmodule load tooldev/gsl-2.7\nmodule load mpi/fftw3.3.10-ompi4.1.x-clang17\nmodule load mpi/ompi4.1.x-clang17-ucx1.15\n\nOPENMPI=/home1/p001cao/app/mpi/openmpi4.1.x-clang17-ucx1.15\nexport PATH=${OPENMPI}/bin:$PATH\nexport CC=mpicc CXX=mpic++ FC=mpifort\nexport LDFLAGS=\"-fuse-ld=lld -lrt\"\n## python (require py3), BLAS+LAPACK\nexport LD_LIBRARY_PATH=/home1/p001cao/app/compiler/gcc-11/lib64:$LD_LIBRARY_PATH   # to avoid using libstdc++.so in conda\nmyBLAS=/home1/p001cao/app/tooldev/openBLAS0.3.23-clang17/lib64/libopenblas.so\nmyPREFIX=/home1/p001cao/app/lammps/llvmOMPI4-dev\n\ncmake ../cmake -C ../cmake/presets/all_on.cmake \\\n  -DBUILD_MPI=yes -DBUILD_OMP=yes -DPKG_OPENMP=yes \\\n  -DLAMMPS_MACHINE=mpi -DBUILD_SHARED_LIBS=yes \\\n  -DPKG_GPU=no -DPKG_KOKKOS=no -DPKG_INTEL=no -DPKG_MDI=no \\\n  -DPKG_SCAFACOS=no -DPKG_ADIOS=no -DPKG_NETCDF=no -DPKG_VTK=no -DPKG_H5MD=no \\\n  -DPKG_MESONT=no -DPKG_LATTE=no -DPKG_MSCG=no -DPKG_ATC=no -DPKG_KIM=no \\\n  -DPKG_LEPTON=yes -DLEPTON_ENABLE_JIT=no \\\n  -DPKG_ML-QUIP=no -DPKG_ML-PACE=no -DPKG_ML-HDNNP=no \\\n  -DPKG_PLUMED=yes -DUSE_INTERNAL_LINALG=yes  \\\n  -DFFT=FFTW3 -DBLAS_LIBRARIES=${myBLAS} -DLAPACK_LIBRARIES=${myBLAS} \\\n  -DCMAKE_INSTALL_PREFIX=${myPREFIX}\n</code></pre> <pre><code>make -j 16 &amp;&amp; make install\n</code></pre> <p>with python <pre><code>export pyROOT=/home1/p001cao/app/miniconda3/envs/py39link_lammps\nexport myZLIB=/home1/p001cao/app/tooldev/zlib-1.2.12               # avoid zlib hidden by conda\n\n-DPython_ROOT_DIR=${pyROOT} \\\n-DZLIB_INCLUDE_DIR=${myZLIB}/include -DZLIB_LIBRARY=${myZLIB}/lib/libz.so.1.2.12 \\\n</code></pre></p>"},{"location":"cluster/compile/LAMMPS/#compile-with-conda","title":"Compile with Conda","text":"<p>This way may eliminate some work on installing dependencies</p> <p>See this link</p>"},{"location":"cluster/compile/LLVM/","title":"LLVM","text":"<ul> <li>LLVM</li> <li>Download</li> <li>LLVM 14<ul> <li>USC2: Tachyon - Centos 6.9</li> <li>use GCC</li> <li>Module file</li> <li>How to Use Clang without GCC on Linux</li> <li>use GCC-conda</li> </ul> </li> <li>LLVM 16<ul> <li>USC2: Tachyon - Centos 6.9</li> </ul> </li> </ul>"},{"location":"cluster/compile/LLVM/#llvm","title":"LLVM","text":"<p>The LLVM project has multiple components. The core of the project is itself called \"LLVM\". This contains all of the tools, libraries, and header files needed to process intermediate representations and convert them into object files. Tools include an assembler, disassembler, bitcode analyzer, and bitcode optimizer. It also contains basic regression tests.</p> <p>C-like languages use the Clang frontend. This component compiles C, C++, Objective-C, and Objective-C++ code into LLVM bitcode -- and from there into object files, using LLVM.</p> <p>Other components include: the libc++ C++ standard library, the LLD linker, and more.</p> <p>**Requirements Compiling LLVM requires that you have several software packages installed. The table below lists those required packages. The Package column is the usual name for the software package that LLVM depends on. The Version column provides \u201cknown to work\u201d versions of the package. The Notes column describes how LLVM uses the package and provides other details.</p> Package Version Cmakte &gt;=3.13.4 GCC &gt;=7.1.0 Python &gt;= 3.6 BINUTILS newer is better <p>See here</p>"},{"location":"cluster/compile/LLVM/#download","title":"Download","text":"<pre><code># tar xvf llvm-project-llvmorg-14.0.5.tar.gz\n# cd llvm-project-llvmorg-14.0.5\n# rm -r llvm-14\n\ngit clone --branch release/14.x https://github.com/llvm/llvm-project.git llvm-14x\ncd llvm-14x\ngit pull origin release/14.x\nmkdir build &amp;&amp; cd build\n</code></pre>"},{"location":"cluster/compile/LLVM/#tachyon-centos-69","title":"Tachyon - Centos 6.9","text":""},{"location":"cluster/compile/LLVM/#llvm-14","title":"LLVM 14","text":""},{"location":"cluster/compile/LLVM/#use-gcc","title":"use GCC","text":"<p>Note</p> <ul> <li>May need GCC &gt;= 9.</li> <li>Use <code>-DCMAKE_CXX_STANDARD=17</code> to avoid no digit exponent.</li> <li>use <code>CMAKE_C_FLAGS=\"-flax-vector-conversions\"</code> avoid 128i convert error.</li> <li>consider -DLLVM_TARGETS_TO_BUILD=\"AArch64\".</li> <li>must use <code>-DGCC_INSTALL_PREFIX -DCMAKE_CXX_LINK_FLAGS=\"-Wl,-rpath,${myCOMPILER}/lib64 -L${myCOMPILER}/lib64\"</code> to have right link to libc.</li> <li>Dont use -DLLVM_ENABLE_RUNTIMES=\"compiler-rt;libc;libcxx;libcxxabi;libunwind\". Instead, use DLLVM_ENABLE_RUNTIMES=\"compiler-rt;libc;libcxx;libcxxabi;libunwind\" see.</li> <li>These modules may cause errors: compiler-rt;libunwind;libc</li> <li>Use Release/Debug</li> <li>See more https://llvm.org/docs/CMake.html</li> <li>LLDB require SWIG &gt; 3.0</li> <li>LLVM require python &gt;= 3.6, and python 3.6 require zlib&gt;1.2.11 require GLIBC_2.14 (libgcc-ng=9). And zlib=1.2.11 will cause hidden libs by conda, so should update  zlib&gt;1.2.11 to hidden error. Or should use static-link (libs*.a) or use absolute path to dynamic libs (.so) in cmake to avoid this error. Note, link a dynamic lib (.so) to a static lib (.a) may cause \" Dyanmic reloc overflow runtime\" error, so best way is use absolute path to dynamic libs (.so).</li> </ul> <pre><code>source activate py37Lammps\nconda install -c conda-forge libgcc-ng=9 libstdcxx-ng=9 libstdcxx-ng=9 libgomp=9 zlib=1.2.11 python=3.7\n</code></pre> <p>**Install LLVM</p> <pre><code>git pull origin release/14.x\nmkdir build &amp;&amp; cd build\n\nmodule load tool_dev/cmake-3.24\nmodule load conda/py37Lammps\nmodule load tool_dev/binutils-2.37\nmodule load compiler/gcc-12.2\n\nexport myGCC=/home1/p001cao/local/app/compiler/gcc-12.2\nexport PATH=$PATH:${myGCC}/bin                                 # :/usr/bin\nexport CC=gcc export CXX=g++\nexport LDFLAGS=\"-fuse-ld=gold -lrt\"\nexport myZLIB=/home1/p001cao/local/app/tool_dev/zlib-1.2.12           # avoid zlib hidden by conda\nexport CPPFLAGS=\"-gdwarf-4 -gstrict-dwarf\"       # avoid dwarf5 error\n\ncmake ../llvm -DCMAKE_BUILD_TYPE=Release \\\n-DLLVM_ENABLE_PROJECTS=\"clang;clang-tools-extra;libclc;lld;openmp;polly;flang;pstl;mlir;libcxx;libcxxabi\" \\\n-DGCC_INSTALL_PREFIX=${myGCC} \\\n-DCMAKE_CXX_LINK_FLAGS=\"-Wl,-rpath,${myGCC}/lib64 -L${myGCC}/lib64\" \\\n-DCMAKE_CXX_STANDARD=17 \\\n-DCMAKE_C_FLAGS=\"-flax-vector-conversions\" -DCMAKE_C_FLAGS_RELEASE=\"-flax-vector-conversions\" \\\n-DZLIB_INCLUDE_DIR=${myZLIB} -DZLIB_LIBRARY=${myZLIB}/lib/libz.so.1.2.12 \\\n-DCMAKE_INSTALL_PREFIX=/home1/p001cao/local/app/compiler/llvm-14\n\nmake -j 16 &amp;&amp; make install\n</code></pre> <p>check:</p> <pre><code>module load compiler/llvm-14\nclang -v\n</code></pre> <p>Options:</p> <pre><code>export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:${myCOMPILER}/lib\n\n-DLLVM_ENABLE_RUNTIMES=\"libunwind;libcxx\"\n-DLLVM_ENABLE_PROJECTS=\"clang;clang-tools-extra;flang;libclc;lld;openmp;polly;pstl;mlir\" \\  # \"clang;flang;lld;openmp\"\n-DCMAKE_CXX_LINK_FLAGS=\"-Wl,-rpath,${myCOMPILER}/lib64 -L${myCOMPILER}/lib64\" \\\n</code></pre> Ref <p>[1] https://stackoverflow.com/questions/69683755/libpng-apngerror-o-requires-dynamic-r-x86-64-pc32-reloc-against-stderr 2(https://tinyurl.com/2bw9jo5q)</p>"},{"location":"cluster/compile/LLVM/#module-file","title":"Module file","text":"<p>at directory: /home1/p001cao/local/1myModfiles/compiler \u2192 create file \"llvm-14\"</p> <pre><code># for Tcl script use only\nset     topdir          /home1/p001cao/local/app/compiler/llvm-14\nset     version         clang-14.0\n\nprepend-path    PATH                    $topdir/bin\nprepend-path    LD_LIBRARY_PATH         $topdir/lib\nprepend-path    LD_LIBRARY_PATH         $topdir/libexec\nprepend-path    INCLUDE                 $topdir/include\n# prepend-path    INCLUDE                 $topdir/include/c++/v1\n</code></pre>"},{"location":"cluster/compile/LLVM/#how-to-use-clang-without-gcc-on-linux","title":"How to Use Clang without GCC on Linux","text":"<pre><code>export LIBS=\"-nodefaultlibs -lc++ -lc++abi -lm -lc -lgcc_s -lgcc\"\nexport CXX=clang++\nexport CC=clang\n</code></pre> <pre><code>cmake -DCMAKE_C_COMPILER=clang -DCMAKE_CXX_COMPILER=clang++\n-DCMAKE_EXE_LINKER_FLAGS=\"-nodefaultlibs -lc++ -lc++abi -lm -lc -lgcc_s -lgcc\"\n</code></pre> <p>http://tolik1967.azurewebsites.net/clang_no_gcc.html</p>"},{"location":"cluster/compile/LLVM/#use-gcc-conda","title":"use GCC-conda","text":"<pre><code>use conda can install: gcc, cmake,... and other libs. But note install LLVM, since new GLIBC is required,\n</code></pre> <p>**Install Conda (Since LLVM require python &gt;= 3.6)</p> <pre><code>conda create -n py37gcc12 python=3.7\nsource activate py37gcc12\nconda install -c conda-forge libgcc-ng=12 libstdcxx-ng=12 libgomp=12 cmake=3 binutils\n</code></pre> <p>**Install LLVM</p> <pre><code>git clone -b release/14.x https://github.com/llvm/llvm-project.git llvm-14\ncd llvm-14\nmkdir build_conda &amp;&amp; cd build_conda\n\nmodule load conda/py37gcc12\n\nexport myCOMPILER=/home1/p001cao/local/app/miniconda3/envs/py37gcc12\nexport PATH=${myCOMPILER}/bin:$PATH                                     # :/usr/bin\nexport CC=gcc export CXX=g++\nexport LDFLAGS=\"-fuse-ld=gold -lrt\"\nexport CFLAGS=\"-gdwarf-4 -gstrict-dwarf -flax-vector-conversions\"\n\ncmake ../llvm -DCMAKE_BUILD_TYPE=Release \\\n-DCMAKE_CXX_STANDARD=17 \\\n-DLLVM_ENABLE_PROJECTS=\"clang;clang-tools-extra;libclc;lld;openmp;polly;pstl;mlir;flang;libcxx;libcxxabi\" \\\n-DGCC_INSTALL_PREFIX=${myCOMPILER} \\\n-DCMAKE_CXX_LINK_FLAGS=\"-Wl,-rpath,${myCOMPILER}/lib64 -L${myCOMPILER}/lib64\" \\\n-DCMAKE_INSTALL_PREFIX=/home1/p001cao/local/app/compiler/llvm-14-conda\n\nmake -j 16 &amp;&amp; make install\n</code></pre>"},{"location":"cluster/compile/LLVM/#llvm-17","title":"LLVM 17","text":"<p>Note</p> <ul> <li>do not use GCC-13, since some source codes can not recognize compiler version</li> <li>projects with errors: PROJECTS=\"mlir;flang;clang-tools-extra;libclc\"  RUNTIMES=\"libc;libcxx;libcxxabi\". Try with few projects, then increasing.</li> <li>LLVM 16 cause error: <code>'aligned_alloc' was not declared in this scope</code> (mlir) \u2192 <code>aligned_alloc</code> should availabe with<code>#include &lt;stdlib.h&gt;</code>, but if system does not support it, then define it in the <code>namespace</code> of the file where error comes see this <pre><code>void* aligned_alloc(size_t alignment, size_t size) {\n    void* ptr;\n    if (posix_memalign(&amp;ptr, alignment, size) != 0) {\n        return NULL;\n    }\n    return ptr;\n}\n</code></pre></li> <li>to disable \"mlir\", we must disable \"flang\", since Enabling MLIR as a dependency to flang</li> <li>error <code>\u2018PTRACE_SEIZE\u2019 was not declared</code> \u2192 add following lines in the file where error comes     <pre><code>#ifndef PTRACE_SEIZE\n#define PTRACE_SEIZE ((__ptrace_request)0x4206)\n#endif\n</code></pre></li> <li>must update newer <code>binutils</code>, to avoid zip error</li> <li>Use GCC-11.4</li> <li><code>conda install gcc_linux-64=11.2 zlib=1.2.11 libzlib-1.2.11</code></li> </ul> <pre><code>cd /home1/p001cao/0SourceCode\n# git clone -b release/17.x https://github.com/llvm/llvm-project.git llvm-17x\n\ncd llvm-17x\ngit pull origin release/17.x\n# git reset --hard origin/main\n# git pull origin main\n\nrm -rf build &amp;&amp; mkdir build &amp;&amp; cd build\n</code></pre> <pre><code>module load tooldev/cmake-3.27\nmodule load tooldev/binutils-2.40\nmodule load conda/py9link_lammps\nmodule load compiler/gcc-11\n\nmyGCC=/home1/p001cao/app/compiler/gcc-11\nexport PATH=${myGCC}/bin:$PATH                                 # :/usr/bin\nexport CC=gcc CXX=g++ FC=clang-new\nexport LDFLAGS=\"-fuse-ld=gold -lrt\"\nexport CXXFLAGS=\"-std=c++17\"\nmyZLIB=/home1/p001cao/app/tooldev/zlib-1.2.12     # avoid zlib hidden by conda\nmyFREFIX=/home1/p001cao/app/compiler/llvm-17\n\ncmake ../llvm -DCMAKE_BUILD_TYPE=Release \\\n    -DLLVM_ENABLE_PROJECTS=\"clang;lld;openmp;polly;flang\" \\\n    -DLLVM_ENABLE_RUNTIMES=\"pstl\" \\\n    -DGCC_INSTALL_PREFIX=${myGCC} \\\n    -DCMAKE_CXX_LINK_FLAGS=\"-Wl,-rpath,${myGCC}/lib64 -L${myGCC}/lib64\" \\\n    -DCMAKE_CXX_STANDARD_REQUIRED=ON -DLLVM_ENABLE_ZLIB=ON \\\n    -DCMAKE_C_FLAGS=\"-flax-vector-conversions\" -DCMAKE_C_FLAGS_RELEASE=\"-flax-vector-conversions\" \\\n    -DZLIB_INCLUDE_DIR=${myZLIB}/include -DZLIB_LIBRARY=${myZLIB}/lib/libz.so.1.2.12 \\\n    -DCMAKE_INSTALL_PREFIX=${myFREFIX}\n\nmake -j 16 &amp;&amp; make install\n</code></pre> <p>Quote</p> <p>ReleaseNotes: https://releases.llvm.org/15.0.0/docs/ReleaseNotes.html</p> <p>options: <pre><code>export CFLAGS=\"-gdwarf-4 -gstrict-dwarf\"                 # avoid dwarf5 error\n</code></pre></p>"},{"location":"cluster/compile/Libtool/","title":"Libtool","text":"<p>Libtool needed in the case compiling from source code. Some source codes do not release with <code>configure</code> file, then <code>libtool</code> is used to accompanied with <code>autoconf</code> and <code>automake</code> to run:</p> <pre><code>./autogen.sh\n</code></pre> <p>The above command with produce <code>configure</code> file, after the configuration can be proceeded with</p> <pre><code>./configure ........\n</code></pre>"},{"location":"cluster/compile/Libtool/#libtool_1","title":"Libtool","text":"<p>Website</p> <pre><code>cd /home1/p001cao/0SourceCode/tooldev\nwget http://ftp.jaist.ac.jp/pub/GNU/libtool/libtool-2.4.7.tar.gz\ntar xvfz libtool-2.4.7.tar.gz\ncd libtool-2.4.7\n</code></pre> <pre><code>./configure --prefix=/home1/p001cao/app/tooldev/libtool-2.4.7\n\nmake &amp;&amp; make install\n</code></pre> <p>Module file</p> <pre><code># for Tcl script use only\nset     topdir          /home1/p001cao/app/tooldev/libtool-2.4.7\n\nprepend-path    PATH                $topdir/bin\nprepend-path    LD_LIBRARY_PATH     $topdir/lib\nprepend-path    INCLUDE             $topdir/include\nprepend-path    PKG_CONFIG_PATH     $topdir/lib/pkgconfig\n</code></pre>"},{"location":"cluster/compile/Libtool/#autoconf","title":"Autoconf","text":"<p>Autoconf is an extensible package of M4 macros that produce shell scripts to automatically configure software source code packages.</p> <ul> <li>Website</li> <li>Repo</li> </ul> <p><pre><code>cd /home1/p001cao/0SourceCode/tooldev\nwget https://ftp.gnu.org/gnu/autoconf/autoconf-2.71.tar.gz\n</code></pre> Alpha/beta releases of Autoconf <pre><code>cd /home1/p001cao/local/wSourceCode/tooldev\nwget https://alpha.gnu.org/pub/gnu/autoconf/autoconf-2.72c.tar.gz --no-check-certificate\ntar zxf autoconf-2.72c.tar.gz\ncd autoconf-2.72c\n</code></pre></p> <pre><code>./configure --prefix=/home1/p001cao/app/tooldev/autoconf-2.72c\n\nmake &amp;&amp; make install\n</code></pre> <p>Module file</p> <pre><code># for Tcl script use only\nset     topdir          /home1/p001cao/app/tooldev/autoconf-2.72\n\nprepend-path    PATH                    $topdir/bin\nprepend-path    LD_LIBRARY_PATH         $topdir/share\n</code></pre>"},{"location":"cluster/compile/Libtool/#automake","title":"Automake","text":"<p>GNU Automake is a tool for automatically generating Makefile.in files compliant with the GNU Coding Standards. Automake requires the use of GNU Autoconf.</p> <ul> <li>Website</li> <li>Repo</li> </ul> <pre><code>Require autoconf&gt;=2.65\n</code></pre> <pre><code>cd /home1/p001cao/0SourceCode/tooldev\nwget http://ftp.gnu.org/gnu/automake/automake-1.16.5.tar.gz\ntar xvzf automake-1.16.5.tar.gz\ncd automake-1.16.5\n</code></pre> <pre><code>module load tooldev/autoconf-2.72c\n\n./configure --prefix=/home1/p001cao/app/tooldev/automake-1.16.5\n\nmake &amp;&amp; make install\n</code></pre> <p>usage:</p> <pre><code>export ACLOCAL_PATH=/home1/p001cao/app/tooldev/libtool-2.4.7/share/aclocal\n</code></pre> <p>Module file</p> <pre><code># for Tcl script use only\nset     topdir          /home1/p001cao/app/tooldev/automake-1.16.5\n\nprepend-path    PATH                    $topdir/bin\n</code></pre>"},{"location":"cluster/compile/Libtool/#gsl","title":"GSL","text":"<p>GSL is needed to link LAPACK &amp; BLAS libraries when installing Plumed in Lammps (but no need now)</p> <pre><code>cd /home1/p001cao/0SourceCode/tooldev\nwget ftp://ftp.gnu.org/gnu/gsl/gsl-2.7.tar.gz\ntar xvzf gsl-2.7.tar.gz\ncd gsl-2.7\n\n./configure --prefix=/home1/p001cao/app/tooldev/gsl-2.7\n\nmake &amp;&amp; make install\n</code></pre> <p>Module files</p> <pre><code>set     topdir          /home1/p001cao/app/tooldev/gsl-2.7\n\nprepend-path    PATH                $topdir/bin\nprepend-path    LD_LIBRARY_PATH     $topdir/lib\nprepend-path    INCLUDE             $topdir/include\n\nprepend-path   PKG_CONFIG_PATH      $topdir/lib/pkgconfig\n</code></pre> See also <p>Install GSL on Linux (Ubuntu, Centros, Redhat, Mac OS) + Simple Installation of gcc Compilers</p>"},{"location":"cluster/compile/Libtool/#zlib","title":"zlib","text":"<pre><code>cd /home1/p001cao/0SourceCode/tooldev\nwget -c --no-check-certificate https://zlib.net/zlib-1.2.12.tar.gz\ntar zxvf zlib-1.2.12.tar.gz\ncd zlib-1.2.12\n\n./configure --enable-shared --prefix=/home1/p001cao/app/tooldev/zlib-1.2.12\nmake -j 16 &amp;&amp; make install\n</code></pre>"},{"location":"cluster/compile/OpenBLAS/","title":"OpenBLAS","text":"<p>OpenBLAS contains BLAS and LAPACK</p>"},{"location":"cluster/compile/OpenBLAS/#tachyon-centos-68","title":"Tachyon - Centos 6.8","text":""},{"location":"cluster/compile/OpenBLAS/#llvm-17-inuse","title":"LLVM 17 (inuse)","text":"<pre><code>cd /home1/p001cao/0SourceCode/tooldev\n# git clone https://github.com/xianyi/OpenBLAS.git openBLAS\ncd openBLAS\ngit pull origin develop\nrm -rf build &amp;&amp; mkdir build &amp;&amp; cd build\n\nmodule load tooldev/cmake-3.27\nmodule load compiler/llvm-17\n\nmyLLVM=/home1/p001cao/app/compiler/llvm-17\nexport PATH=$myLLVM/bin:$PATH\nexport CC=clang export CXX=clang++ export FC=$myGCC/bin/gfortran\nexport LDFLAGS=\"-fuse-ld=lld -lrt\"\nmyPREFIX=/home1/p001cao/app/tooldev/openBLAS0.3.23-clang17\n\ncmake .. -DBUILD_SHARED_LIBS=on -DCMAKE_INSTALL_PREFIX=$myPREFIX\n\nmake -j 16 &amp;&amp; make install\n</code></pre>"},{"location":"cluster/compile/OpenBLAS/#gcc-9","title":"GCC 9","text":"<pre><code>module load tooldev/cmake-3.27\nmodule load compiler/gcc-9.5\n\nmyGCC=/home2/app/compiler/gcc/9.5.0\nexport PATH=$myGCC/bin:$PATH\nexport CC=$myGCC/bin/gcc export CXX=$myGCC/bin/g++ export FC=$myGCC/bin/gfortran\nmyPREFIX=/home1/p001cao/app/tooldev/openBLAS0.3.23-gcc9\n\ncmake .. -DBUILD_SHARED_LIBS=on -DCMAKE_INSTALL_PREFIX=$myPREFIX\n\nmake -j 16 &amp;&amp; make install\n</code></pre>"},{"location":"cluster/compile/OpenMPI_4/","title":"OpenMPI 4","text":"<ul> <li>OpenMPI-4</li> <li>Possible errors</li> <li>1. Download</li> <li>2. Compiling OpenMPI + GCC<ul> <li>USC1: (Cenntos 6.5)</li> <li>InfiniBand cluster</li> <li>no InfiniBand cluster</li> <li>USC2: (Cenntos 6.9)</li> <li>CANlab: (Cenntos 5.8)</li> <li>CAN-GPU: (Ubuntu-18)</li> <li>Install conda</li> <li>compile OpenMPI</li> </ul> </li> <li>3. Compiling OpenMPI + Intel<ul> <li>USC1: (Cenntos 6.5)</li> <li>InfiniBand cluster</li> <li>USC2: (Cenntos 6.9)</li> </ul> </li> <li>4. Make module file</li> <li>OpenMPI-5<ul> <li>USC1: (Cenntos 6.5)</li> <li>USC2 (Cenntos 6.9) GCC</li> <li>USC2(Cenntos 6.9) - Clang</li> </ul> </li> <li>2. Compiling OpenMPI + Clang<ul> <li>USC2(Cenntos 6.9) - OPMI 4</li> <li>Prepare source code</li> <li>Building</li> </ul> </li> </ul>"},{"location":"cluster/compile/OpenMPI_4/#openmpi-4","title":"OpenMPI-4","text":"<p>Open MPI is a Message Passing Interface (MPI) library project combining technologies and resources from several other projects (FT-MPI, LA-MPI, LAM/MPI, and PACX-MPI).</p> <p></p> <p>Note</p> <p>There are 3 ways to use IB in OpenMPI, (let compile with all, and use runtime setting to select)</p> <pre><code>- OpenIB is an very old Infiband implemented in OpenMPI. OpenIB is not maintained and will be remove in OpenMPI-5 [see this](https://github.com/open-mpi/ompi/issues/11755)\n- UCX: newer OpenMPI uses UCX. But some apps may conflict with UCX (e.g., Gpaw)\n- Libfabric: this may a reasonable choice now [libfabric](https://github.com/ofiwg/libfabric) to instead of OpenIB.\n</code></pre> Note <ul> <li>Some applications require C++11, this is only supported on GCC 4.8 or newer, which is not always available on system, then newer GCC need to be installed before compiling Openmpi.</li> <li>Make sure to build OpenMPI with 64-bit support. To check whether the currently available OpenMPI do support 64-bit or not, type this:   `ompi_info -a | grep 'Fort integer size'. If the output is 8, then it supports 64-bit. If output is 4, then it just supports 32-bit.* configuration for 64-bit support:</li> <li>For Intel compilers use: <code>FFLAGS=-i8 FCFLAGS=-i8 CFLAGS=-m64 CXXFLAGS=-m64</code></li> <li>For GNU compilers type: `FFLAGS=\"-m64 -fdefault-integer-8\" FCFLAGS=\"-m64 -fdefault-integer-8\" CFLAGS=-m64 CXXFLAGS=-m64'</li> <li>must keep the source after compiling</li> <li>consider to use UCX</li> <li>consider compile your own PMIX.</li> <li>consider using linker</li> <li> <p>lld linker:     <pre><code>module load llvm/llvm-gcc10-lld                   # to use lld\nLDFLAGS=\"-fuse-ld=lld -lrt\"\n</code></pre></p> </li> <li> <p>gold linker:     <pre><code>module load tool_dev/binutils-2.32\nLDFLAGS=\"-fuse-ld=gold -lrt\"\n</code></pre></p> </li> </ul>"},{"location":"cluster/compile/OpenMPI_4/#possible-errors","title":"Possible errors","text":"<ul> <li>OpenMPI-4 use UCX by default (openMPI 4.0,3 \u2192 ucx-1.7 or older). Solution: compile your own UCX.</li> <li>No components were able to be opened in the pml framework. <code>PML ucx cannot be selected</code>. This error may be due to no IB device, check it</li> </ul> <pre><code>ssh com054\nibv_devinfo\n</code></pre> <ul> <li>counter exceeded may be solved by compile openMPI with your own PMIX.</li> </ul>"},{"location":"cluster/compile/OpenMPI_4/#1-download","title":"1. Download","text":"<p>See what new in openMPI-4</p> <p>download OpenMPI-4</p> <pre><code>tar xvf openmpi-4.1.3rc1.tar.gz\ncd openmpi-4.1.3rc1\n</code></pre>"},{"location":"cluster/compile/OpenMPI_4/#2-compiling-openmpi-gcc","title":"2. Compiling OpenMPI + GCC","text":"<p>Need separated installations for: eagle, lion/leopard, cheetah, taycheon  Installation OPTIONS in README.txt or <code>./configure -h</code></p> <ul> <li>Sun Grid: <code>--with-sge</code></li> <li>InfiniBand: <code>--with-verbs</code></li> <li>with KNEM: <code>--with-knem=path</code></li> <li>use UCX: <code>--with-ucx=path</code></li> </ul> <pre><code>export myUCX=/uhome/p001cao/app/tool_dev/ucx-1.9\n../configure...  --with-ucx=${myUCX}\n</code></pre>"},{"location":"cluster/compile/OpenMPI_4/#usc1-cenntos-65","title":"USC1: (Cenntos 6.5)","text":"<pre><code>- should use gold-linker to avoid compiling error\n- UCX cause error: ib_md.c:329  UCX  ERROR ibv_reg_mr(address=0x145cb580, length=263504, access=0xf) failed: Resource temporarily unavailable. So dont use UCX on this server.\n</code></pre> <pre><code>module load tool_dev/binutils-2.36                       # gold, should use to avoid link-error\nmodule load compiler/gcc-11.2\nexport myKNEM=/uhome/p001cao/app/tool_dev/knem-1.1.4\n</code></pre>"},{"location":"cluster/compile/OpenMPI_4/#infiniband-cluster","title":"InfiniBand cluster","text":"<pre><code>cd openmpi-4.1.1\nmkdir build_eagle &amp;&amp; cd build_eagle\n\n../configure CC=gcc CXX=g++ FC=gfortran F77=gfortran LDFLAGS=\"-fuse-ld=gold -lrt\" \\\n--with-sge --without-ucx --with-verbs --with-knem=${myKNEM} \\\n--prefix=/uhome/p001cao/app/openmpi/4.1.1-gcc11.2-noUCX-eagle\n</code></pre>"},{"location":"cluster/compile/OpenMPI_4/#no-infiniband-cluster","title":"no InfiniBand cluster","text":"<pre><code>cd openmpi-4.1.1\nmkdir build_lion &amp;&amp; cd build_lion\n../configure CC=gcc CXX=g++ FC=gfortran F77=gfortran LDFLAGS=\"-fuse-ld=gold -lrt\" \\\n--with-sge --without-ucx --without-verbs --with-knem=${myKNEM} \\\n--prefix=/uhome/p001cao/app/openmpi/4.1.1-gcc11.2-noUCX-lion\n</code></pre> <pre><code>make  -j 20         # not use -j to know what error\nmake install\n</code></pre>"},{"location":"cluster/compile/OpenMPI_4/#canlab-cenntos-58","title":"CANlab: (Cenntos 5.8)","text":"<pre><code>module load gcc/gcc-7.4.0\n\n../configure CC=gcc CXX=g++ FC=gfortran F77=gfortran \\\n--with-sge --without-verbs --without-ucx  \\\n--prefix=/home/thang/app/openmpi/4.0.2-gcc7.4.0\n</code></pre>"},{"location":"cluster/compile/OpenMPI_4/#can-gpu-ubuntu-18","title":"CAN-GPU: (Ubuntu-18)","text":"<pre><code>- install Cuda ussing GCC\n- cuda-10 only support to gcc-8\n- need binutils 2.22 or newer to link cuda\n</code></pre>"},{"location":"cluster/compile/OpenMPI_4/#install-conda","title":"Install conda","text":"<ul> <li>CLI install Cuda</li> <li>Download:  <code>wget http://developer.download.nvidia.com/compute/cuda/10.2/Prod/local_installers/cuda_10.2.89_440.33.01_rhel6.run</code></li> <li>Install (using Root acc)</li> <li>disable the graphical target, to update Nvidia driver</li> </ul> <pre><code>systemctl isolate multi-user.target\nmodprobe -r nvidia-drm\n</code></pre> <pre><code>module load compiler/gcc-7.4\nsh cuda_10.2.89_440.33.01_rhel6.run --toolkitpath=/home/thang/app/cuda-10.2\n</code></pre> <ol> <li>after install Cuda, start the graphical environment again</li> </ol> <pre><code>systemctl start graphical.target\n</code></pre>"},{"location":"cluster/compile/OpenMPI_4/#compile-openmpi","title":"compile OpenMPI","text":"<pre><code>cd openmpi-4.1.1\nmkdir build &amp;&amp; cd build\n\nmodule load compiler/gcc-7.4   # cuda-10 only support to gcc-8\nmodule load binutils-2.35\n\n../configure CC=gcc CXX=g++ FC=gfortran F77=gfortran \\\n--with-sge --without-ucx \\\n--with-cuda=/home/thang/app/cuda-10.2 \\\n--prefix=/home/thang/app/openmpi/4.1.1-gcc7.4-cuda\n</code></pre>"},{"location":"cluster/compile/OpenMPI_4/#3-compiling-openmpi-intel","title":"3. Compiling OpenMPI + Intel","text":""},{"location":"cluster/compile/OpenMPI_4/#usc1-cenntos-65_1","title":"USC1: (Cenntos 6.5)","text":""},{"location":"cluster/compile/OpenMPI_4/#infiniband-cluster_1","title":"InfiniBand cluster","text":"<pre><code>cd openmpi-4.1.1\nmkdir build_eagle &amp;&amp; cd build_eagle\n</code></pre> <pre><code>module load intel/compiler-xe19u5\nmodule load compiler/gcc/9.1.0\n# check: icpc -v\nexport PATH=/home1/p001cao/app/intel/xe19u5/compilers_and_libraries_2019.5.281/linux/bin/intel64:$PATH\nexport CC=icc  export CXX=icpc  export FORTRAN=ifort\n\n../configure CC=icc CXX=icpc FC=ifort F77=ifort \\\n--with-sge --without-ucx --with-verbs --with-knem=${myKNEM} \\\n--prefix=/uhome/p001cao/app/openmpi/4.1.1-intelxe19u5-noUCX-eagle\n</code></pre>"},{"location":"cluster/compile/OpenMPI_4/#usc2-cenntos-69","title":"USC2: (Cenntos 6.9)","text":"<pre><code># use linker lld (include in Intel-bin, require GLIBC &gt;2.15)\nmodule load compiler/gcc-10.1.0\nmodule load intel/compiler-xe19u5       # lld\n##\nexport PATH=/home1/p001cao/app/intel/xe19u5/compilers_and_libraries_2019.5.281/linux/bin/intel64:$PATH\nexport CC=icc  export CXX=icpc  export FORTRAN=ifort\nexport myUCX=/home1/p001cao/app/tool_dev/ucx-1.8-intel\n\n../configure CC=icc CXX=icpc FC=ifort F77=ifort LDFLAGS=\"-fuse-ld=lld -lrt\" \\\n--with-sge --without-verbs --with-ucx=${myUCX} \\\n--prefix=/home1/p001cao/app/openmpi/4.0.4-intelxe19u5\n</code></pre>"},{"location":"cluster/compile/OpenMPI_4/#4-make-module-file","title":"4. Make module file","text":"<p>at directory: /uhome/p001cao/local/share/lmodfiles/mpi\u2192 create file \"ompi4.1.1-gcc11.2-noUCX\"</p> <pre><code># for Tcl script use only\nmodule load compiler/gcc-11.2\nmodule load tool_dev/binutils-2.37\n\nset     topdir          /uhome/p001cao/app/openmpi/4.1.1-gcc11.2-noUCX-eagle\n\nprepend-path   PATH                $topdir/bin\nprepend-path   LD_LIBRARY_PATH     $topdir/lib\nprepend-path   INCLUDE             $topdir/include\n\nprepend-path   PKG_CONFIG_PATH     $topdir/lib/pkgconfig          # this is required\n</code></pre> <p>Check:</p> <pre><code>module load ompi4.1.1-gcc11.2-noUCX\nmpic++ -v\n</code></pre>"},{"location":"cluster/compile/OpenMPI_4/#usc2cenntos-69","title":"USC2(Cenntos 6.9)","text":"<p>Note</p> <ul> <li>Now, compile with all IB options, and select them by runtime parameters. (not work, should exclude UCX)</li> <li>How to build from source code see here</li> <li><code>--with-verbs</code> (default - auto detect)</li> <li><code>./autogen.pl</code> is the same as <code>./autogen.sh</code></li> </ul> <pre><code># cd /home1/p001cao/0SourceCode\n# wget https://github.com/open-mpi/ompi/releases/tag/v4.1.4/ompi-4.1.4.tar.gz\n# tar xvf openmpi-4.1.4.tar.gz\n# cd openmpi-4.1.4\n</code></pre> <pre><code>cd /home1/p001cao/0SourceCode\n# wget https://github.com/open-mpi/ompi/releases/download/v4.1.5/ompi-4.1.5.tar.gz\n# git clone -b v4.1.x https://github.com/open-mpi/ompi.git  ompi-4.1.x\ncd ompi-4.1.x\ngit pull origin v4.1.x\n\nmodule load tooldev/autoconf-2.72c\nmodule load tooldev/automake-1.16.5\nmodule load tooldev/libtool-2.4.7\nexport ACLOCAL_PATH=/home1/p001cao/app/tooldev/libtool-2.4.7/share/aclocal\n\n./autogen.pl\n</code></pre>"},{"location":"cluster/compile/OpenMPI_4/#using-llvm","title":"Using LLVM","text":"Note <ul> <li>To use clang libc++, use this link <code>export CPPFLAGS=\"-nodefaultlibs -lc++ -lc++abi -lm -lc -lgcc_s -lgcc\"</code>. But might not be used?</li> <li>with <code>FC=flang-new</code>, To solve <code>error: unknown argument: '-soname'</code> \u2192 see this</li> </ul> <pre><code>rm -rf build_llvm &amp;&amp; mkdir build_llvm &amp;&amp; cd build_llvm\n\nmodule load compiler/llvm-17          # clang + lld\nmodule load tooldev/ucx1.15-clang17\n\nmyLLVM=/home1/p001cao/app/compiler/llvm-17\nexport PATH=$myLLVM/bin:$PATH\nexport CC=clang CXX=clang++ FC=gfortran        # flang-new\nexport LDFLAGS=\"-fuse-ld=lld -lrt\"\nmyUCX=/home1/p001cao/app/tooldev/ucx1.15-clang17\nOFI=/home1/p001cao/app/tooldev/libfabric-1.19\nKNEM=/home1/p001cao/app/tooldev/knem-1.1.4\nmyPREFIX=/home1/p001cao/app/mpi/openmpi4.1.x-clang17\n\n../configure --with-sge --with-verbs --with-ucx=${myUCX} --with-knem=${KNEM} --with-ofi=${OFI} --prefix=${myPREFIX}\n\nmake  -j 16 &amp;&amp; make install\n</code></pre> <p>Test: <pre><code>mpicc ../examples/hello_c.c -o ../examples/hello_c.exe\nmpirun -np 2 ../examples/hello_c.exe\n</code></pre></p> <pre><code>module load mpi/ompi4.1.x-clang17\nmpirun --version\nompi_info\n</code></pre> <p>Other options <pre><code>export my_PMIX=/home1/p001cao/app/tool_dev/pmix-4.1.2\nexport my_libevent=/home1/p001cao/app/tool_dev/libevent-2.1.11       # require by PMIX\nexport my_hwloc=/home1/p001cao/app/tool_dev/hwloc-2.8.0\n\n--with-pmix=${my_PMIX} --with-libevent=${my_libevent} --with-hwloc=${my_hwloc}\n</code></pre></p>"},{"location":"cluster/compile/OpenMPI_4/#llvm-no-ucx","title":"LLVM no UCX","text":"<pre><code>rm -rf build_noUCX &amp;&amp; mkdir build_noUCX &amp;&amp; cd build_noUCX\n\nmodule load compiler/llvm-17          # clang + lld\n\nmyLLVM=/home1/p001cao/app/compiler/llvm-17\nexport PATH=$myLLVM/bin:$PATH\nexport CC=clang CXX=clang++ FC=gfortran        # flang-new\nexport LDFLAGS=\"-fuse-ld=lld -lrt\"\nOFI=/home1/p001cao/app/tooldev/libfabric-1.19\nKNEM=/home1/p001cao/app/tooldev/knem-1.1.4\nmyPREFIX=/home1/p001cao/app/mpi/openmpi4.1.x-clang17-noUCX\n\n../configure --with-sge --with-verbs --without-ucx --with-knem=${KNEM} --with-ofi=${OFI} --prefix=${myPREFIX}\n\nmake  -j 16 &amp;&amp; make install\n</code></pre>"},{"location":"cluster/compile/OpenMPI_4/#gcc-11","title":"GCC 11","text":"<pre><code>cd /home1/p001cao/0SourceCode\ncd ompi-4.1.x\nrm -rf build_ase &amp;&amp; mkdir build_ase &amp;&amp; cd build_ase\n\nmodule load compiler/gcc-11\nmyGCC=/home1/p001cao/app/compiler/gcc-11\nexport PATH=$myGCC/bin:$PATH\nexport CFLAGS=\"-gdwarf-2 -gstrict-dwarf\"\nmyUCX=/home1/p001cao/app/tooldev/ucx-1.15-gcc\nmyPREFIX=/home1/p001cao/app/mpi/openmpi4.1.x-gcc11\n\n../configure --with-sge --without-verbs --with-ucx=${myUCX} --prefix=${myPREFIX}\n\nmake -j 16 &amp;&amp; make install\n</code></pre> <p>Test <pre><code>module load mpi/ompi4.1.x-gcc11\nmpirun --version\n</code></pre></p>"},{"location":"cluster/compile/OpenMPI_4/#gcc-9","title":"GCC 9","text":"<pre><code>cd /home1/p001cao/0SourceCode\ncd ompi-4.1.5\nrm -rf build_gcc &amp;&amp; mkdir build_gcc &amp;&amp; cd build_gcc\n\nmodule load compiler/gcc-9.5\nmyGCC=/home2/app/compiler/gcc/9.5.0\nexport PATH=$myGCC/bin:$PATH\nmyUCX=/home1/p001cao/app/tooldev/ucx1.15-gcc9\nmyPREFIX=/home1/p001cao/app/openmpi/4.1.5-gcc9\n\n../configure --with-sge --without-verbs --with-ucx=${myUCX} --prefix=${myPREFIX}\n\nmake -j 16 &amp;&amp; make install\n</code></pre>"},{"location":"cluster/compile/OpenMPI_4/#some-optional-packages","title":"Some optional packages","text":""},{"location":"cluster/compile/OpenMPI_4/#2-libnuma-devel","title":"2. libnuma-devel","text":"<p>https://github.com/numactl/numactl</p> <pre><code>cd /home1/p001cao/0SourceCode/tooldev\ntar xzf numactl-2.0.13.tar.gz\ncd numactl-2.0.13\n\nmodule load tooldev/autoconf-2.72c\n./autogen.sh\n\nrm -rf build &amp;&amp; mkdir build &amp;&amp; cd build\n../configure --prefix=/home1/p001cao/app/tooldev/numactl-2.0.13\n</code></pre>"},{"location":"cluster/compile/OpenMPI_4/#2-libudev","title":"2. libudev","text":"<p>NOTE: remove <code>-Wpedantic</code> in <code>Makefile</code> <pre><code>cd /home1/p001cao/0SourceCode/tooldev\ngit clone https://github.com/illiliti/libudev-zero.git\ncd libudev-zero\n\nmake PREFIX=/home1/p001cao/app/tooldev/libudev-zero install\n</code></pre></p>"},{"location":"cluster/compile/OpenMPI_4/#3-openmpiucx-libfabric","title":"3. openMPI/UCX: libfabric ()","text":"<p>If building directly from the libfabric git tree, run './autogen.sh' before the configure step.</p> <pre><code># wget https://github.com/ofiwg/libfabric/releases/tag/v1.19.0/libfabric-1.19.0.tar.bz2\n\ncd /home1/p001cao/0SourceCode/tooldev\ngit clone -b main https://github.com/ofiwg/libfabric\ncd libfabric\ngit pull origin main\n\nmodule load tooldev/autoconf-2.72c\n./autogen.sh\n</code></pre> <pre><code>module load compiler/llvm-17\n\n./configure --enable-ucx=no --prefix=/home1/p001cao/app/tooldev/libfabric-1.19\nmake -j 16 &amp;&amp; make install\n\n## module\nprepend-path PKG_CONFIG_PATH $topdir/lib/pkgconfig\n</code></pre>"},{"location":"cluster/compile/OpenMPI_4/#4-openmpiucx-knem","title":"4. openMPI/UCX: KNEM","text":"<p>Dont use new compiler.</p> <p>https://knem.gitlabpages.inria.fr/</p> <pre><code>tar zxvf knem-1.1.4.tar.gz\ncd knem-1.1.4\n./configure --prefix=/home1/p001cao/app/tooldev/knem-1.1.4\n</code></pre>"},{"location":"cluster/compile/OpenMPI_4/#5-openmpiucx-xpmem","title":"5. openMPI/UCX: XPMEM","text":"<p>https://github.com/hjelmn/xpmem/releases/tag/v2.6.3</p> <p>https://github.com/hjelmn/xpmem/wiki/Installing-XPMEM \u2192 cannot install: require linux kernel 4.x</p> <pre><code>check: uname -a\n</code></pre> <pre><code>tar zxvf xpmem-2.6.3.tar.gz\ncd xpmem-2.6.3\n\n./configure --prefix=/home1/p001cao/app/tooldev/xpmem-2.6.2\n</code></pre>"},{"location":"cluster/compile/OpenMPI_5/","title":"OpenMPI-5","text":"<ul> <li>There is no <code>--with-verb</code> anymore. And openib BTL is remove in this version, so InfiniBand must use \"ucx PML\". See more</li> <li>May use UCX with OMPI-5 and do not need seperate installation for Eagle, Lion?</li> <li>May not be used with UCX-1.11</li> <li>See news in 5.x here</li> <li>Use UCX or Libfabric for IB. (Libfabric may use a lot of memory, so may lead to memory problem)</li> <li>UCX + OMPI4 may cause <code>address not mapped</code> error with GPAW.</li> </ul>"},{"location":"cluster/compile/OpenMPI_5/#usc1-cenntos-65","title":"USC1: (Cenntos 6.5)","text":"<pre><code>module load tool_dev/binutils-2.36                       # gold, should use to avoid link-error\nmodule load compiler/gcc-11.2\nexport myUCX=/uhome/p001cao/app/tool_dev/ucx-1.11\n</code></pre> <pre><code>cd openmpi-5.0.0\nmkdir build_eagle &amp;&amp; cd build_eagle\n\n../configure CC=gcc CXX=g++ FC=gfortran F77=gfortran LDFLAGS=\"-fuse-ld=gold -lrt\" \\\n--with-sge --with-ucx=${myUCX}  \\\n--prefix=/uhome/p001cao/app/openmpi/5.0.0-gcc11.2-eagle\n</code></pre>"},{"location":"cluster/compile/OpenMPI_5/#tachyon-cenntos-69","title":"Tachyon - Cenntos 6.9","text":""},{"location":"cluster/compile/OpenMPI_5/#using-llvm","title":"Using LLVM","text":"<ul> <li>With version <code>5.0.0rc12</code>, compiling fails with error <code>ld.lld: error: unable to find library -lnuma</code> and <code>-ludev</code>. This mean the current version of <code>libudev</code> no longer work. Tried install install them</li> <li>create link : <code>ln -sf $UDEVlib/libudev.a $myLLVM/lib/libudev.so.0</code></li> <li><code>libudev</code> error can solve by <code>--without-hcoll</code> as discuss here</li> <li><code>prrte</code> docs error, to disable build docs, delete <code>docs</code> in <code>SUBDIRS</code> of <code>/home1/p001cao/0SourceCode/ompi-5.0.x/3rd-party/prrte/Makefile.in</code> see this -&gt; not work. Solve by manually create files in subfolder 3<sup>rd</sup>-party \u2192 copy from folder <code>0SourceCode/ompi-5.0.x/3rd-party/prrte/src/docs/show-help-files</code> and rename .rst to .txt (or create empty files) files: <code>help-prte.txt, help-prted.txt, help-prterun.txt, help-prun.txt, help-pterm.txt</code> in folder <code>.../build_clang/3rd-party/prrte/src/docs/show-help-files/_build/text</code>. Then make install</li> </ul> <pre><code>cd /home1/p001cao/0SourceCode\n# git clone --recursive  -b v5.0.x --recursive https://github.com/open-mpi/ompi.git  ompi-5.0.x\ncd ompi-5.0.x\ngit pull origin v5.0.x\ngit submodule update --recursive\n\nmodule load tooldev/autoconf-2.72c\nmodule load tooldev/automake-1.16.5\nmodule load tooldev/libtool-2.4.7\nexport ACLOCAL_PATH=/home1/p001cao/app/tooldev/libtool-2.4.7/share/aclocal\n\n./autogen.pl\n</code></pre> <pre><code>rm -rf build_clang &amp;&amp; mkdir build_clang &amp;&amp; cd build_clang\n\nmodule load compiler/llvm-17          # clang + lld\nmodule load tooldev/libudev\n\nmyLLVM=/home1/p001cao/app/compiler/llvm-17\nexport PATH=$myLLVM/bin:$PATH\nexport CC=clang CXX=clang++ FC=gfortran        # flang-new\nexport LDFLAGS=\"-fuse-ld=lld -lrt\"\nNUMAlib=/home1/p001cao/app/tooldev/numactl-2.0.13/lib\nUDEVlib=/home1/p001cao/app/tooldev/libudev-zero/lib\nexport LD_LIBRARY_PATH=$myLLVM/lib:$NUMAlib:$UDEVlib:$LD_LIBRARY_PATH\nmyUCX=/home1/p001cao/app/tooldev/ucx1.15-clang17\nKNEM=/opt/knem-1.1.3.90mlnx1                 # /home1/p001cao/app/tooldev/knem-1.1.4\nOFI=/home1/p001cao/app/tooldev/libfabric-1.19\nmyPREFIX=/home1/p001cao/app/mpi/openmpi5.0.x-clang17\n\n../configure --with-sge --with-ucx=${myUCX} --with-knem=${KNEM} --with-ofi=${OFI} \\\n    --without-hcoll --enable-mpi1-compatibility --prefix=${myPREFIX}\n\nmake -j 16 &amp;&amp; make install\n</code></pre>"},{"location":"cluster/compile/OpenMPI_5/#llvm-no-ucx","title":"LLVM no UCX","text":"<pre><code>rm -rf build_noUCX &amp;&amp; mkdir build_noUCX &amp;&amp; cd build_noUCX\n\nmodule load compiler/llvm-17          # clang + lld\nmodule load tooldev/libudev\n\nmyLLVM=/home1/p001cao/app/compiler/llvm-17\nexport PATH=$myLLVM/bin:$PATH\nexport CC=clang CXX=clang++ FC=gfortran        # flang-new\nexport LDFLAGS=\"-fuse-ld=lld -lrt\"\nNUMAlib=/home1/p001cao/app/tooldev/numactl-2.0.13/lib\nUDEVlib=/home1/p001cao/app/tooldev/libudev-zero/lib\nexport LD_LIBRARY_PATH=$myLLVM/lib:$NUMAlib:$UDEVlib:$LD_LIBRARY_PATH\nKNEM=/opt/knem-1.1.3.90mlnx1                 # /home1/p001cao/app/tooldev/knem-1.1.4\nOFI=/home1/p001cao/app/tooldev/libfabric-1.19\nmyPREFIX=/home1/p001cao/app/mpi/openmpi5.0.x-clang17-noUCX\n\n../configure --with-sge --without-ucx --with-knem=${KNEM} --with-ofi=${OFI} \\\n    --without-hcoll --enable-mpi1-compatibility --prefix=${myPREFIX}\n\nmake -j 16 &amp;&amp; make install\n</code></pre>"},{"location":"cluster/compile/OpenMPI_conda/","title":"Openmpi in Conda","text":"<pre><code>- Use conda to manage all necessary libs in Linux.\n- However, this way cannot use openmpi with clang. So install clang in conda and use clang to compile openmpi\n- Python &gt; 3.7.12 require to update GCC-conda=11\n`conda install -c conda-forge libstdcxx-ng=11 libgcc-ng=11 libgfortran-ng=11`. But dont use this to void requiring higher GLIBC. Also, `zlib=1.2.12` require GLIBC=2.14. So that to void these errors, use `conda install -c conda-forge libstdcxx-ng=10 libgcc-ng=10 libgfortran-ng=10 zlib=1.2.11 python=3.7.12`\n</code></pre>"},{"location":"cluster/compile/OpenMPI_conda/#usc2-tachyon-centos-69","title":"USC2 Tachyon (centos 6.9)","text":""},{"location":"cluster/compile/OpenMPI_conda/#install-conda","title":"Install conda","text":"<pre><code>Consider Miniconda for light, and reduce error\n</code></pre> <p>Download Anaconda installer for Linux</p> <pre><code>cd /uhome/p001cao/local/W_Source_Code\nwget https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh\n\nmodule load compiler/gcc-11.2\nexport PATH=/uhome/p001cao/local/app/compiler/gcc-11.2/bin:$PATH\nexport CC=gcc  export CXX=g++  export FC=gfortran\n\nbash Miniconda3-py37_4.9.2-Linux-x86_64.sh -u\n\nchoose folder to install:   /home1/p001cao/local/app/miniconda3\nrunning conda init?  NO\n... finish\n</code></pre>"},{"location":"cluster/compile/OpenMPI_conda/#module-file","title":"Module file","text":"<ul> <li>Conda module: create file into folder  /uhome/p001cao/local/share/lmodfiles/conda/conda3</li> </ul> <pre><code>set     topdir          /uhome/p001cao/local/miniconda3\nprepend-path    PATH                    $topdir/bin\nprepend-path    LD_LIBRARY_PATH         $topdir/lib\nprepend-path    INCLUDE                 $topdir/include\n</code></pre> <ul> <li>module file for Python Environments https://manjusri.ucsc.edu/2017/09/08/environment-modules/ create 2 evironments: python37, python27</li> </ul> <pre><code>module load conda/conda3\nconda create -n py37llvm python=3.7.5\n</code></pre> <p>create module files for environments, create file into folder  /uhome/p001cao/local/share/lmodfiles/conda/py37llvm</p> <pre><code>set     topdir          /uhome/p001cao/local/Miniconda3/envs/py37ompi\nprepend-path    PATH                    $topdir/bin\nprepend-path    LD_LIBRARY_PATH         $topdir/lib\nprepend-path    INCLUDE                 $topdir/include\n</code></pre>"},{"location":"cluster/compile/OpenMPI_conda/#install-libraries","title":"Install libraries","text":"<p>Don't install ompi</p> <pre><code>module load conda/conda3\nsource activate py37llvm\n\nconda install -c asmeurer glibc       # may error\nconda install -c conda-forge cmake libstdcxx-ng=10 libgcc-ng=10 libgfortran-ng=10 zlib=1.2.11 python=3.7.12\n</code></pre> <p>1.LLVM</p> <pre><code>conda install -c conda-forge llvm clang flang libclang lld llvm-openmp llvm-tools\n</code></pre> <p>2.ucx</p> <pre><code>conda install -c conda-forge ucx\n</code></pre>"},{"location":"cluster/compile/OpenMPI_conda/#openmpi","title":"OpenMPI","text":""},{"location":"cluster/compile/OpenMPI_conda/#lammps","title":"Lammps","text":"<pre><code>git pull origin develop\nmkdir build_LLVM &amp;&amp; cd build_LLVM\n\nmodule load tool_dev/binutils-2.37\nmodule load tool_dev/cmake-3.20.3\nmodule load fftw/fftw3.3.10-ompi4.1.4-clang14\nmodule load mpi/ompi4.1.4-clang14\n\nexport myCOMPILER=/home1/p001cao/local/app/compiler/llvm-14\nexport PATH=$PATH:${myCOMPILER}/bin\nexport CC=mpicc  export CXX=mpic++  export FC=mpifort\nexport LDFLAGS=\"-fuse-ld=lld -lrt\"\n## python (require py3) &amp; BLAS+LAPACK\nexport pyROOT=/home1/p001cao/local/app/miniconda3/envs/py37Lammps\n\ncmake ../cmake -C ../cmake/presets/all_on.cmake \\\n-DPython_ROOT_DIR=${pyROOT} \\\n-DBUILD_MPI=yes -DBUILD_OMP=yes -DPKG_OPENMP=yes -DLAMMPS_MACHINE=mpi -DBUILD_SHARED_LIBS=no \\\n-DPKG_GPU=no -DPKG_KOKKOS=no -DPKG_INTEL=no -DPKG_MDI=no \\\n-DPKG_SCAFACOS=no -DPKG_ADIOS=no -DPKG_NETCDF=no -DPKG_VTK=no -DPKG_H5MD=no \\\n-DPKG_MESONT=no -DPKG_LATTE=no -DPKG_MSCG=no -DPKG_ATC=no -DPKG_KIM=no \\\n-DPKG_PLUMED=yes -DPKG_ML-PACE=yes -DPKG_ML-QUIP=no -DPKG_ML-HDNNP=no  \\\n-DFFT=FFTW3 \\\n-DCMAKE_INSTALL_PREFIX=/home1/p001cao/local/app/lammps/llvmOMPI4-dev\n\nmake -j 16 &amp;&amp; make install\n</code></pre>"},{"location":"cluster/compile/OpenMPI_conda/#ref","title":"Ref","text":"<p>Update GLIBC: https://gist.github.com/michaelchughes/85287f1c6f6440c060c3d86b4e7d764b</p>"},{"location":"cluster/compile/OpenMPI_windows/","title":"MPICH2 on Windows","text":""},{"location":"cluster/compile/OpenMPI_windows/#mpich2","title":"MPICH2","text":"<ul> <li>Step1: Download and install mpich2-1.4.1p1-win-x86-64.msi</li> <li>Step2: download and install Microsoft MPI v10.1, install msmpisetup.exe</li> <li>check: <pre><code>mpiexec -help\n</code></pre></li> </ul>"},{"location":"cluster/compile/PMIX/","title":"PMIX","text":"<pre><code>require libevent and hwloc\n</code></pre>"},{"location":"cluster/compile/PMIX/#compile-libevent","title":"Compile libevent","text":"<pre><code>tar xvf libevent-2.1.11-stable.tar.gz\ncd libevent-2.1.11-stable\nmkdir build &amp;&amp; cd build\n\nmodule load compiler/llvm-14          # clang + lld\n\nexport myCOMPILER=/home1/p001cao/local/app/compiler/llvm-14\nexport PATH=$PATH:${myCOMPILER}/bin\nexport CC=clang export CXX=clang++ export FC=flang\nexport LDFLAGS=\"-fuse-ld=lld -lrt\"\n\n./configure --prefix=/home1/p001cao/local/app/tool_dev/libevent-2.1.11\n\nmake -j 16 &amp;&amp; make install\n</code></pre>"},{"location":"cluster/compile/PMIX/#compile-hwloc","title":"Compile hwloc","text":"<p>Download</p> <pre><code>tar xvf hwloc-2.8.0.tar.gz\ncd hwloc-2.8.0\nmkdir build &amp;&amp; cd build\n\nmodule load compiler/llvm-14          # clang + lld\n\nexport myCOMPILER=/home1/p001cao/local/app/compiler/llvm-14\nexport PATH=$PATH:${myCOMPILER}/bin\nexport CC=clang export CXX=clang++ export FC=flang\nexport LDFLAGS=\"-fuse-ld=lld -lrt\"\n\n../configure --prefix=/home1/p001cao/local/app/tool_dev/hwloc-2.8.0\n\nmake -j 16 &amp;&amp; make install\n</code></pre>"},{"location":"cluster/compile/PMIX/#compile-pmix","title":"compile PMIX","text":"<pre><code>tar xvf pmix-4.1.2.tar.gz\ncd pmix-4.1.2\nmkdir build &amp;&amp; cd build\n\nmodule load compiler/llvm-14          # clang + lld\n\nexport myCOMPILER=/home1/p001cao/local/app/compiler/llvm-14\nexport PATH=$PATH:${myCOMPILER}/bin\nexport CC=clang export CXX=clang++ export FC=flang\nexport LDFLAGS=\"-fuse-ld=lld -lrt\"\nexport my_libevent=/home1/p001cao/local/app/tool_dev/libevent-2.1.11\nexport my_hwloc=/home1/p001cao/local/app/tool_dev/hwloc-2.8.0\n\n../configure --with-libevent=${my_libevent} --with-hwloc=${my_hwloc} \\\n--prefix=/home1/p001cao/local/app/tool_dev/pmix-4.1.2\n\nmake -j 16 &amp;&amp; make install\n</code></pre> <p>Refs: \\ https://openpmix.github.io/code/building-the-pmix-reference-server \\</p>"},{"location":"cluster/compile/Plumed/","title":"Compile PLUMED","text":"<p>PLUMED 2.4 requires a compiler that supports C++11, and needs one of the following - gcc 4.8.1      (need to install GCC) - clang 3.3 - intel 15        (need to install Intel)</p> <p>Intel alone does not fully support C++11 if the environment is without gcc 4.8 or newer. Installing an external GCC is a solution for this, but this may cause some errors when running Plumed due to cross-compiling.</p> <p>Note</p> <ul> <li>Making lepton library faster <code>--enable-asmjit</code></li> </ul>"},{"location":"cluster/compile/Plumed/#dowload","title":"Dowload","text":"<ul> <li>github</li> </ul> <pre><code>https://github.com/plumed/plumed2/releases/tag/v2.5.2\ntar xvzf plumed2-2.5.2.tar.gz\n</code></pre>"},{"location":"cluster/compile/Plumed/#download-branch-v25","title":"download branch v2.5","text":"<p>git clone https://github.com/plumed/plumed2.git --branch=v2.5   plumed2-2.5.x cd plumed2-2.5.x git pull origin v2.5                           # or    git checkout v2.5</p>"},{"location":"cluster/compile/Plumed/#download-branch-with-pycv","title":"download branch with PYCV","text":"<p>git clone --branch v2.6-pycv-devel  https://github.com/giorginolab/plumed2-pycv.git   plumed2-2.6pycv cd    plumed2-2.6pycv</p>"},{"location":"cluster/compile/Plumed/#download-branch-hack-the-tree","title":"download branch hack-the-tree","text":"<p>git clone   --branch hack-the-tree    https://github.com/plumed/plumed2.git    plumed2-2.7htt cd plumed2-2.7htt git pull origin hack-the-tree</p> <p>git pull origin master</p>"},{"location":"cluster/compile/Plumed/#or-clone-a-specific-tag-name-using-git-clone-httpsgit-scmcomdocsgit-clone","title":"or Clone a specific tag name using git clone: https://git-scm.com/docs/git-clone","text":"<p>git clone  --branch= I. OMPI + Intel 1. USC1 module load mpi/openmpi4.0.2-Intel2019xe module load intel/mkl-2019xe <p>check:  mpiicpc  -v                      (intel C++)             mpicxx --version             ( gcc C++)</p> <p>Notes: openMPI must be compile with gcc 4.8 or newer (load gcc/gcc-7.4.0 when compile openMPI)</p>"},{"location":"cluster/compile/Plumed/#install-plumed","title":"Install PLUMED","text":"<p>(to compile with mpi-enable, need to use compiler: CXX=mpic++   CC=mpicc) chose modules to install: https://www.plumed.org/doc-v2.5/user-doc/html/mymodules.html enable/disable modules: ./configure --enable-modules=+crystallization-colvar ./configure --enable-modules=all:-colvar-multicolvar BLAS and LAPACK Libs a. separate compile Blas &amp; Lapack b. use Blas &amp; Lapack from intel_mkl LIBS=\"-mkl\" c. or use internal link: (blas &amp; lapack is automatically built, need FORTRAN compiler) --disable-external-blas --disable-external-lapack \\</p> <p>VMD trajectory plugins https://www.plumed.org/doc-master/user-doc/html/_installation.html</p>"},{"location":"cluster/compile/Plumed/#configuring-plumed","title":"Configuring PLUMED","text":"<p>./configure --prefix=/uhome/p001cao/local/app/plumed2/2.6htt \\ CXX=mpic++ LIBS=\"-mkl\" \\ --enable-openmp --enable-modules=all --enable-asmjit</p>"},{"location":"cluster/compile/Plumed/#or","title":"or","text":"<p>./configure --prefix=/uhome/p001cao/local/app/plumed2/2.6 \\ CXX=mpic++ --disable-external-blas --disable-external-lapack \\ --enable-openmp --enable-modules=all --enable-asmjit</p>"},{"location":"cluster/compile/Plumed/#create-module-file-test","title":"create Module file + test","text":"<p>prepend-path PATH $topdir/bin prepend-path   PATH                $topdir/bin prepend-path   LD_LIBRARY_PATH     $topdir/lib prepend-path   INCLUDE             $topdir/include prepend-path   PKG_CONFIG_PATH     $topdir/lib/pkgconfig          # this is required in order to Lammps can found Plumed</p>"},{"location":"cluster/compile/Plumed/#test","title":"test:","text":"<p>module load plumed2/2.6.0 plumed help</p>"},{"location":"cluster/compile/Plumed/#usc2","title":"USC2:","text":"<p>module load mpi/ompi4.0.3-intel19u5 module load intel/compiler-xe19u5 module load intel/mkl-xe19u5 Configure</p> <p>./configure CXX=mpic++ CC=mpicc  LIBS=\"-mkl\" \\ --enable-openmp --enable-modules=all --enable-asmjit \\ --prefix=/home1/p001cao/local/app/plumed2/2.7htt</p> <p>make -j 8 make install II. Install PLUMED using lMPI-2019xe</p>"},{"location":"cluster/compile/Plumed/#1-usc-1","title":"1. USC 1:","text":"<p>(use this, bc compilers are available for all clusters) NOTE: intelMPI on eagle does not work, due to wrong path 1. Module load: module load intel/compiler-xe19u5 module load mpi/impi-xe19u5 module load intel/mkl-xe19u5 module load compiler/gcc/9.1.0 module load conda/py37</p> <p>Configure ./configure CXX=mpiicpc CC=mpiicc LIBS=\"-mkl\" \\ --enable-openmp --enable-modules=all --enable-asmjit \\ --prefix=/uhome/p001cao/local/app/plumed2/2.6httIMPI \\</p>"},{"location":"cluster/compile/Plumed/#usc-2","title":"USC 2","text":"<p>IV. Install PLUMED using openmpi-4.0.1 + GCC-7.4.0 (CAN) 1. Module load: module load mpi/openmpi4.0.1-gcc7.4.0 module load gcc/gcc-7.4.0</p> <p>check:  mpic++ --version             ( gcc C++) 2. Install PLUMED unzip plumed2-hack-the-tree.zip cd plumed2-hack-the-tree</p> <p>Configuring PLUMED: ./configure --prefix=/home/thang/local/app/plumed2/2.6.0-gcc \\ CXX=mpic++ --disable-external-blas --disable-external-lapack \\ --enable-openmp --enable-modules=all</p>"},{"location":"cluster/compile/Plumed/#usc2_1","title":"USC2","text":""},{"location":"cluster/compile/Plumed/#with-conda","title":"with Conda","text":"<p>Need create conda env and install <code>ompi</code>, see this</p> <p>check MPI compiler:  <code>mpic++ --version</code></p> <pre><code>cd /home1/p001cao/local/wSourceCode\ngit clone  -b master   https://github.com/plumed/plumed2.git    plumed  # hack-the-tree  master\ncd plumed\ngit pull origin master\n</code></pre> <pre><code>module load conda/py310lammps\nexport myCOMPILER=/home1/p001cao/local/app/miniconda3/envs/py310lammps\nexport PATH=${myCOMPILER}/bin:$PATH\nexport CC=mpicc  export CXX=mpic++  export FC=mpifort\nexport myPREFIX=/home1/p001cao/local/app/plumed2/ompi_conda_master\n\n./configure --prefix=${myPREFIX} \\\n--enable-openmp --enable-modules=all --enable-asmjit \\\n--disable-external-blas --disable-external-lapack\n</code></pre> <pre><code>make -j 16 &amp;&amp; make install\n</code></pre> see also <p>[1] https://www.plumed.org/doc-master/user-doc/html/_installation.html  [2] https://groups.google.com/forum/#!topic/plumed-users/x3YKcbDA-AE</p>"},{"location":"cluster/compile/UCX_UCC/","title":"UCX UCC","text":"<ul> <li>UCX</li> <li>Compile from Source vs. from pre-configured Release<ul> <li>1. install from Source</li> <li>2. install from UCX pre-configured Release</li> </ul> </li> <li>Compile with GCC<ul> <li>USC2</li> <li>USC1 (eagle)</li> </ul> </li> <li>Compile with Intel</li> <li>II. UCX optional Libs<ul> <li>1. rdma-core (fail)</li> <li>2. libnuma-devel</li> <li>3. openMPI/UCX: libfabric ()</li> <li>4. openMPI/UCX: KNEM</li> <li>5. openMPI/UCX: XPMEM</li> </ul> </li> <li>Compile with LLVM<ul> <li>USC2</li> <li>Prepare source code</li> <li>Building</li> <li>Make module file</li> </ul> </li> </ul>"},{"location":"cluster/compile/UCX_UCC/#ucx","title":"UCX","text":"<p>UCX is needed to compile OpenMPI to use InfiniBand</p> <p>Work with UCX in short:</p> <ul> <li>Get the recent release from https://github.com/openucx/ucx/releases</li> <li>Build and make <code>ucx</code> available to your machines</li> <li>Configure and compile OMPI with  <code>--with-ucx=\"path-to-ucx\"</code></li> </ul> <p>Afterward, when you launch OMPI run, you set UCX pml:</p> <pre><code>mpirun -mca btl self -mca pml ucx ....\n</code></pre> <p>To control which device and what transport are being used you can add following env variables:</p> <pre><code>mpirun -mca btl self -mca pml ucx -x UCX_NET_DEVICES=mlx5_0:1 -x UCX_TLS=rc,shm ....\n</code></pre> <p>Try to experiment with different TLS's see here for more info.</p> <p>``` tip \"See also 1. https://github.com/openucx/ucx/wiki/OpenMPI-and-OpenSHMEM-installation-with-UCX 2. https://github.com/openucx/ucx/wiki <pre><code>???+ note\n\n    - OpenMPI 4.0,3 support `ucx` 1.7 or older\n    - NOTE: UCX &gt;= 1.12.0 requires rdma-core &gt;= 28.0 or MLNX_OFED &gt;= 5.0 for Infiniband and RoCE transports support. This may cause error `address not mapped` on old system\n\n## Compile from Source vs. from pre-configured Release\n\nFor compiling from source codes, need [some tools](https://thangckt.github.io/cluster/compiling/Libtool/)\n\n### 1. install from Source\n\n```note\n- work now, but should not be use to avoid runtime errors\n- Requirements: `autoconf`, `libtool`, and `automake`\n</code></pre></p> <pre><code>cd /home1/p001cao/local/wSourceCode/tooldev\ngit clone --branch master https://github.com/openucx/ucx.git  ucx-master\ncd ucx-master\nmodule load tooldev/autoconf-2.72c\nmodule load tooldev/automake-1.16.5\nmodule load tooldev/libtool-2.4.7\nexport ACLOCAL_PATH=/home1/p001cao/app/tooldev/libtool-2.4.7/share/aclocal\n\n./autogen.sh\nmkdir build  &amp;&amp;  cd build\n\nmodule load tooldev/binutils-2.37              # gold\nmodule load compiler/gcc-10.3\n\nexport PATH=$PATH:/home1/p001cao/app/compiler/gcc-10.3/bin\nexport CC=gcc export CXX=g++ export FORTRAN=gfortran\nexport LDFLAGS=\"-fuse-ld=gold -lrt\"\n\n../configure --enable-mt  \\\n--prefix=/home1/p001cao/app/tooldev/ucx-master\n</code></pre>"},{"location":"cluster/compile/UCX_UCC/#2-install-from-ucx-pre-configured-release","title":"2. install from UCX pre-configured Release","text":"<pre><code>- This way no need ./autogen.h\n- ver 1.12.1 will cause error: not found auvx.h\n</code></pre> <pre><code>wget https://github.com/openucx/ucx/releases/download/v1.12.0/ucx-1.12.0.tar.gz\ntar xvf ucx-1.12.0.tar.gz\ncd ucx-1.12.0\nmkdir build &amp;&amp; cd build\n</code></pre>"},{"location":"cluster/compile/UCX_UCC/#tachyon","title":"Tachyon","text":""},{"location":"cluster/compile/UCX_UCC/#ucx-15-gcc-11","title":"UCX 15 - GCC 11","text":"<pre><code>- do not use GCC-11 to avoid error: Dwarf Error: found dwarf version '5', use: export CFLAGS='-gdwarf-4 -gstrict-dwarf'\nexport CFLAGS='-gdwarf-4 -gstrict-dwarf'\n</code></pre> <pre><code>cd /home1/p001cao/0SourceCode/tooldev\n# git clone --branch v1.15.x https://github.com/openucx/ucx.git  ucx-1.15.x\ncd ucx-1.15.x\ngit pull origin v1.15.x\n\nmodule load tooldev/autoconf-2.72c\nmodule load tooldev/automake-1.16.5\nmodule load tooldev/libtool-2.4.7\nexport ACLOCAL_PATH=/home1/p001cao/app/tooldev/libtool-2.4.7/share/aclocal\n\n./autogen.sh\n</code></pre> <pre><code># tar xvf ucx-1.13.1.tar.gz\ncd ucx-1.15.0\n\nmodule load compiler/gcc-11\nmyGCC=/home1/p001cao/app/compiler/gcc-11\nexport PATH=$myGCC/bin:$PATH\nexport CFLAGS=\"-gdwarf-2 -gstrict-dwarf\"\nexport CFLAGS=\"-Wno-shadow\"\nexport myPREFIX=/home1/p001cao/app/tooldev/ucx1.15-gcc11\n\n../contrib/configure-release --enable-mt --prefix=${myPREFIX}\n\nmake -j 16 &amp;&amp; make install\n</code></pre> <p>Test <pre><code>module load tooldev/ucx-1.15-gcc\nucx_info -d | grep Transport\n</code></pre></p> <p>Option:</p> <pre><code>export CFLAGS='-gdwarf-4 -gstrict-dwarf'\nmyKNEM=/home1/p001cao/app/tooldev/knem-1.1.4\nmyNUMA=/home1/p001cao/app/tooldev/numactl-2.0.13\n\n--with-knem=$myKNEM \\\nLDFLAGS=\"-fuse-ld=gold -lrt  -L$myNUMA/lib -Wl,-rpath,$myNUMA/lib\" \\\nCFLAGS=\"-I$myNUMA/include\" \\\n\n../contrib/configure-release  --enable-optimizations\n</code></pre>"},{"location":"cluster/compile/UCX_UCC/#ucx-15-llvm","title":"UCX 15 - LLVM","text":"<p>From source code</p> Note <ul> <li>consider to update: <code>autoconf</code>, <code>libtool</code>, and <code>automake</code></li> <li>To solve error with <code>libuct_ib.la: command not found</code>, use <code>./contrib/configure-release</code> but not <code>/configure</code></li> <li>It deos not work with clang 16 (not use now).</li> <li>May error <code>gdwarf</code></li> </ul> <pre><code>cd /home1/p001cao/0SourceCode/tooldev\n# git clone --branch v1.15.x https://github.com/openucx/ucx.git  ucx-1.15.x\ncd ucx-1.15.x\ngit pull origin v1.15.x\n\nmodule load tooldev/autoconf-2.72c\nmodule load tooldev/automake-1.16.5\nmodule load tooldev/libtool-2.4.7\nexport ACLOCAL_PATH=/home1/p001cao/app/tooldev/libtool-2.4.7/share/aclocal\n\n./autogen.sh\n</code></pre> <p>Building</p> <pre><code>rm -rf build &amp;&amp; mkdir build  &amp;&amp;  cd build\n\nmodule load compiler/llvm-17          # clang + lld\n\nmyLLVM=/home1/p001cao/app/compiler/llvm-17\nexport PATH=$myLLVM/bin:$PATH\nexport CC=clang export CXX=clang++\nexport LDFLAGS=\"-fuse-ld=lld -lrt\"\nexport CFLAGS=\"-gdwarf-2 -gstrict-dwarf -Wno-unused-but-set-variable\"\nRMDA=/home1/p001cao/0SourceCode/tooldev/rdma-core/build\nmyPREFIX=/home1/p001cao/app/tooldev/ucx1.15-clang17\n\n../contrib/configure-release --enable-mt --with-rdmacm=$RMDA --prefix=${myPREFIX}\n\nmake -j 16 &amp;&amp; make install\n</code></pre> <p>UCC: <pre><code>cd /home1/p001cao/0SourceCode/tooldev\n# git clone --branch master https://github.com/openucx/ucc.git  ucc\ncd ucc\ngit pull origin master\n\nmodule load tooldev/autoconf-2.72c\nmodule load tooldev/automake-1.16.5\nmodule load tooldev/libtool-2.4.7\nexport ACLOCAL_PATH=/home1/p001cao/app/tooldev/libtool-2.4.7/share/aclocal\n\n./autogen.sh\n</code></pre> <pre><code>rm -rf build &amp;&amp; mkdir build  &amp;&amp;  cd build\n\nmodule load compiler/llvm-17          # clang + lld\n\nmyLLVM=/home1/p001cao/app/compiler/llvm-17\nexport PATH=$myLLVM/bin:$PATH\nexport CC=clang export CXX=clang++\nexport LDFLAGS=\"-fuse-ld=lld -lrt\"\nmyUCX=/home1/p001cao/app/tooldev/ucx1.15-clang17\nmyPREFIX=/home1/p001cao/app/tooldev/ucc1.2\n\n../configure --with-ucx=${myUCX} --prefix=${myPREFIX}\n\nmake -j 16 &amp;&amp; make install\n</code></pre></p>"},{"location":"cluster/compile/UCX_UCC/#ucx-11-llvm","title":"UCX 11 - LLVM","text":"<ul> <li>NOTE: UCX &gt;= 1.12.0 requires rdma-core &gt;= 28.0 or MLNX_OFED &gt;= 5.0 for Infiniband and RoCE transports support. This may cause error <code>address not mapped</code> on old system</li> <li>dont use <code>lld</code> with ucx-1.11</li> </ul> <pre><code>cd /home1/p001cao/0SourceCode/tooldev\nwget https://github.com/openucx/ucx/releases/download/v1.11.2/ucx-1.11.2.tar.gz\ntar xvf ucx-1.11.2.tar.gz\ncd ucx-1.11.2\nrm -rf build &amp;&amp; mkdir build &amp;&amp; cd build\n\nmodule load compiler/llvm-17\nmyLLVM=/home1/p001cao/app/compiler/llvm-17\nexport PATH=$myLLVM/bin:$PATH\nexport CC=clang export CXX=clang++\nexport LDFLAGS=\"-fuse-ld=gold -lrt\"\nexport CFLAGS=\"-Wno-unused-but-set-variable\"\nexport myPREFIX=/home1/p001cao/app/tooldev/ucx1.11-clang17\n\n../contrib/configure-release --enable-mt --prefix=${myPREFIX}\n\nmake -j 16 &amp;&amp; make install\n</code></pre>"},{"location":"cluster/compile/UCX_UCC/#make-module-file","title":"Make module file","text":"<p>at directory: /uhome/p001cao/local/share/lmodfiles/GCC \u2192 create file \"gcc-11.2\"</p> <pre><code># for Tcl script use only\nset     topdir          /home1/p001cao/app/tooldev/ucx-1.15\n\nprepend-path    PATH                    $topdir/bin\nprepend-path    INCLUDE                 $topdir/include\nprepend-path    LD_LIBRARY_PATH         $topdir/lib\nprepend-path    PKG_CONFIG_PATH         $topdir/lib/pkgconfig\n</code></pre>"},{"location":"cluster/compile/UCX_UCC/#ii-ucx-optional-libs","title":"II. UCX optional Libs","text":"<p>UCX detects the exiting libraries on the build machine and enables/disables support for various features accordingly. If some of the modules UCX was built with are not found during runtime, they will be silently disabled.</p> <ul> <li>Basic shared memory and TCP support - always enabled</li> <li>Optimized shared memory - requires knem or xpmem drivers. On modern kernels also CMA (cross-memory-attach) mechanism will be used.</li> <li>RDMA support - requires rdma-core or libibverbs library.</li> <li>NVIDIA GPU support - requires Cuda drives</li> <li>AMD GPU support - requires ROCm drivers</li> </ul>"},{"location":"cluster/compile/UCX_UCC/#1-rdma-core-work","title":"1. rdma-core (work)","text":"<p>build/bin will contain the sample programs and build/lib will contain the shared libraries. The build is configured to run all the programs 'in-place' and cannot be installed. see more</p> <p>NOTE: rdma-core does not have install function, so use directly from build folder.</p> <pre><code>cd /home1/p001cao/0SourceCode/tooldev\ngit clone https://github.com/linux-rdma/rdma-core  rdma-core\ncd rdma-core\n# tar xvf rdma-core-30.0.tar.gz\n# cd rdma-core-30.0\n\nmodule load tooldev/cmake-3.27\nmodule load tooldev/libnl-3.2\nexport LDFLAGS=\"-lrt\"\n\n./build.sh\n</code></pre>"},{"location":"cluster/compile/UCX_UCC/#libnl","title":"libnl","text":"<p>https://topic.alibabacloud.com/a/how-to-compile-libnl-3225-in-centos-6_1_18_20033603.html</p> <pre><code>cd /home1/p001cao/0SourceCode/tooldev\nwget --no-check-certificate https://www.infradead.org/~tgr/libnl/files/libnl-3.2.25.tar.gz\ntar vxf libnl-3.2.25.tar.gz\ncd libnl-3.2.25\nexport myPREFIX=/home1/p001cao/app/tooldev/libnl-3.2.25\n\n./configure --prefix=${myPREFIX}\nmake -j 16 &amp;&amp; make install\n</code></pre>"},{"location":"cluster/compile/UCX_UCC/#usc1-eagle","title":"USC1 (eagle)","text":"<pre><code>module load tooldev/binutils-2.36              # gold\nmodule load compiler/gcc-11.2\n\nexport PATH=$PATH:/uhome/p001cao/app/compiler/gcc-11.2/bin\nexport CC=gcc export CXX=g++ export FORTRAN=gfortran\n\n../configure --enable-mt --prefix=/uhome/p001cao/app/tooldev/ucx-1.11\n</code></pre> <p>Option:</p> <pre><code>myKNEM=/uhome/p001cao/app/tooldev/knem-1.1.4\nmyNUMA=/uhome/p001cao/app/tooldev/numactl-2.0.13\n\n--with-knem=$myKNEM \\\nLDFLAGS=\"-fuse-ld=gold -lrt  -L$myNUMA/lib -Wl,-rpath,$myNUMA/lib\" \\\nCFLAGS=\"-I$myNUMA/include\" \\\n</code></pre> <p>Other options:</p> <pre><code>--disable-numa\n--with-rc --with-ud --with-dc --with-ib-hw-tm --with-dm --with-cm \\\n## consider options\n--with-verbs(=DIR)      Build OpenFabrics support, adding DIR/include,\n                        DIR/lib, and DIR/lib64 to the search path for\n                        headers and libraries\n--with-rc               Compile with IB Reliable Connection support\n--with-ud               Compile with IB Unreliable Datagram support\n--with-dc               Compile with IB Dynamic Connection support\n--with-mlx5-dv          Compile with mlx5 Direct Verbs support. Direct Verbs\n                        (DV) support provides additional acceleration\n                        capabilities that are not available in a regular\n                        mode.\n--with-ib-hw-tm         Compile with IB Tag Matching support\n--with-dm               Compile with Device Memory support\n\n--with-cm               Compile with IB Connection Manager support\n\n##-- Consider\nmyNUMA=/home1/p001cao/app/tooldev/numactl-2.0.13\nLDFLAGS=\"-fuse-ld=gold -lrt  -L$myNUMA/lib -Wl,-rpath,$myNUMA/lib\" \\\nCFLAGS=\"-I$myNUMA/include\" \\\n##--\nexport myKNEM=/home1/p001cao/app/tooldev/knem1.1.3\nexport myOFI=/home1/p001cao/app/tooldev/libfabric-1.10.1\n--with-verbs=${myOFI} --with-knem=${myKNEM} \\\nhttps://developer.arm.com/tools-and-software/server-and-hpc/help/porting-and-tuning/building-open-mpi-with-openucx/running-openmpi-with-openucx\n</code></pre>"},{"location":"cluster/compile/UCX_UCC/#compile-with-intel","title":"Compile with Intel","text":"<pre><code>module load intel/compiler-xe19u5\nexport PATH=/home1/p001cao/app/intel/xe19u5/compilers_and_libraries_2019.5.281/linux/bin/intel64:$PATH\nexport CC=icc  export CXX=icpc  export FORTRAN=ifort\nexport LD_LIBRARY_PATH=/home1/p001cao/app/intel/xe19u5/compilers_and_libraries_2019.5.281/linux/compiler/lib/intel64_lin:$LD_LIBRARY_PATH\n\nexport LD_LIBRARY_PATH=/home1/p001cao/app/tooldev/glibc-2.18/lib:$LD_LIBRARY_PATH\nexport LD_LIBRARY_PATH=/usr/local/lib\n\nexport myKNEM=/home1/p001cao/app/tooldev/knem1.1.3\nexport myOFI=/home1/p001cao/app/tooldev/libfabric-1.10.1\n\n../contrib/configure-release --disable-numa --enable-mt LDFLAGS=\"-fuse-ld=lld -lrt\" \\\n--with-verbs=${myOFI} --with-knem=${myKNEM} \\\n--prefix=/home1/p001cao/app/tooldev/ucx-1.8-intel\n</code></pre> <p>List of main transports and aliases https://github.com/openucx/ucx/wiki/UCX-environment-parameters all use all the available transports. sm  all shared memory transports. shm same as \"sm\". ugni    ugni_rdma and ugni_udt. rc  RC (=reliable connection), and UD (=unreliable datagram) for connection bootstrap. \"accelerated\" transports are used if possible. ud  UD transport, \"accelerated\" is used if possible. dc  DC - Mellanox scalable offloaded dynamic connection transport rc_x    Same as \"rc\", but using accelerated transports only rc_v    Same as \"rc\", but using Verbs-based transports only ud_x    Same as \"ud\", but using accelerated transports only ud_v    Same as \"ud\", but using Verbs-based transports only tcp     TCP over SOCK_STREAM sockets rdmacm  Use RDMACM connection management for client-server API sockcm  Use sockets-based connection management for client-server API cuda_copy   Use cu*Memcpy for hostcuda device self transfers but also to detect cuda memory gdr_copy    Use GDRcopy library for hostcuda device self transfers cuda_ipc    Use CUDA-IPC for cuda devicedevice transfers over PCIe/NVLINK rocm_copy   Use for host-rocm device transfers rocm_ipc    Use IPC for rocm device-device transfers self    Loopback transport to communicate within the same process</p>"},{"location":"cluster/compile/binutils_linker/","title":"Binutils linker","text":"<ul> <li>Binutils</li> <li>UCS2:</li> <li>UCS1:</li> <li>create module file</li> <li>Zlib</li> <li>texinfo</li> <li>bison</li> </ul>"},{"location":"cluster/compile/binutils_linker/#binutils","title":"Binutils","text":"<p>to use Gold linker (first released in binutils version 2.19), should to avoid link-error https://mirror.yongbok.net/gnu/binutils/?C=M&amp;O=D There are three linkers available on modern GNU/Linux systems:</p> <pre><code>- ld, maintained by GNU binutils,\n- gold, maintained by GNU binutils, \"still in beta test\",\n- lld, developed as part of the LLVM project.\n</code></pre> <p>For speed benchmarks, see: https://www.phoronix.com/scan.php?page=article&amp;item=lld4-linux-tests&amp;num=2 TL, DR: lld is fastest, followed by gold, followed by ld check  binutils version:  ld -v</p> <p>Install: http://www.linuxfromscratch.org/lfs/view/development/chapter06/binutils.html</p> <p>Note</p> <p>do not use <code>#</code> in folder name</p>"},{"location":"cluster/compile/binutils_linker/#tachyon-centos-69","title":"Tachyon - Centos 6.9","text":"<ul> <li><code>binutils-2.40</code> require to install:<ul> <li>texinfo</li> <li>bison</li> <li>need new GCC</li> </ul> </li> </ul> <pre><code>cd /home1/p001cao/0SourceCode/tooldev\nwget -c --no-check-certificate https://ftp.gnu.org/gnu/binutils/binutils-2.40.tar.gz\ntar zxvf binutils-2.40.tar.gz\n\ncd binutils-2.40\nrm -rf build &amp;&amp; mkdir build  &amp;&amp;  cd build\n\nexport PATH=/home2/app/compiler/gcc/9.5.0/bin:$PATH\nexport PATH=/home1/p001cao/app/tooldev/texinfo-7.0.3/bin:$PATH\nexport PATH=/home1/p001cao/app/tooldev/bison-3.8.2/bin:$PATH       # add custom ver before system's version\n\n../configure --enable-gold=yes --enable-ld=default --enable-lto \\\n    --enable-plugins --enable-shared --disable-werror  \\\n    --enable-64-bit-bfd --with-system-zlib \\\n    --prefix=/home1/p001cao/app/tooldev/binutils-2.40\n\nmake -j 16  &amp;&amp; make install\n</code></pre> <p>check:  ld -v   #  --enable-gprofng=no</p>"},{"location":"cluster/compile/binutils_linker/#ucs1","title":"UCS1:","text":"<ul> <li>work with binutils-2.36.1, to avoid error in GCC-11</li> </ul> <pre><code>tar zxvf binutils-2.36.1.tar.gz\ncd binutils-2.36.1\nmkdir build  &amp;&amp;  cd build\n\n../configure --enable-gold=yes --enable-ld=default --enable-lto \\\n--enable-plugins --enable-shared --disable-werror \\\n--enable-64-bit-bfd --with-system-zlib \\\n--prefix=/uhome/p001cao/app/tool_dev/binutils-2.36\n</code></pre>"},{"location":"cluster/compile/binutils_linker/#create-module-file","title":"create module file","text":"<p>cd /uhome/p001cao/local/Imodfiles  \u2192  create file \"cmake-3.20.3\" <pre><code># for Tcl script use only\nset     topdir          /home1/p001cao/app/tool_dev/binutils-2.37\n\nprepend-path    PATH                    $topdir/bin\nprepend-path    LD_LIBRARY_PATH         $topdir/lib\nprepend-path    INCLUDE             $topdir/include\n</code></pre></p>"},{"location":"cluster/compile/binutils_linker/#texinfo","title":"texinfo","text":"<pre><code>cd /home1/p001cao/0SourceCode/tooldev\nwget -c --no-check-certificate https://ftp.gnu.org/gnu/texinfo/texinfo-7.0.3.tar.gz\ntar zxvf  texinfo-7.0.3.tar.gz\ncd texinfo-7.0.3\n\n./configure --prefix=/home1/p001cao/app/tooldev/texinfo-7.0.3\nmake -j 16 &amp;&amp; make install\n</code></pre>"},{"location":"cluster/compile/binutils_linker/#bison","title":"bison","text":"<pre><code>wget -c --no-check-certificate https://ftp.gnu.org/gnu/bison/bison-3.8.2.tar.gz\ntar zxvf  bison-3.8.2.tar.gz\ncd bison-3.8.2\n\n./configure --prefix=/home1/p001cao/app/tooldev/bison-3.8.2\nmake -j 16 &amp;&amp; make install\n</code></pre>"},{"location":"cluster/compile/scaLAPACK_BLACS/","title":"scaLAPACK and BLACS","text":"<p>Note</p> <ul> <li>BLACS is a part of scaLAPACK, don't need to install it separately.</li> <li>Need MPI compiler</li> <li>sometimes, need <code>-DMPI_C_COMPILER=$OPENMPI/bin/mpicc -DCMAKE_Fortran_COMPILER=$OPENMPI/bin/mpif90</code></li> </ul>"},{"location":"cluster/compile/scaLAPACK_BLACS/#tachyon-centos-69","title":"Tachyon - Centos 6.9","text":""},{"location":"cluster/compile/scaLAPACK_BLACS/#openmpillvm","title":"OpenMPI+LLVM","text":"<p>Error:</p> <pre><code>cd /home1/p001cao/0SourceCode/tooldev\n# git clone -b master https://github.com/Reference-ScaLAPACK/scalapack.git ScaLAPACK-master  #   v2.2.1  master\ncd ScaLAPACK-master\nrm -rf build &amp;&amp; mkdir build &amp;&amp; cd build\n\nmodule load tooldev/cmake-3.27\nmodule load mpi/ompi4.1.x-clang17\nmodule load tooldev/openBLAS-0.3.23\n\nOPENMPI=/home1/p001cao/app/openmpi/4.1.x-clang17\nexport PATH=$OPENMPI/bin:$PATH\nexport CC=mpicc CXX=mpic++ FC=mpifort F90=mpif90 F77=mpif77\nexport LDFLAGS=\"-fuse-ld=lld -lrt\"\nexport CFLAGS=\"-Wno-implicit-function-declaration\"\nexport myBLAS=/home1/p001cao/app/tooldev/openBLAS-0.3.23/lib64/libopenblas.so\nmyPREFIX=/home1/p001cao/app/mpi/scaLAPACK2.2-ompi4.1.x-clang17\n\ncmake .. -DUSE_OPTIMIZED_LAPACK_BLAS=yes -DBUILD_SHARED_LIBS=on \\\n-DBLAS_LIBRARIES=${myBLAS} -DLAPACK_LIBRARIES=${myBLAS} -DCMAKE_INSTALL_PREFIX=$myPREFIX\n\nmake -j 16 &amp;&amp; make install\n</code></pre>"},{"location":"cluster/compile/scaLAPACK_BLACS/#openmpigcc","title":"OpenMPI+GCC","text":"<pre><code>module load tooldev/cmake-3.27\nmodule load mpi/ompi4.1.5-gcc9\nmodule load tooldev/openBLAS0.3.23-gcc9\n\nOPENMPI=/home1/p001cao/app/openmpi/4.1.5-gcc9\nexport PATH=$OPENMPI/bin:$PATH\nexport CC=mpicc CXX=mpic++ FC=mpifort F90=mpif90 F77=mpif77\nexport myBLAS=/home1/p001cao/app/tooldev/openBLAS0.3.23-gcc9/lib64/libopenblas.so\nmyPREFIX=/home1/p001cao/app/mpi/scaLAPACK2.2-ompi4.1.5-gcc9\n\ncmake .. -DUSE_OPTIMIZED_LAPACK_BLAS=yes -DBUILD_SHARED_LIBS=on \\\n-DBLAS_LIBRARIES=${myBLAS} -DLAPACK_LIBRARIES=${myBLAS} -DCMAKE_INSTALL_PREFIX=$myPREFIX\n\nmake -j 16 &amp;&amp; make install\n</code></pre>"},{"location":"cluster/refPage/cheatsheet/","title":"Cheatsheet","text":"Pandas cheatsheet pdf Regression Analysis cheatsheet pdf PPT guideline pdf Basic Concepts of Chemical Engineering Thermodynamics pdf"},{"location":"cluster/refPage/docs_syntax/","title":"Documentation syntax","text":""},{"location":"cluster/refPage/docs_syntax/#latex","title":"Latex","text":"Note for Latex html Code block with <code>listing</code> pdf Code block with <code>minted</code> pdf"},{"location":"cluster/refPage/docs_syntax/#docs-syntax","title":"Docs Syntax","text":"Markdown basic html Kramdown basic html Software engineering and systems engineering [course html"},{"location":"cluster/refPage/docs_syntax/#making-docs","title":"Making Docs","text":"Mkdocs html MkDocs Material html Python Markdown html Jupyter Books html The best MkDocs plugins and customizations html <p>Using Google Colab with GitHub</p>"},{"location":"odd/","title":"Odd","text":""},{"location":"odd/music/Lyrics/","title":"Lyrical Chord","text":""},{"location":"odd/music/Lyrics/#chiec-la-cuoi-cung","title":"Chi\u1ebfc l\u00e1 cu\u1ed1i c\u00f9ng","text":"<p>\u0110o\u00e0n Chu\u1ea9n &amp; T\u1eeb Linh - 1955, Boston, Capo 3</p> <pre><code>Em th\u1eddi [Em] gian, s\u01b0\u01a1ng gi\u00f3 ph\u00f4i [Am] pha\nAnh ng\u1ed3i \u0111\u00e2y anh nh\u1edb \u0111\u1ebfn [Em] em\nNh\u01b0 c\u00e0nh [C] kh\u00f4 tr\u01b0\u1edbc l\u00fac xa [B7] c\u00e2y g\u1ecdi n\u1eafng\nEm th\u1eddi [Em] gian, em c\u00f3 bi\u1ebft [Am] kh\u00f4ng\nKhi m\u00f9a \u0111\u00f4ng \u0111\u01b0a n\u1eafng qua [Em] s\u00f4ng\n\u0110\u1ec3 t\u00ecnh [C] y\u00eau gi\u1eefa n\u01b0\u1edbc m\u00eanh [B7] m\u00f4ng g\u1ecdi [Em] \u0111\u00f2.\n\nT\u00f4i \u0111i b\u00ean [G] ng\u01b0\u1eddi, ng\u01b0\u1eddi \u0111i b\u00ean t\u00f4i\nSao \u0111\u00f4i t\u00e2m [D] h\u1ed3n \u0111\u00e3 qu\u00e1 xa [G] x\u00f4i\nTr\u00ean nh\u1eefng con [Em] \u0111\u01b0\u1eddng tho\u1ea3ng h\u01b0\u01a1ng hoa s\u1eefa\nEm \u0111\u00e3 n\u00f3i [B7] g\u00ec, qu\u00e1 kh\u1ee9 t\u01b0\u01a1ng [Em] lai\nTr\u0103ng sao tr\u00ean [G] tr\u1eddi c\u00f2n khi chia \u0111\u00f4i\nNh\u01b0ng ti\u1ebfng ca [D] n\u00e0o c\u00f2n l\u1eafng trong [G] t\u00f4i\nT\u00f4i ng\u01b0\u1edbc l\u00ean [Em] tr\u1eddi g\u1ecdi m\u00e2y h\u1ea1nh [C] ph\u00fac\nM\u00e2y v\u1eabn \u00e2m [B7] th\u1ea7m l\u00e3ng \u0111\u00e3ng m\u00e2y [Em] tr\u00f4i.\n\nS\u00e0i G\u00f2n chi\u1ec1u [G] nay tr\u1eddi l\u00ean m\u00e2y [B7] tr\u1eafng\nChi\u1ebfc l\u00e1 cu\u1ed1i c\u00f9ng r\u01a1i xu\u1ed1ng ch\u00e2n [Am] em\nNh\u01b0 nh\u1eafc m\u1ed1i [D] t\u00ecnh tr\u00f3t l\u1ee1 kh\u00f4ng [G] t\u00ean\nEm bi\u1ebft n\u00f3i [Em] g\u00ec h\u1ee1i anh y\u00eau [C] d\u1ea5u\nEm kh\u00f3c cho [B7] t\u00ecnh m\u00e3i m\u00e3i kh\u00f4ng [Em] qu\u00ean.\n\nS\u00e0i G\u00f2n chi\u1ec1u [G] nay c\u00f2n nh\u01b0 in [B7] b\u00f3ng\nD\u1ea5u v\u1ebft l\u00e2u \u0111\u00e0i tr\u00ean c\u00e1t anh [Am] x\u00e2y\nB\u00f3ng d\u00e1ng em [D] v\u1ec1 th\u1ea5p tho\u00e1ng \u0111\u00e2u [G] \u0111\u00e2y\nChi\u1ebfc l\u00e1 cu\u1ed1i [Em] c\u00f9ng l\u00e0 c\u1ee7a em [C] \u0111\u00f3\nEm h\u00e3y gi\u1eef [B7] g\u00ecn tr\u01b0\u1edbc l\u00fac chia [Em] tay.\n</code></pre>"},{"location":"odd/music/music_classic/","title":"Classic pieces","text":""},{"location":"odd/music/music_classic/#classic-pieces","title":"Classic pieces","text":""},{"location":"odd/music/music_foreigned/","title":"Foreigned","text":""},{"location":"odd/music/music_foreigned/#f","title":"f","text":""},{"location":"odd/music/music_guitar_cover/","title":"Guitar covers","text":""},{"location":"odd/music/music_guitar_cover/#guitar","title":"guitar","text":""},{"location":"odd/music/music_saigon_fall/","title":"Saigon memorial","text":""},{"location":"odd/music/music_saigon_fall/#saigon-memorial","title":"Saigon memorial","text":""},{"location":"odd/music/music_sleep/","title":"Sleeping","text":""},{"location":"odd/music/music_sleep/#sleep","title":"sleep","text":""},{"location":"odd/music/music_tinh_ca/","title":"Love theme","text":"<p> Khi su\u1ed1i t\u00f3c \u0111\u1ed5 xu\u1ed1ng ng\u1ecdn t\u00ecnh ca  Nh\u1eefng s\u1ee3i huy\u1ec1n ch\u1ea3y xu\u00f4i v\u1ec1 m\u1ed9t h\u01b0\u1edbng  \u00d4i su\u1ed1i t\u00f3c u\u1ed1n m\u00ecnh qua kho\u1ea3ng tr\u1ed1ng  Nh\u1ed1t h\u1ed3n ta v\u00e0o t\u1eadn \u0111\u00e1y thi\u00ean \u0111\u01b0\u1eddng  </p>"},{"location":"odd/music/music_tinh_ca/#love-theme","title":"Love theme","text":""},{"location":"odd/music/music_viet_su/","title":"Historical theme","text":"<p> M\u1edd trong b\u00f3ng chi\u1ec1u   M\u1ed9t \u0111o\u00e0n qu\u00e2n th\u1ea5p tho\u00e1ng   N\u00fai c\u00e2y r\u1eebng, l\u1eafng ti\u1ebfng nghe h\u00ecnh d\u00e1ng  C\u1ee7a ng\u01b0\u1eddi anh h\u00f9ng  L\u1ea1nh l\u00f9ng theo tr\u1ed1ng d\u1ed3n  Tr\u00ean khu \u0111\u1ed3i hoang, in trong chi\u1ec1u bu\u00f4ng  </p> <p> </p>"},{"location":"odd/music/music_viet_su/#historical-theme","title":"Historical theme","text":""},{"location":"odd/reading/read_list/","title":"Reading list","text":"<p>The Road to Serfdom - F.A. Hayek - pdf</p> <p>Animal Farm - George Orwell - pdf</p> <p>Nineteen eighty-four - George Orwell - pdf</p> <p>\u0110\u01b0\u1eddng v\u1ec1 n\u00f4 l\u1ec7 - F.A. Hayek - pdf</p> <p>\u0110\u1eebng chet duoi tay TQ - PETER NAVARRO - pdf</p>"},{"location":"ref/","title":"Refs","text":""},{"location":"ref/chat/","title":"Chat","text":""},{"location":"ref/chat/#online","title":"Online","text":""},{"location":"ref/chat/#local","title":"Local","text":"<p>GPT4 copilot</p>"},{"location":"ref/english/english_learn/","title":"English","text":""},{"location":"ref/english/english_learn/#grammar","title":"Grammar","text":"<ul> <li>Giai thich ngu phap tieng Anh - Mai Lan Huong \u00a0  pdf</li> </ul>"},{"location":"ref/english/vocabulary_img/","title":"Vocabulary by images","text":"<p>See more</p>"},{"location":"ref/english/vocabulary_img/#clothes-and-accessories","title":"Clothes and accessories","text":""},{"location":"ref/english/vocabulary_img/#motorbike-parts","title":"Motorbike parts","text":""},{"location":"ref/raw_md/ml_in_comp_mat/","title":"Ml in comp mat","text":"Best of Atomistic Machine Learning \u269b\ufe0f\ud83e\uddec\ud83d\udc8e      <p> \ud83c\udfc6\u00a0 A ranked list of awesome atomistic machine learning (AML) projects. Updated regularly. </p> <p> </p> <p>This curated list contains 430 awesome open-source projects with a total of 190K stars grouped into 22 categories. All projects are ranked by a project-quality score, which is calculated based on various metrics automatically collected from GitHub and different package managers. If you like to add or update projects, feel free to open an issue, submit a pull request, or directly edit the projects.yaml.</p> <p>The current focus of this list is more on simulation data rather than experimental data, and more on materials rather than drug design. Nevertheless, contributions from other fields are warmly welcome!</p> <p>How to cite. See the button \"Cite this repository\" on the right side-bar.</p> <p>\ud83e\uddd9\u200d\u2642\ufe0f  Discover other best-of lists or create your own.</p>"},{"location":"ref/raw_md/ml_in_comp_mat/#contents","title":"Contents","text":"<ul> <li>Active learning 6 projects</li> <li>Community resources 30 projects</li> <li>Datasets 45 projects</li> <li>Data Structures 4 projects</li> <li>Density functional theory (ML-DFT) 33 projects</li> <li>Educational Resources 28 projects</li> <li>Explainable Artificial intelligence (XAI) 3 projects</li> <li>Electronic structure methods (ML-ESM) 5 projects</li> <li>General Tools 22 projects</li> <li>Generative Models 14 projects</li> <li>Interatomic Potentials (ML-IAP) 70 projects</li> <li>Language Models 22 projects</li> <li>Materials Discovery 12 projects</li> <li>Mathematical tools 11 projects</li> <li>Molecular Dynamics 10 projects</li> <li>Reinforcement Learning 2 projects</li> <li>Representation Engineering 25 projects</li> <li>Representation Learning 58 projects</li> <li>Universal Potentials 10 projects</li> <li>Unsupervised Learning 7 projects</li> <li>Visualization 6 projects</li> <li>Wavefunction methods (ML-WFT) 5 projects</li> <li>Others 1 projects</li> </ul>"},{"location":"ref/raw_md/ml_in_comp_mat/#explanation","title":"Explanation","text":"<ul> <li>\ud83e\udd47\ud83e\udd48\ud83e\udd49\u00a0 Combined project-quality score</li> <li>\u2b50\ufe0f\u00a0 Star count from GitHub</li> <li>\ud83d\udc23\u00a0 New project (less than 6 months old)</li> <li>\ud83d\udca4\u00a0 Inactive project (6 months no activity)</li> <li>\ud83d\udc80\u00a0 Dead project (12 months no activity)</li> <li>\ud83d\udcc8\ud83d\udcc9\u00a0 Project is trending up or down</li> <li>\u2795\u00a0 Project was recently added</li> <li>\ud83d\udc68\u200d\ud83d\udcbb\u00a0 Contributors count from GitHub</li> <li>\ud83d\udd00\u00a0 Fork count from GitHub</li> <li>\ud83d\udccb\u00a0 Issue count from GitHub</li> <li>\u23f1\ufe0f\u00a0 Last update timestamp on package manager</li> <li>\ud83d\udce5\u00a0 Download count from package manager</li> <li>\ud83d\udce6\u00a0 Number of dependent projects</li> </ul>"},{"location":"ref/raw_md/ml_in_comp_mat/#active-learning","title":"Active learning","text":"<p>Projects that focus on enabling active learning, iterative learning schemes for atomistic ML.</p> FLARE (\ud83e\udd4722 \u00b7  \u2b50 290 \u00b7 \ud83d\udcc8) - An open-source Python package for creating fast and accurate interatomic potentials. <code>MIT</code> <code>C++</code> <code>ML-IAP</code>  - [GitHub](https://github.com/mir-group/flare) (\ud83d\udc68\u200d\ud83d\udcbb 41 \u00b7 \ud83d\udd00 66 \u00b7 \ud83d\udce5 8 \u00b7 \ud83d\udce6 11 \u00b7 \ud83d\udccb 220 - 16% open \u00b7 \u23f1\ufe0f 20.09.2024):      <pre><code>git clone https://github.com/mir-group/flare\n</code></pre> IPSuite (\ud83e\udd4817 \u00b7  \u2b50 18) - A Python toolkit for FAIR development and deployment of machine-learned interatomic potentials. <code>EPL-2.0</code> <code>ML-IAP</code> <code>MD</code> <code>workflows</code> <code>HTC</code> <code>FAIR</code>  - [GitHub](https://github.com/zincware/IPSuite) (\ud83d\udc68\u200d\ud83d\udcbb 8 \u00b7 \ud83d\udd00 10 \u00b7 \ud83d\udce6 6 \u00b7 \ud83d\udccb 130 - 51% open \u00b7 \u23f1\ufe0f 19.09.2024):      <pre><code>git clone https://github.com/zincware/IPSuite\n</code></pre> - [PyPi](https://pypi.org/project/ipsuite) (\ud83d\udce5 160 / month \u00b7 \u23f1\ufe0f 08.08.2024):     <pre><code>pip install ipsuite\n</code></pre> Finetuna (\ud83e\udd4910 \u00b7  \u2b50 42) - Active Learning for Machine Learning Potentials. <code>MIT</code>  - [GitHub](https://github.com/ulissigroup/finetuna) (\ud83d\udc68\u200d\ud83d\udcbb 11 \u00b7 \ud83d\udd00 11 \u00b7 \ud83d\udccb 20 - 25% open \u00b7 \u23f1\ufe0f 15.05.2024):      <pre><code>git clone https://github.com/ulissigroup/finetuna\n</code></pre> ACEHAL (\ud83e\udd495 \u00b7  \u2b50 11 \u00b7 \ud83d\udca4) - Hyperactive Learning (HAL) Python interface for building Atomic Cluster Expansion potentials. <code>Unlicensed</code> <code>Julia</code>  - [GitHub](https://github.com/ACEsuit/ACEHAL) (\ud83d\udc68\u200d\ud83d\udcbb 3 \u00b7 \ud83d\udd00 7 \u00b7 \ud83d\udccb 10 - 40% open \u00b7 \u23f1\ufe0f 21.09.2023):      <pre><code>git clone https://github.com/ACEsuit/ACEHAL\n</code></pre> Show 2 hidden projects...  - flare++ (\ud83e\udd4813 \u00b7  \u2b50 35 \u00b7 \ud83d\udc80) - A many-body extension of the FLARE code. <code>MIT</code> <code>C++</code> <code>ML-IAP</code> - ALEBREW (\ud83e\udd493 \u00b7  \u2b50 9) - Official repository for the paper Uncertainty-biased molecular dynamics for learning uniformly accurate interatomic.. <code>Custom</code> <code>ML-IAP</code> <code>MD</code> <p></p>"},{"location":"ref/raw_md/ml_in_comp_mat/#community-resources","title":"Community resources","text":"<p>Projects that collect atomistic ML resources or foster communication within community.</p> <p>\ud83d\udd17\u00a0AI for Science Map  - Interactive mindmap of the AI4Science research field, including atomistic machine learning, including papers,..</p> <p>\ud83d\udd17\u00a0Atomic Cluster Expansion  - Atomic Cluster Expansion (ACE) community homepage.</p> <p>\ud83d\udd17\u00a0CrystaLLM  - Generate a crystal structure from a composition. <code>language-models</code> <code>generative</code> <code>pretrained</code> <code>transformer</code></p> <p>\ud83d\udd17\u00a0GAP-ML.org community homepage <code>ML-IAP</code></p> <p>\ud83d\udd17\u00a0matsci.org  - A community forum for the discussion of anything materials science, with a focus on computational materials science..</p> <p>\ud83d\udd17\u00a0Matter Modeling Stack Exchange - Machine Learning  - Forum StackExchange, site Matter Modeling, ML-tagged questions.</p> Best-of Machine Learning with Python (\ud83e\udd4722 \u00b7  \u2b50 16K) - A ranked list of awesome machine learning Python libraries. Updated weekly. <code>CC-BY-4.0</code> <code>general-ml</code> <code>Python</code>  - [GitHub](https://github.com/ml-tooling/best-of-ml-python) (\ud83d\udc68\u200d\ud83d\udcbb 47 \u00b7 \ud83d\udd00 2.3K \u00b7 \ud83d\udccb 59 - 42% open \u00b7 \u23f1\ufe0f 26.09.2024):      <pre><code>git clone https://github.com/ml-tooling/best-of-ml-python\n</code></pre> Graph-based Deep Learning Literature (\ud83e\udd4719 \u00b7  \u2b50 4.7K) - links to conference publications in graph-based deep learning. <code>MIT</code> <code>general-ml</code> <code>rep-learn</code>  - [GitHub](https://github.com/naganandy/graph-based-deep-learning-literature) (\ud83d\udc68\u200d\ud83d\udcbb 12 \u00b7 \ud83d\udd00 770 \u00b7 \u23f1\ufe0f 09.09.2024):      <pre><code>git clone https://github.com/naganandy/graph-based-deep-learning-literature\n</code></pre> MatBench (\ud83e\udd4718 \u00b7  \u2b50 110 \u00b7 \ud83d\udca4) - Matbench: Benchmarks for materials science property prediction. <code>MIT</code> <code>datasets</code> <code>benchmarking</code> <code>model-repository</code>  - [GitHub](https://github.com/materialsproject/matbench) (\ud83d\udc68\u200d\ud83d\udcbb 25 \u00b7 \ud83d\udd00 45 \u00b7 \ud83d\udce6 16 \u00b7 \ud83d\udccb 65 - 60% open \u00b7 \u23f1\ufe0f 20.01.2024):      <pre><code>git clone https://github.com/materialsproject/matbench\n</code></pre> - [PyPi](https://pypi.org/project/matbench) (\ud83d\udce5 420 / month \u00b7 \ud83d\udce6 2 \u00b7 \u23f1\ufe0f 27.07.2022):     <pre><code>pip install matbench\n</code></pre> MatBench Discovery (\ud83e\udd4718 \u00b7  \u2b50 92) - An evaluation framework for machine learning models simulating high-throughput materials discovery. <code>MIT</code> <code>datasets</code> <code>benchmarking</code> <code>model-repository</code>  - [GitHub](https://github.com/janosh/matbench-discovery) (\ud83d\udc68\u200d\ud83d\udcbb 8 \u00b7 \ud83d\udd00 12 \u00b7 \ud83d\udce6 2 \u00b7 \ud83d\udccb 38 - 10% open \u00b7 \u23f1\ufe0f 23.09.2024):      <pre><code>git clone https://github.com/janosh/matbench-discovery\n</code></pre> - [PyPi](https://pypi.org/project/matbench-discovery) (\ud83d\udce5 1.7K / month \u00b7 \u23f1\ufe0f 11.09.2024):     <pre><code>pip install matbench-discovery\n</code></pre> OpenML (\ud83e\udd4817 \u00b7  \u2b50 660) - Open Machine Learning. <code>BSD-3</code> <code>datasets</code>  - [GitHub](https://github.com/openml/OpenML) (\ud83d\udc68\u200d\ud83d\udcbb 35 \u00b7 \ud83d\udd00 90 \u00b7 \ud83d\udccb 930 - 39% open \u00b7 \u23f1\ufe0f 08.09.2024):      <pre><code>git clone https://github.com/openml/OpenML\n</code></pre> GT4SD - Generative Toolkit for Scientific Discovery (\ud83e\udd4816 \u00b7  \u2b50 330) - Gradio apps of generative models in GT4SD. <code>MIT</code> <code>generative</code> <code>pretrained</code> <code>drug-discovery</code> <code>model-repository</code>  - [GitHub](https://github.com/GT4SD/gt4sd-core) (\ud83d\udc68\u200d\ud83d\udcbb 20 \u00b7 \ud83d\udd00 68 \u00b7 \ud83d\udccb 110 - 12% open \u00b7 \u23f1\ufe0f 12.09.2024):      <pre><code>git clone https://github.com/GT4SD/gt4sd-core\n</code></pre> AI for Science Resources (\ud83e\udd4813 \u00b7  \u2b50 490) - List of resources for AI4Science research, including learning resources. <code>GPL-3.0 license</code>  - [GitHub](https://github.com/divelab/AIRS) (\ud83d\udc68\u200d\ud83d\udcbb 29 \u00b7 \ud83d\udd00 58 \u00b7 \ud83d\udccb 15 - 6% open \u00b7 \u23f1\ufe0f 03.09.2024):      <pre><code>git clone https://github.com/divelab/AIRS\n</code></pre> Neural-Network-Models-for-Chemistry (\ud83e\udd4811 \u00b7  \u2b50 78) - A collection of Nerual Network Models for chemistry. <code>Unlicensed</code> <code>rep-learn</code>  - [GitHub](https://github.com/Eipgen/Neural-Network-Models-for-Chemistry) (\ud83d\udc68\u200d\ud83d\udcbb 3 \u00b7 \ud83d\udd00 10 \u00b7 \ud83d\udccb 2 - 50% open \u00b7 \u23f1\ufe0f 20.09.2024):      <pre><code>git clone https://github.com/Eipgen/Neural-Network-Models-for-Chemistry\n</code></pre> Awesome Neural Geometry (\ud83e\udd489 \u00b7  \u2b50 910) - A curated collection of resources and research related to the geometry of representations in the brain, deep networks,.. <code>Unlicensed</code> <code>educational</code> <code>rep-learn</code>  - [GitHub](https://github.com/neurreps/awesome-neural-geometry) (\ud83d\udc68\u200d\ud83d\udcbb 12 \u00b7 \ud83d\udd00 57 \u00b7 \u23f1\ufe0f 25.09.2024):      <pre><code>git clone https://github.com/neurreps/awesome-neural-geometry\n</code></pre> GNoME Explorer (\ud83e\udd489 \u00b7  \u2b50 870) - Graph Networks for Materials Exploration Database. <code>Apache-2</code> <code>datasets</code> <code>materials-discovery</code>  - [GitHub](https://github.com/google-deepmind/materials_discovery) (\ud83d\udc68\u200d\ud83d\udcbb 2 \u00b7 \ud83d\udd00 140 \u00b7 \ud83d\udccb 22 - 81% open \u00b7 \u23f1\ufe0f 04.09.2024):      <pre><code>git clone https://github.com/google-deepmind/materials_discovery\n</code></pre> Awesome Materials Informatics (\ud83e\udd489 \u00b7  \u2b50 370) - Curated list of known efforts in materials informatics, i.e. in modern materials science. <code>Custom</code>  - [GitHub](https://github.com/tilde-lab/awesome-materials-informatics) (\ud83d\udc68\u200d\ud83d\udcbb 19 \u00b7 \ud83d\udd00 81 \u00b7 \u23f1\ufe0f 18.09.2024):      <pre><code>git clone https://github.com/tilde-lab/awesome-materials-informatics\n</code></pre> MoLFormers UI (\ud83e\udd489 \u00b7  \u2b50 250 \u00b7 \ud83d\udca4) - A family of foundation models trained on chemicals. <code>Apache-2</code> <code>transformer</code> <code>language-models</code> <code>pretrained</code> <code>drug-discovery</code>  - [GitHub](https://github.com/IBM/molformer) (\ud83d\udc68\u200d\ud83d\udcbb 5 \u00b7 \ud83d\udd00 41 \u00b7 \ud83d\udccb 19 - 47% open \u00b7 \u23f1\ufe0f 16.10.2023):      <pre><code>git clone https://github.com/IBM/molformer\n</code></pre> AI for Science paper collection (\ud83e\udd489 \u00b7  \u2b50 56 \u00b7 \ud83d\udc23) - List the AI for Science papers accepted by top conferences. <code>Apache-2</code>  - [GitHub](https://github.com/sherrylixuecheng/AI_for_Science_paper_collection) (\ud83d\udc68\u200d\ud83d\udcbb 5 \u00b7 \ud83d\udd00 6 \u00b7 \u23f1\ufe0f 14.09.2024):      <pre><code>git clone https://github.com/sherrylixuecheng/AI_for_Science_paper_collection\n</code></pre> optimade.science (\ud83e\udd498 \u00b7  \u2b50 8) - A sky-scanner Optimade browser-only GUI. <code>MIT</code> <code>datasets</code>  - [GitHub](https://github.com/tilde-lab/optimade.science) (\ud83d\udc68\u200d\ud83d\udcbb 8 \u00b7 \ud83d\udd00 2 \u00b7 \ud83d\udccb 26 - 26% open \u00b7 \u23f1\ufe0f 10.06.2024):      <pre><code>git clone https://github.com/tilde-lab/optimade.science\n</code></pre> Awesome-Graph-Generation (\ud83e\udd497 \u00b7  \u2b50 270) - A curated list of up-to-date graph generation papers and resources. <code>Unlicensed</code> <code>rep-learn</code>  - [GitHub](https://github.com/yuanqidu/awesome-graph-generation) (\ud83d\udc68\u200d\ud83d\udcbb 4 \u00b7 \ud83d\udd00 17 \u00b7 \u23f1\ufe0f 17.03.2024):      <pre><code>git clone https://github.com/yuanqidu/awesome-graph-generation\n</code></pre> Awesome Neural SBI (\ud83e\udd497 \u00b7  \u2b50 84) - Community-sourced list of papers and resources on neural simulation-based inference. <code>MIT</code> <code>active-learning</code>  - [GitHub](https://github.com/smsharma/awesome-neural-sbi) (\ud83d\udc68\u200d\ud83d\udcbb 3 \u00b7 \ud83d\udd00 6 \u00b7 \ud83d\udccb 2 - 50% open \u00b7 \u23f1\ufe0f 17.06.2024):      <pre><code>git clone https://github.com/smsharma/awesome-neural-sbi\n</code></pre> Awesome-Crystal-GNNs (\ud83e\udd497 \u00b7  \u2b50 60) - This repository contains a collection of resources and papers on GNN Models on Crystal Solid State Materials. <code>MIT</code>  - [GitHub](https://github.com/kdmsit/Awesome-Crystal-GNNs) (\ud83d\udc68\u200d\ud83d\udcbb 2 \u00b7 \ud83d\udd00 8 \u00b7 \u23f1\ufe0f 16.06.2024):      <pre><code>git clone https://github.com/kdmsit/Awesome-Crystal-GNNs\n</code></pre> The Collection of Database and Dataset Resources in Materials Science (\ud83e\udd496 \u00b7  \u2b50 260) - A list of databases, datasets and books/handbooks where you can find materials properties for machine learning.. <code>Unlicensed</code> <code>datasets</code>  - [GitHub](https://github.com/sedaoturak/data-resources-for-materials-science) (\ud83d\udc68\u200d\ud83d\udcbb 2 \u00b7 \ud83d\udd00 42 \u00b7 \ud83d\udccb 2 - 50% open \u00b7 \u23f1\ufe0f 07.06.2024):      <pre><code>git clone https://github.com/sedaoturak/data-resources-for-materials-science\n</code></pre> Does this material exist? (\ud83e\udd495 \u00b7  \u2b50 15) - Vote on whether you think predicted crystal structures could be synthesised. <code>MIT</code> <code>for-fun</code> <code>materials-discovery</code>  - [GitHub](https://github.com/ml-evs/this-material-does-not-exist) (\ud83d\udc68\u200d\ud83d\udcbb 2 \u00b7 \ud83d\udd00 3 \u00b7 \u23f1\ufe0f 10.04.2024):      <pre><code>git clone https://github.com/ml-evs/this-material-does-not-exist\n</code></pre> Show 5 hidden projects...  - MADICES Awesome Interoperability (\ud83e\udd498 \u00b7  \u2b50 1) - Linked data interoperability resources of the Machine-actionable data interoperability for the chemical sciences.. <code>MIT</code> <code>datasets</code> - A Highly Opinionated List of Open-Source Materials Informatics Resources (\ud83e\udd497 \u00b7  \u2b50 120 \u00b7 \ud83d\udc80) - A Highly Opinionated List of Open Source Materials Informatics Resources. <code>MIT</code> - Geometric-GNNs (\ud83e\udd494 \u00b7  \u2b50 92 \u00b7 \ud83d\udca4) - List of Geometric GNNs for 3D atomic systems. <code>Unlicensed</code> <code>datasets</code> <code>educational</code> <code>rep-learn</code> - GitHub topic materials-informatics (\ud83e\udd491) - GitHub topic materials-informatics. <code>Unlicensed</code> - MateriApps (\ud83e\udd491) - A Portal Site of Materials Science Simulation. <code>Unlicensed</code> <p></p>"},{"location":"ref/raw_md/ml_in_comp_mat/#datasets","title":"Datasets","text":"<p>Datasets, databases and trained models for atomistic ML.</p> <p>\ud83d\udd17\u00a0Alexandria Materials Database  - A database of millions of theoretical crystal structures (3D, 2D and 1D) discovered by machine learning accelerated..</p> <p>\ud83d\udd17\u00a0Catalysis Hub  - A web-platform for sharing data and software for computational catalysis research!.</p> <p>\ud83d\udd17\u00a0Citrination Datasets  - AI-Powered Materials Data Platform. Open Citrination has been decommissioned.</p> <p>\ud83d\udd17\u00a0crystals.ai  - Curated datasets for reproducible AI in materials science.</p> <p>\ud83d\udd17\u00a0DeepChem Models  - DeepChem models on HuggingFace. <code>model-repository</code> <code>pretrained</code> <code>language-models</code></p> <p>\ud83d\udd17\u00a0Graphs of Materials Project 20190401  - The dataset used to train the MEGNet interatomic potential. <code>ML-IAP</code></p> <p>\ud83d\udd17\u00a0HME21 Dataset  - High-temperature multi-element 2021 dataset for the PreFerred Potential (PFP).. <code>UIP</code></p> <p>\ud83d\udd17\u00a0JARVIS-Leaderboard ( \u2b50 58)  - Explore State-of-the-Art Materials Design Methods: https://www.nature.com/articles/s41524-024-01259-w. <code>model-repository</code> <code>benchmarking</code> <code>community-resource</code> <code>educational</code></p> <p>\ud83d\udd17\u00a0Materials Project - Charge Densities  - Materials Project has started offering charge density information available for download via their public API.</p> <p>\ud83d\udd17\u00a0Materials Project Trajectory (MPtrj) Dataset  - The dataset used to train the CHGNet universal potential. <code>UIP</code></p> <p>\ud83d\udd17\u00a0matterverse.ai  - Database of yet-to-be-sythesized materials predicted using state-of-the-art machine learning algorithms.</p> <p>\ud83d\udd17\u00a0MPF.2021.2.8  - The dataset used to train the M3GNet universal potential. <code>UIP</code></p> <p>\ud83d\udd17\u00a0NRELMatDB  - Computational materials database with the specific focus on materials for renewable energy applications including, but..</p> <p>\ud83d\udd17\u00a0Quantum-Machine.org Datasets  - Collection of datasets, including QM7, QM9, etc. MD, DFT. Small organic molecules, mostly.</p> <p>\ud83d\udd17\u00a0sGDML Datasets  - MD17, MD22, DFT datasets.</p> <p>\ud83d\udd17\u00a0MoleculeNet  - A Benchmark for Molecular Machine Learning. <code>benchmarking</code></p> <p>\ud83d\udd17\u00a0ZINC15  - A free database of commercially-available compounds for virtual screening. ZINC contains over 230 million purchasable.. <code>graph</code> <code>biomolecules</code></p> <p>\ud83d\udd17\u00a0ZINC20  - A free database of commercially-available compounds for virtual screening. ZINC contains over 230 million purchasable.. <code>graph</code> <code>biomolecules</code></p> OPTIMADE Python tools (\ud83e\udd4727 \u00b7  \u2b50 68) - Tools for implementing and consuming OPTIMADE APIs in Python. <code>MIT</code>  - [GitHub](https://github.com/Materials-Consortia/optimade-python-tools) (\ud83d\udc68\u200d\ud83d\udcbb 28 \u00b7 \ud83d\udd00 42 \u00b7 \ud83d\udce6 60 \u00b7 \ud83d\udccb 450 - 23% open \u00b7 \u23f1\ufe0f 23.09.2024):      <pre><code>git clone https://github.com/Materials-Consortia/optimade-python-tools\n</code></pre> - [PyPi](https://pypi.org/project/optimade) (\ud83d\udce5 8K / month \u00b7 \ud83d\udce6 4 \u00b7 \u23f1\ufe0f 16.09.2024):     <pre><code>pip install optimade\n</code></pre> - [Conda](https://anaconda.org/conda-forge/optimade) (\ud83d\udce5 91K \u00b7 \u23f1\ufe0f 16.09.2024):     <pre><code>conda install -c conda-forge optimade\n</code></pre> MPContribs (\ud83e\udd4723 \u00b7  \u2b50 35) - Platform for materials scientists to contribute and disseminate their materials data through Materials Project. <code>MIT</code>  - [GitHub](https://github.com/materialsproject/MPContribs) (\ud83d\udc68\u200d\ud83d\udcbb 25 \u00b7 \ud83d\udd00 20 \u00b7 \ud83d\udce6 39 \u00b7 \ud83d\udccb 99 - 21% open \u00b7 \u23f1\ufe0f 25.09.2024):      <pre><code>git clone https://github.com/materialsproject/MPContribs\n</code></pre> - [PyPi](https://pypi.org/project/mpcontribs-client) (\ud83d\udce5 2.6K / month \u00b7 \ud83d\udce6 3 \u00b7 \u23f1\ufe0f 20.06.2024):     <pre><code>pip install mpcontribs-client\n</code></pre> FAIR Chemistry datasets (\ud83e\udd4721 \u00b7  \u2b50 770) - Datasets OC20, OC22, etc. Formerly known as Open Catalyst Project. <code>MIT</code> <code>catalysis</code>  - [GitHub](https://github.com/FAIR-Chem/fairchem) (\ud83d\udc68\u200d\ud83d\udcbb 42 \u00b7 \ud83d\udd00 230 \u00b7 \ud83d\udccb 200 - 6% open \u00b7 \u23f1\ufe0f 24.09.2024):      <pre><code>git clone https://github.com/FAIR-Chem/fairchem\n</code></pre> Open Databases Integration for Materials Design (OPTIMADE) (\ud83e\udd4818 \u00b7  \u2b50 82) - Specification of a common REST API for access to materials databases. <code>CC-BY-4.0</code>  - [GitHub](https://github.com/Materials-Consortia/OPTIMADE) (\ud83d\udc68\u200d\ud83d\udcbb 21 \u00b7 \ud83d\udd00 35 \u00b7 \ud83d\udccb 240 - 28% open \u00b7 \u23f1\ufe0f 12.06.2024):      <pre><code>git clone https://github.com/Materials-Consortia/OPTIMADE\n</code></pre> load-atoms (\ud83e\udd4815 \u00b7  \u2b50 38) - download and manipulate atomistic datasets. <code>MIT</code> <code>data-structures</code>  - [GitHub](https://github.com/jla-gardner/load-atoms) (\ud83d\udc68\u200d\ud83d\udcbb 3 \u00b7 \ud83d\udd00 2 \u00b7 \ud83d\udce6 3 \u00b7 \ud83d\udccb 31 - 3% open \u00b7 \u23f1\ufe0f 16.09.2024):      <pre><code>git clone https://github.com/jla-gardner/load-atoms\n</code></pre> - [PyPi](https://pypi.org/project/load-atoms) (\ud83d\udce5 760 / month \u00b7 \u23f1\ufe0f 16.09.2024):     <pre><code>pip install load-atoms\n</code></pre> QH9 (\ud83e\udd4813 \u00b7  \u2b50 490) - A Quantum Hamiltonian Prediction Benchmark. <code>CC-BY-NC-SA-4.0</code> <code>ML-DFT</code>  - [GitHub](https://github.com/divelab/AIRS) (\ud83d\udc68\u200d\ud83d\udcbb 29 \u00b7 \ud83d\udd00 58 \u00b7 \ud83d\udccb 15 - 6% open \u00b7 \u23f1\ufe0f 03.09.2024):      <pre><code>git clone https://github.com/divelab/AIRS\n</code></pre> SPICE (\ud83e\udd4811 \u00b7  \u2b50 150) - A collection of QM data for training potential functions. <code>MIT</code> <code>ML-IAP</code> <code>MD</code>  - [GitHub](https://github.com/openmm/spice-dataset) (\ud83d\udc68\u200d\ud83d\udcbb 1 \u00b7 \ud83d\udd00 9 \u00b7 \ud83d\udce5 250 \u00b7 \ud83d\udccb 63 - 25% open \u00b7 \u23f1\ufe0f 19.08.2024):      <pre><code>git clone https://github.com/openmm/spice-dataset\n</code></pre> Materials Data Facility (MDF) (\ud83e\udd489 \u00b7  \u2b50 10 \u00b7 \ud83d\udca4) - A simple way to publish, discover, and access materials datasets. Publication of very large datasets supported (e.g.,.. <code>Apache-2</code>  - [GitHub](https://github.com/materials-data-facility/connect_client) (\ud83d\udc68\u200d\ud83d\udcbb 7 \u00b7 \ud83d\udd00 1 \u00b7 \ud83d\udccb 7 - 14% open \u00b7 \u23f1\ufe0f 05.02.2024):      <pre><code>git clone https://github.com/materials-data-facility/connect_client\n</code></pre> 2DMD dataset (\ud83e\udd489 \u00b7  \u2b50 6 \u00b7 \ud83d\udca4) - Code for Kazeev, N., Al-Maeeni, A.R., Romanov, I. et al. Sparse representation for machine learning the properties of.. <code>Apache-2</code> <code>material-defect</code>  - [GitHub](https://github.com/HSE-LAMBDA/ai4material_design) (\ud83d\udc68\u200d\ud83d\udcbb 11 \u00b7 \ud83d\udd00 3 \u00b7 \u23f1\ufe0f 21.11.2023):      <pre><code>git clone https://github.com/HSE-LAMBDA/ai4material_design\n</code></pre> AIS Square (\ud83e\udd497 \u00b7  \u2b50 10 \u00b7 \ud83d\udca4) - A collaborative and open-source platform for sharing AI for Science datasets, models, and workflows. Home of the.. <code>LGPL-3.0</code> <code>community-resource</code> <code>model-repository</code>  - [GitHub](https://github.com/deepmodeling/AIS-Square) (\ud83d\udc68\u200d\ud83d\udcbb 8 \u00b7 \ud83d\udd00 8 \u00b7 \ud83d\udccb 6 - 83% open \u00b7 \u23f1\ufe0f 06.12.2023):      <pre><code>git clone https://github.com/deepmodeling/AIS-Square\n</code></pre> The Perovskite Database Project (\ud83e\udd495 \u00b7  \u2b50 58) - Perovskite Database Project aims at making all perovskite device data, both past and future, available in a form.. <code>Unlicensed</code> <code>community-resource</code>  - [GitHub](https://github.com/Jesperkemist/perovskitedatabase) (\ud83d\udc68\u200d\ud83d\udcbb 2 \u00b7 \ud83d\udd00 18 \u00b7 \u23f1\ufe0f 07.03.2024):      <pre><code>git clone https://github.com/Jesperkemist/perovskitedatabase\n</code></pre> 3DSC Database (\ud83e\udd495 \u00b7  \u2b50 15 \u00b7 \ud83d\udca4) - Repo for the paper publishing the superconductor database with 3D crystal structures. <code>Custom</code> <code>superconductors</code> <code>materials-discovery</code>  - [GitHub](https://github.com/aimat-lab/3DSC) (\ud83d\udd00 4 \u00b7 \u23f1\ufe0f 08.01.2024):      <pre><code>git clone https://github.com/aimat-lab/3DSC\n</code></pre> Show 15 hidden projects...  - ATOM3D (\ud83e\udd4818 \u00b7  \u2b50 300 \u00b7 \ud83d\udc80) - ATOM3D: tasks on molecules in three dimensions. <code>MIT</code> <code>biomolecules</code> <code>benchmarking</code> - OpenKIM (\ud83e\udd4810 \u00b7  \u2b50 31 \u00b7 \ud83d\udc80) - The Open Knowledgebase of Interatomic Models (OpenKIM) aims to be an online resource for standardized testing, long-.. <code>LGPL-2.1</code> <code>model-repository</code> <code>knowledge-base</code> <code>pretrained</code> - ANI-1 Dataset (\ud83e\udd498 \u00b7  \u2b50 96 \u00b7 \ud83d\udc80) - A data set of 20 million calculated off-equilibrium conformations for organic molecules. <code>MIT</code> - MoleculeNet Leaderboard (\ud83e\udd498 \u00b7  \u2b50 88 \u00b7 \ud83d\udc80) -  <code>MIT</code> <code>benchmarking</code> - GEOM (\ud83e\udd497 \u00b7  \u2b50 200 \u00b7 \ud83d\udc80) - GEOM: Energy-annotated molecular conformations. <code>Unlicensed</code> <code>drug-discovery</code> - ANI-1x Datasets (\ud83e\udd496 \u00b7  \u2b50 55 \u00b7 \ud83d\udc80) - The ANI-1ccx and ANI-1x data sets, coupled-cluster and density functional theory properties for organic molecules. <code>MIT</code> - COMP6 Benchmark dataset (\ud83e\udd496 \u00b7  \u2b50 39 \u00b7 \ud83d\udc80) - COMP6 Benchmark dataset for ML potentials. <code>MIT</code> - SciGlass (\ud83e\udd495 \u00b7  \u2b50 10 \u00b7 \ud83d\udc80) - The database contains a vast set of data on the properties of glass materials. <code>MIT</code> - GDB-9-Ex9 and ORNL_AISD-Ex (\ud83e\udd495 \u00b7  \u2b50 6 \u00b7 \ud83d\udc80) - Distributed computing workflow for generation and analysis of large scale molecular datasets obtained running multi-.. <code>Unlicensed</code> - linear-regression-benchmarks (\ud83e\udd495 \u00b7  \u2b50 1 \u00b7 \ud83d\udc80) - Data sets used for linear regression benchmarks. <code>MIT</code> <code>benchmarking</code> <code>single-paper</code> - paper-data-redundancy (\ud83e\udd494 \u00b7  \u2b50 8) - Repo for the paper Exploiting redundancy in large materials datasets for efficient machine learning with less data. <code>BSD-3</code> <code>small-data</code> <code>single-paper</code> - Visual Graph Datasets (\ud83e\udd494 \u00b7  \u2b50 2) - Datasets for the training of graph neural networks (GNNs) and subsequent visualization of attributional explanations.. <code>MIT</code> <code>XAI</code> <code>rep-learn</code> - OPTIMADE providers dashboard (\ud83e\udd494 \u00b7  \u2b50 1) - A dashboard of known providers. <code>Unlicensed</code> - nep-data (\ud83e\udd492 \u00b7  \u2b50 12 \u00b7 \ud83d\udc80) - Data related to the NEP machine-learned potential of GPUMD. <code>Unlicensed</code> <code>ML-IAP</code> <code>MD</code> <code>transport-phenomena</code> - tmQM_wB97MV Dataset (\ud83e\udd492 \u00b7  \u2b50 6) - Code for Applying Large Graph Neural Networks to Predict Transition Metal Complex Energies Using the tmQM_wB97MV.. <code>Unlicensed</code> <code>catalysis</code> <code>rep-learn</code> <p></p>"},{"location":"ref/raw_md/ml_in_comp_mat/#data-structures","title":"Data Structures","text":"<p>Projects that focus on providing data structures used in atomistic machine learning.</p> dpdata (\ud83e\udd4724 \u00b7  \u2b50 200) - A Python package for manipulating atomistic data of software in computational science. <code>LGPL-3.0</code>  - [GitHub](https://github.com/deepmodeling/dpdata) (\ud83d\udc68\u200d\ud83d\udcbb 61 \u00b7 \ud83d\udd00 130 \u00b7 \ud83d\udce6 120 \u00b7 \ud83d\udccb 120 - 28% open \u00b7 \u23f1\ufe0f 20.09.2024):      <pre><code>git clone https://github.com/deepmodeling/dpdata\n</code></pre> - [PyPi](https://pypi.org/project/dpdata) (\ud83d\udce5 44K / month \u00b7 \ud83d\udce6 40 \u00b7 \u23f1\ufe0f 20.09.2024):     <pre><code>pip install dpdata\n</code></pre> - [Conda](https://anaconda.org/deepmodeling/dpdata) (\ud83d\udce5 230 \u00b7 \u23f1\ufe0f 27.09.2023):     <pre><code>conda install -c deepmodeling dpdata\n</code></pre> Metatensor (\ud83e\udd4821 \u00b7  \u2b50 51) - Self-describing sparse tensor data format for atomistic machine learning and beyond. <code>BSD-3</code> <code>Rust</code> <code>C-lang</code> <code>C++</code> <code>Python</code>  - [GitHub](https://github.com/metatensor/metatensor) (\ud83d\udc68\u200d\ud83d\udcbb 22 \u00b7 \ud83d\udd00 15 \u00b7 \ud83d\udce5 27K \u00b7 \ud83d\udce6 11 \u00b7 \ud83d\udccb 210 - 34% open \u00b7 \u23f1\ufe0f 25.09.2024):      <pre><code>git clone https://github.com/lab-cosmo/metatensor\n</code></pre> mp-pyrho (\ud83e\udd4917 \u00b7  \u2b50 36 \u00b7 \ud83d\udca4) - Tools for re-griding volumetric quantum chemistry data for machine-learning purposes. <code>Custom</code> <code>ML-DFT</code>  - [GitHub](https://github.com/materialsproject/pyrho) (\ud83d\udc68\u200d\ud83d\udcbb 8 \u00b7 \ud83d\udd00 7 \u00b7 \ud83d\udce6 24 \u00b7 \ud83d\udccb 4 - 25% open \u00b7 \u23f1\ufe0f 23.02.2024):      <pre><code>git clone https://github.com/materialsproject/pyrho\n</code></pre> - [PyPi](https://pypi.org/project/mp-pyrho) (\ud83d\udce5 14K / month \u00b7 \ud83d\udce6 3 \u00b7 \u23f1\ufe0f 23.02.2024):     <pre><code>pip install mp-pyrho\n</code></pre> dlpack (\ud83e\udd4916 \u00b7  \u2b50 890) - common in-memory tensor structure. <code>Apache-2</code> <code>C++</code>  - [GitHub](https://github.com/dmlc/dlpack) (\ud83d\udc68\u200d\ud83d\udcbb 23 \u00b7 \ud83d\udd00 130 \u00b7 \ud83d\udccb 71 - 40% open \u00b7 \u23f1\ufe0f 26.03.2024):      <pre><code>git clone https://github.com/dmlc/dlpack\n</code></pre> <p></p>"},{"location":"ref/raw_md/ml_in_comp_mat/#density-functional-theory-ml-dft","title":"Density functional theory (ML-DFT)","text":"<p>Projects and models that focus on quantities of DFT, such as density functional approximations (ML-DFA), the charge density, density of states, the Hamiltonian, etc.</p> <p>\ud83d\udd17\u00a0IKS-PIML  - Code and generated data for the paper Inverting the Kohn-Sham equations with physics-informed machine learning.. <code>neural-operator</code> <code>pinn</code> <code>datasets</code> <code>single-paper</code></p> JAX-DFT (\ud83e\udd4725 \u00b7  \u2b50 34K) - This library provides basic building blocks that can construct DFT calculations as a differentiable program. <code>Apache-2</code>  - [GitHub](https://github.com/google-research/google-research) (\ud83d\udc68\u200d\ud83d\udcbb 800 \u00b7 \ud83d\udd00 7.8K \u00b7 \ud83d\udccb 1.8K - 81% open \u00b7 \u23f1\ufe0f 26.09.2024):      <pre><code>git clone https://github.com/google-research/google-research\n</code></pre> MALA (\ud83e\udd4717 \u00b7  \u2b50 81 \u00b7 \ud83d\udcc9) - Materials Learning Algorithms. A framework for machine learning materials properties from first-principles data. <code>BSD-3</code>  - [GitHub](https://github.com/mala-project/mala) (\ud83d\udc68\u200d\ud83d\udcbb 44 \u00b7 \ud83d\udd00 23 \u00b7 \ud83d\udce6 1 \u00b7 \ud83d\udccb 270 - 15% open \u00b7 \u23f1\ufe0f 04.07.2024):      <pre><code>git clone https://github.com/mala-project/mala\n</code></pre> QHNet (\ud83e\udd4713 \u00b7  \u2b50 490) - Artificial Intelligence Research for Science (AIRS). <code>GPL-3.0</code> <code>rep-learn</code>  - [GitHub](https://github.com/divelab/AIRS) (\ud83d\udc68\u200d\ud83d\udcbb 29 \u00b7 \ud83d\udd00 58 \u00b7 \ud83d\udccb 15 - 6% open \u00b7 \u23f1\ufe0f 03.09.2024):      <pre><code>git clone https://github.com/divelab/AIRS\n</code></pre> SALTED (\ud83e\udd4713 \u00b7  \u2b50 30) - Symmetry-Adapted Learning of Three-dimensional Electron Densities. <code>GPL-3.0</code>  - [GitHub](https://github.com/andreagrisafi/SALTED) (\ud83d\udc68\u200d\ud83d\udcbb 17 \u00b7 \ud83d\udd00 4 \u00b7 \ud83d\udccb 6 - 16% open \u00b7 \u23f1\ufe0f 26.09.2024):      <pre><code>git clone https://github.com/andreagrisafi/SALTED\n</code></pre> DeepH-pack (\ud83e\udd4812 \u00b7  \u2b50 220) - Deep neural networks for density functional theory Hamiltonian. <code>LGPL-3.0</code> <code>Julia</code>  - [GitHub](https://github.com/mzjb/DeepH-pack) (\ud83d\udc68\u200d\ud83d\udcbb 8 \u00b7 \ud83d\udd00 44 \u00b7 \ud83d\udccb 51 - 25% open \u00b7 \u23f1\ufe0f 22.05.2024):      <pre><code>git clone https://github.com/mzjb/DeepH-pack\n</code></pre> DeePKS-kit (\ud83e\udd4810 \u00b7  \u2b50 99) - a package for developing machine learning-based chemically accurate energy and density functional models. <code>LGPL-3.0</code>  - [GitHub](https://github.com/deepmodeling/deepks-kit) (\ud83d\udc68\u200d\ud83d\udcbb 7 \u00b7 \ud83d\udd00 35 \u00b7 \ud83d\udccb 19 - 26% open \u00b7 \u23f1\ufe0f 13.04.2024):      <pre><code>git clone https://github.com/deepmodeling/deepks-kit\n</code></pre> Grad DFT (\ud83e\udd4810 \u00b7  \u2b50 73 \u00b7 \ud83d\udca4) - GradDFT is a JAX-based library enabling the differentiable design and experimentation of exchange-correlation.. <code>Apache-2</code>  - [GitHub](https://github.com/XanaduAI/GradDFT) (\ud83d\udc68\u200d\ud83d\udcbb 4 \u00b7 \ud83d\udd00 6 \u00b7 \ud83d\udccb 54 - 20% open \u00b7 \u23f1\ufe0f 13.02.2024):      <pre><code>git clone https://github.com/XanaduAI/GradDFT\n</code></pre> HamGNN (\ud83e\udd488 \u00b7  \u2b50 55) - An E(3) equivariant Graph Neural Network for predicting electronic Hamiltonian matrix. <code>GPL-3.0</code> <code>rep-learn</code> <code>magnetism</code> <code>C-lang</code>  - [GitHub](https://github.com/QuantumLab-ZY/HamGNN) (\ud83d\udc68\u200d\ud83d\udcbb 2 \u00b7 \ud83d\udd00 15 \u00b7 \ud83d\udccb 29 - 79% open \u00b7 \u23f1\ufe0f 26.09.2024):      <pre><code>git clone https://github.com/QuantumLab-ZY/HamGNN\n</code></pre> Q-stack (\ud83e\udd488 \u00b7  \u2b50 14) - Stack of codes for dedicated pre- and post-processing tasks for Quantum Machine Learning (QML). <code>MIT</code> <code>excited-states</code> <code>general-tool</code>  - [GitHub](https://github.com/lcmd-epfl/Q-stack) (\ud83d\udc68\u200d\ud83d\udcbb 7 \u00b7 \ud83d\udd00 5 \u00b7 \ud83d\udccb 29 - 31% open \u00b7 \u23f1\ufe0f 26.09.2024):      <pre><code>git clone https://github.com/lcmd-epfl/Q-stack\n</code></pre> ChargE3Net (\ud83e\udd497 \u00b7  \u2b50 29) - Higher-order equivariant neural networks for charge density prediction in materials. <code>MIT</code> <code>rep-learn</code>  - [GitHub](https://github.com/AIforGreatGood/charge3net) (\ud83d\udc68\u200d\ud83d\udcbb 2 \u00b7 \ud83d\udd00 8 \u00b7 \ud83d\udccb 5 - 40% open \u00b7 \u23f1\ufe0f 15.08.2024):      <pre><code>git clone https://github.com/AIforGreatGood/charge3net\n</code></pre> InfGCN for Electron Density Estimation (\ud83e\udd495 \u00b7  \u2b50 11 \u00b7 \ud83d\udca4) - Official implementation of the NeurIPS 23 spotlight paper of InfGCN. <code>MIT</code> <code>rep-learn</code> <code>neural-operator</code>  - [GitHub](https://github.com/ccr-cheng/InfGCN-pytorch) (\ud83d\udd00 3 \u00b7 \u23f1\ufe0f 05.12.2023):      <pre><code>git clone https://github.com/ccr-cheng/infgcn-pytorch\n</code></pre> Show 21 hidden projects...  - DM21 (\ud83e\udd4720 \u00b7  \u2b50 13K \u00b7 \ud83d\udc80) - This package provides a PySCF interface to the DM21 (DeepMind 21) family of exchange-correlation functionals described.. <code>Apache-2</code> - NeuralXC (\ud83e\udd4810 \u00b7  \u2b50 33 \u00b7 \ud83d\udc80) - Implementation of a machine learned density functional. <code>BSD-3</code> - PROPhet (\ud83e\udd489 \u00b7  \u2b50 62 \u00b7 \ud83d\udc80) - PROPhet is a code to integrate machine learning techniques with first-principles quantum chemistry approaches. <code>GPL-3.0</code> <code>ML-IAP</code> <code>MD</code> <code>single-paper</code> <code>C++</code> - ACEhamiltonians (\ud83e\udd489 \u00b7  \u2b50 12 \u00b7 \ud83d\udc80) - Provides tools for constructing, fitting, and predicting self-consistent Hamiltonian and overlap matrices in solid-.. <code>MIT</code> <code>Julia</code> - Mat2Spec (\ud83e\udd497 \u00b7  \u2b50 27 \u00b7 \ud83d\udc80) - Density of States Prediction for Materials Discovery via Contrastive Learning from Probabilistic Embeddings. <code>MIT</code> <code>spectroscopy</code> - Libnxc (\ud83e\udd497 \u00b7  \u2b50 16 \u00b7 \ud83d\udc80) - A library for using machine-learned exchange-correlation functionals for density-functional theory. <code>MPL-2.0</code> <code>C++</code> <code>Fortran</code> - DeepH-E3 (\ud83e\udd496 \u00b7  \u2b50 70 \u00b7 \ud83d\udc80) - General framework for E(3)-equivariant neural network representation of density functional theory Hamiltonian. <code>MIT</code> <code>magnetism</code> - DeepDFT (\ud83e\udd496 \u00b7  \u2b50 57 \u00b7 \ud83d\udc80) - Official implementation of DeepDFT model. <code>MIT</code> - rho_learn (\ud83e\udd496 \u00b7  \u2b50 4) - A proof-of-concept framework for torch-based learning of the electron density and related scalar fields. <code>MIT</code> - KSR-DFT (\ud83e\udd496 \u00b7  \u2b50 4 \u00b7 \ud83d\udc80) - Kohn-Sham regularizer for machine-learned DFT functionals. <code>Apache-2</code> - xDeepH (\ud83e\udd495 \u00b7  \u2b50 32 \u00b7 \ud83d\udc80) - Extended DeepH (xDeepH) method for magnetic materials. <code>LGPL-3.0</code> <code>magnetism</code> <code>Julia</code> - ML-DFT (\ud83e\udd495 \u00b7  \u2b50 23 \u00b7 \ud83d\udc80) - A package for density functional approximation using machine learning. <code>MIT</code> - charge-density-models (\ud83e\udd494 \u00b7  \u2b50 10 \u00b7 \ud83d\udca4) - Tools to build charge density models using [fairchem](https://github.com/FAIR-Chem/fairchem). <code>MIT</code> <code>rep-learn</code> - gprep (\ud83e\udd494 \u00b7 \ud83d\udc80) - Fitting DFTB repulsive potentials with GPR. <code>MIT</code> <code>single-paper</code> - DeepCDP (\ud83e\udd493 \u00b7  \u2b50 6 \u00b7 \ud83d\udc80) - DeepCDP: Deep learning Charge Density Prediction. <code>Unlicensed</code> - APET (\ud83e\udd493 \u00b7  \u2b50 4 \u00b7 \ud83d\udca4) - Atomic Positional Embedding-based Transformer. <code>GPL-3.0</code> <code>density-of-states</code> <code>transformer</code> - CSNN (\ud83e\udd493 \u00b7  \u2b50 2 \u00b7 \ud83d\udc80) - Primary codebase of CSNN - Concentric Spherical Neural Network for 3D Representation Learning. <code>BSD-3</code> - MALADA (\ud83e\udd493 \u00b7  \u2b50 1 \u00b7 \ud83d\udc80) - MALA Data Acquisition: Helpful tools to build data for MALA. <code>BSD-3</code> - A3MD (\ud83e\udd492 \u00b7  \u2b50 8 \u00b7 \ud83d\udc80) - MPNN-like + Analytic Density Model = Accurate electron densities. <code>Unlicensed</code> <code>rep-learn</code> <code>single-paper</code> - kdft (\ud83e\udd491 \u00b7  \u2b50 2 \u00b7 \ud83d\udc80) - The Kernel Density Functional (KDF) code allows generating ML based DFT functionals. <code>Unlicensed</code> - MLDensity ( \u2b50 2 \u00b7 \ud83d\udc80) - Linear Jacobi-Legendre expansion of the charge density for machine learning-accelerated electronic structure.. <code>Unlicensed</code> <p></p>"},{"location":"ref/raw_md/ml_in_comp_mat/#educational-resources","title":"Educational Resources","text":"<p>Tutorials, guides, cookbooks, recipes, etc.</p> <p>\ud83d\udd17\u00a0AI for Science 101 <code>community-resource</code> <code>rep-learn</code></p> <p>\ud83d\udd17\u00a0AL4MS 2023 workshop tutorials <code>active-learning</code></p> <p>\ud83d\udd17\u00a0Quantum Chemistry in the Age of Machine Learning  - Book, 2022.</p> jarvis-tools-notebooks (\ud83e\udd4712 \u00b7  \u2b50 62) - A Google-Colab Notebook Collection for Materials Design: https://jarvis.nist.gov/. <code>NIST</code>  - [GitHub](https://github.com/JARVIS-Materials-Design/jarvis-tools-notebooks) (\ud83d\udc68\u200d\ud83d\udcbb 5 \u00b7 \ud83d\udd00 26 \u00b7 \u23f1\ufe0f 14.08.2024):      <pre><code>git clone https://github.com/JARVIS-Materials-Design/jarvis-tools-notebooks\n</code></pre> AI4Chemistry course (\ud83e\udd4810 \u00b7  \u2b50 130) - EPFL AI for chemistry course, Spring 2023. https://schwallergroup.github.io/ai4chem_course. <code>MIT</code> <code>chemistry</code>  - [GitHub](https://github.com/schwallergroup/ai4chem_course) (\ud83d\udc68\u200d\ud83d\udcbb 6 \u00b7 \ud83d\udd00 31 \u00b7 \ud83d\udccb 4 - 25% open \u00b7 \u23f1\ufe0f 02.05.2024):      <pre><code>git clone https://github.com/schwallergroup/ai4chem_course\n</code></pre> DSECOP (\ud83e\udd489 \u00b7  \u2b50 43) - This repository contains data science educational materials developed by DSECOP Fellows. <code>CCO-1.0</code>  - [GitHub](https://github.com/GDS-Education-Community-of-Practice/DSECOP) (\ud83d\udc68\u200d\ud83d\udcbb 14 \u00b7 \ud83d\udd00 25 \u00b7 \ud83d\udccb 8 - 12% open \u00b7 \u23f1\ufe0f 26.06.2024):      <pre><code>git clone https://github.com/GDS-Education-Community-of-Practice/DSECOP\n</code></pre> iam-notebooks (\ud83e\udd489 \u00b7  \u2b50 26) - Jupyter notebooks for the lectures of the Introduction to Atomistic Modeling. <code>Apache-2</code>  - [GitHub](https://github.com/ceriottm/iam-notebooks) (\ud83d\udc68\u200d\ud83d\udcbb 6 \u00b7 \ud83d\udd00 5 \u00b7 \u23f1\ufe0f 26.06.2024):      <pre><code>git clone https://github.com/ceriottm/iam-notebooks\n</code></pre> OPTIMADE Tutorial Exercises (\ud83e\udd489 \u00b7  \u2b50 14 \u00b7 \ud83d\udca4) - Tutorial exercises for the OPTIMADE API. <code>MIT</code> <code>datasets</code>  - [GitHub](https://github.com/Materials-Consortia/optimade-tutorial-exercises) (\ud83d\udc68\u200d\ud83d\udcbb 6 \u00b7 \ud83d\udd00 7 \u00b7 \u23f1\ufe0f 27.09.2023):      <pre><code>git clone https://github.com/Materials-Consortia/optimade-tutorial-exercises\n</code></pre> BestPractices (\ud83e\udd488 \u00b7  \u2b50 170 \u00b7 \ud83d\udca4) - Things that you should (and should not) do in your Materials Informatics research. <code>MIT</code>  - [GitHub](https://github.com/anthony-wang/BestPractices) (\ud83d\udc68\u200d\ud83d\udcbb 3 \u00b7 \ud83d\udd00 70 \u00b7 \ud83d\udccb 7 - 71% open \u00b7 \u23f1\ufe0f 17.11.2023):      <pre><code>git clone https://github.com/anthony-wang/BestPractices\n</code></pre> COSMO Software Cookbook (\ud83e\udd488 \u00b7  \u2b50 16) - A cookbook wtih recipes for atomic-scale modeling of materials and molecules. <code>BSD-3</code>  - [GitHub](https://github.com/lab-cosmo/atomistic-cookbook) (\ud83d\udc68\u200d\ud83d\udcbb 10 \u00b7 \ud83d\udd00 1 \u00b7 \ud83d\udccb 12 - 16% open \u00b7 \u23f1\ufe0f 23.09.2024):      <pre><code>git clone https://github.com/lab-cosmo/software-cookbook\n</code></pre> MACE-tutorials (\ud83e\udd496 \u00b7  \u2b50 38) - Another set of tutorials for the MACE interatomic potential by one of the authors. <code>MIT</code> <code>ML-IAP</code> <code>rep-learn</code> <code>MD</code>  - [GitHub](https://github.com/ilyes319/mace-tutorials) (\ud83d\udc68\u200d\ud83d\udcbb 2 \u00b7 \ud83d\udd00 10 \u00b7 \u23f1\ufe0f 16.07.2024):      <pre><code>git clone https://github.com/ilyes319/mace-tutorials\n</code></pre> Show 17 hidden projects...  - Geometric GNN Dojo (\ud83e\udd4712 \u00b7  \u2b50 460 \u00b7 \ud83d\udc80) - New to geometric GNNs: try our practical notebook, prepared for MPhil students at the University of Cambridge. <code>MIT</code> <code>rep-learn</code> - DeepLearningLifeSciences (\ud83e\udd4712 \u00b7  \u2b50 350 \u00b7 \ud83d\udc80) - Example code from the book Deep Learning for the Life Sciences. <code>MIT</code> - Deep Learning for Molecules and Materials Book (\ud83e\udd4811 \u00b7  \u2b50 610 \u00b7 \ud83d\udc80) - Deep learning for molecules and materials book. <code>Custom</code> - RDKit Tutorials (\ud83e\udd488 \u00b7  \u2b50 260 \u00b7 \ud83d\udc80) - Tutorials to learn how to work with the RDKit. <code>Custom</code> - MAChINE (\ud83e\udd497 \u00b7  \u2b50 1 \u00b7 \ud83d\udca4) - Client-Server Web App to introduce usage of ML in materials science to beginners. <code>MIT</code> - Applied AI for Materials (\ud83e\udd496 \u00b7  \u2b50 58 \u00b7 \ud83d\udc80) - Course materials for Applied AI for Materials Science and Engineering. <code>Unlicensed</code> - ML for catalysis tutorials (\ud83e\udd496 \u00b7  \u2b50 8 \u00b7 \ud83d\udc80) - A jupyter book repo for tutorial on how to use OCP ML models for catalysis. <code>MIT</code> - AI4Science101 (\ud83e\udd495 \u00b7  \u2b50 83 \u00b7 \ud83d\udc80) - AI for Science. <code>Unlicensed</code> - Machine Learning for Materials Hard and Soft (\ud83e\udd495 \u00b7  \u2b50 34 \u00b7 \ud83d\udc80) - ESI-DCAFM-TACO-VDSP Summer School on Machine Learning for Materials Hard and Soft. <code>Unlicensed</code> - Data Handling, DoE and Statistical Analysis for Material Chemists (\ud83e\udd495 \u00b7  \u2b50 1 \u00b7 \ud83d\udc80) - Notebooks for workshops of DoE course, hosted by the Computational Materials Chemistry group at Uppsala University. <code>GPL-3.0</code> - ML-in-chemistry-101 (\ud83e\udd494 \u00b7  \u2b50 68 \u00b7 \ud83d\udc80) - The course materials for Machine Learning in Chemistry 101. <code>Unlicensed</code> - chemrev-gpr (\ud83e\udd494 \u00b7  \u2b50 6 \u00b7 \ud83d\udc80) - Notebooks accompanying the paper on GPR in materials and molecules in Chemical Reviews 2020. <code>Unlicensed</code> - AI4ChemMat Hands-On Series (\ud83e\udd494 \u00b7  \u2b50 1) - Hands-On Series organized by Chemistry and Materials working group at Argonne Nat Lab. <code>MPL-2.0</code> - PiNN Lab (\ud83e\udd493 \u00b7  \u2b50 2 \u00b7 \ud83d\udc80) - Material for running a lab session on atomic neural networks. <code>GPL-3.0</code> - MLDensity_tutorial (\ud83e\udd492 \u00b7  \u2b50 9 \u00b7 \ud83d\udc80) - Tutorial files to work with ML for the charge density in molecules and solids. <code>Unlicensed</code> - LAMMPS-style pair potentials with GAP (\ud83e\udd492 \u00b7  \u2b50 4 \u00b7 \ud83d\udc80) - A tutorial on how to create LAMMPS-style pair potentials and use them in combination with GAP potentials to run MD.. <code>Unlicensed</code> <code>ML-IAP</code> <code>MD</code> <code>rep-eng</code> - MALA Tutorial (\ud83e\udd492 \u00b7  \u2b50 2 \u00b7 \ud83d\udca4) - A full MALA hands-on tutorial. <code>Unlicensed</code> <p></p>"},{"location":"ref/raw_md/ml_in_comp_mat/#explainable-artificial-intelligence-xai","title":"Explainable Artificial intelligence (XAI)","text":"<p>Projects that focus on explainability and model interpretability in atomistic ML.</p> exmol (\ud83e\udd4718 \u00b7  \u2b50 280 \u00b7 \ud83d\udca4) - Explainer for black box models that predict molecule properties. <code>MIT</code>  - [GitHub](https://github.com/ur-whitelab/exmol) (\ud83d\udc68\u200d\ud83d\udcbb 7 \u00b7 \ud83d\udd00 40 \u00b7 \ud83d\udce6 20 \u00b7 \ud83d\udccb 69 - 15% open \u00b7 \u23f1\ufe0f 04.12.2023):      <pre><code>git clone https://github.com/ur-whitelab/exmol\n</code></pre> - [PyPi](https://pypi.org/project/exmol) (\ud83d\udce5 890 / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 03.06.2022):     <pre><code>pip install exmol\n</code></pre> MEGAN: Multi Explanation Graph Attention Student (\ud83e\udd496 \u00b7  \u2b50 5) - Minimal implementation of graph attention student model architecture. <code>MIT</code> <code>rep-learn</code>  - [GitHub](https://github.com/aimat-lab/graph_attention_student) (\ud83d\udc68\u200d\ud83d\udcbb 2 \u00b7 \ud83d\udd00 1 \u00b7 \u23f1\ufe0f 19.08.2024):      <pre><code>git clone https://github.com/aimat-lab/graph_attention_student\n</code></pre> Show 1 hidden projects...  - Linear vs blackbox (\ud83e\udd493 \u00b7  \u2b50 2 \u00b7 \ud83d\udc80) - Code and data related to the publication: Interpretable models for extrapolation in scientific machine learning. <code>MIT</code> <code>XAI</code> <code>single-paper</code> <code>rep-eng</code> <p></p>"},{"location":"ref/raw_md/ml_in_comp_mat/#electronic-structure-methods-ml-esm","title":"Electronic structure methods (ML-ESM)","text":"<p>Projects and models that focus on quantities of electronic structure methods, which do not fit into either of the categories ML-WFT or ML-DFT.</p> Show 5 hidden projects...  - QDF for molecule (\ud83e\udd478 \u00b7  \u2b50 200 \u00b7 \ud83d\udc80) - Quantum deep field: data-driven wave function, electron density generation, and energy prediction and extrapolation.. <code>MIT</code> - QMLearn (\ud83e\udd485 \u00b7  \u2b50 11 \u00b7 \ud83d\udc80) - Quantum Machine Learning by learning one-body reduced density matrices in the AO basis... <code>MIT</code> - q-pac (\ud83e\udd485 \u00b7  \u2b50 4 \u00b7 \ud83d\udc80) - Kernel charge equilibration method. <code>MIT</code> <code>electrostatics</code> - halex (\ud83e\udd485 \u00b7  \u2b50 3 \u00b7 \ud83d\udca4) - Hamiltonian Learning for Excited States https://doi.org/10.48550/arXiv.2311.00844. <code>Unlicensed</code> <code>excited-states</code> - e3psi (\ud83e\udd493 \u00b7  \u2b50 3 \u00b7 \ud83d\udca4) - Equivariant machine learning library for learning from electronic structures. <code>LGPL-3.0</code> <p></p>"},{"location":"ref/raw_md/ml_in_comp_mat/#general-tools","title":"General Tools","text":"<p>General tools for atomistic machine learning.</p> DeepChem (\ud83e\udd4736 \u00b7  \u2b50 5.4K) - Democratizing Deep-Learning for Drug Discovery, Quantum Chemistry, Materials Science and Biology. <code>MIT</code>  - [GitHub](https://github.com/deepchem/deepchem) (\ud83d\udc68\u200d\ud83d\udcbb 250 \u00b7 \ud83d\udd00 1.7K \u00b7 \ud83d\udce6 430 \u00b7 \ud83d\udccb 1.9K - 33% open \u00b7 \u23f1\ufe0f 20.09.2024):      <pre><code>git clone https://github.com/deepchem/deepchem\n</code></pre> - [PyPi](https://pypi.org/project/deepchem) (\ud83d\udce5 40K / month \u00b7 \ud83d\udce6 13 \u00b7 \u23f1\ufe0f 20.09.2024):     <pre><code>pip install deepchem\n</code></pre> - [Conda](https://anaconda.org/conda-forge/deepchem) (\ud83d\udce5 110K \u00b7 \u23f1\ufe0f 05.04.2024):     <pre><code>conda install -c conda-forge deepchem\n</code></pre> - [Docker Hub](https://hub.docker.com/r/deepchemio/deepchem) (\ud83d\udce5 7.6K \u00b7 \u2b50 5 \u00b7 \u23f1\ufe0f 20.09.2024):     <pre><code>docker pull deepchemio/deepchem\n</code></pre> RDKit (\ud83e\udd4735 \u00b7  \u2b50 2.6K) -  <code>BSD-3</code> <code>C++</code>  - [GitHub](https://github.com/rdkit/rdkit) (\ud83d\udc68\u200d\ud83d\udcbb 230 \u00b7 \ud83d\udd00 860 \u00b7 \ud83d\udce5 1.1K \u00b7 \ud83d\udce6 3 \u00b7 \ud83d\udccb 3.4K - 29% open \u00b7 \u23f1\ufe0f 26.09.2024):      <pre><code>git clone https://github.com/rdkit/rdkit\n</code></pre> - [PyPi](https://pypi.org/project/rdkit) (\ud83d\udce5 1.8M / month \u00b7 \ud83d\udce6 710 \u00b7 \u23f1\ufe0f 07.08.2024):     <pre><code>pip install rdkit\n</code></pre> - [Conda](https://anaconda.org/rdkit/rdkit) (\ud83d\udce5 2.6M \u00b7 \u23f1\ufe0f 16.06.2023):     <pre><code>conda install -c rdkit rdkit\n</code></pre> Matminer (\ud83e\udd4728 \u00b7  \u2b50 470) - Data mining for materials science. <code>Custom</code>  - [GitHub](https://github.com/hackingmaterials/matminer) (\ud83d\udc68\u200d\ud83d\udcbb 54 \u00b7 \ud83d\udd00 190 \u00b7 \ud83d\udce6 320 \u00b7 \ud83d\udccb 230 - 12% open \u00b7 \u23f1\ufe0f 23.09.2024):      <pre><code>git clone https://github.com/hackingmaterials/matminer\n</code></pre> - [PyPi](https://pypi.org/project/matminer) (\ud83d\udce5 13K / month \u00b7 \ud83d\udce6 58 \u00b7 \u23f1\ufe0f 27.03.2024):     <pre><code>pip install matminer\n</code></pre> - [Conda](https://anaconda.org/conda-forge/matminer) (\ud83d\udce5 70K \u00b7 \u23f1\ufe0f 28.03.2024):     <pre><code>conda install -c conda-forge matminer\n</code></pre> QUIP (\ud83e\udd4826 \u00b7  \u2b50 350) - libAtoms/QUIP molecular dynamics framework: https://libatoms.github.io. <code>GPL-2.0</code> <code>MD</code> <code>ML-IAP</code> <code>rep-eng</code> <code>Fortran</code>  - [GitHub](https://github.com/libAtoms/QUIP) (\ud83d\udc68\u200d\ud83d\udcbb 85 \u00b7 \ud83d\udd00 120 \u00b7 \ud83d\udce5 670 \u00b7 \ud83d\udce6 42 \u00b7 \ud83d\udccb 470 - 22% open \u00b7 \u23f1\ufe0f 15.08.2024):      <pre><code>git clone https://github.com/libAtoms/QUIP\n</code></pre> - [PyPi](https://pypi.org/project/quippy-ase) (\ud83d\udce5 7.3K / month \u00b7 \ud83d\udce6 4 \u00b7 \u23f1\ufe0f 15.01.2023):     <pre><code>pip install quippy-ase\n</code></pre> - [Docker Hub](https://hub.docker.com/r/libatomsquip/quip) (\ud83d\udce5 9.9K \u00b7 \u2b50 4 \u00b7 \u23f1\ufe0f 24.04.2023):     <pre><code>docker pull libatomsquip/quip\n</code></pre> MAML (\ud83e\udd4824 \u00b7  \u2b50 360) - Python for Materials Machine Learning, Materials Descriptors, Machine Learning Force Fields, Deep Learning, etc. <code>BSD-3</code>  - [GitHub](https://github.com/materialsvirtuallab/maml) (\ud83d\udc68\u200d\ud83d\udcbb 33 \u00b7 \ud83d\udd00 77 \u00b7 \ud83d\udce6 10 \u00b7 \ud83d\udccb 71 - 12% open \u00b7 \u23f1\ufe0f 18.09.2024):      <pre><code>git clone https://github.com/materialsvirtuallab/maml\n</code></pre> - [PyPi](https://pypi.org/project/maml) (\ud83d\udce5 420 / month \u00b7 \ud83d\udce6 2 \u00b7 \u23f1\ufe0f 13.06.2024):     <pre><code>pip install maml\n</code></pre> JARVIS-Tools (\ud83e\udd4823 \u00b7  \u2b50 300 \u00b7 \ud83d\udcc9) - JARVIS-Tools: an open-source software package for data-driven atomistic materials design. Publications:.. <code>Custom</code>  - [GitHub](https://github.com/usnistgov/jarvis) (\ud83d\udc68\u200d\ud83d\udcbb 15 \u00b7 \ud83d\udd00 120 \u00b7 \ud83d\udce6 97 \u00b7 \ud83d\udccb 90 - 50% open \u00b7 \u23f1\ufe0f 07.09.2024):      <pre><code>git clone https://github.com/usnistgov/jarvis\n</code></pre> - [PyPi](https://pypi.org/project/jarvis-tools) (\ud83d\udce5 20K / month \u00b7 \ud83d\udce6 31 \u00b7 \u23f1\ufe0f 07.09.2024):     <pre><code>pip install jarvis-tools\n</code></pre> - [Conda](https://anaconda.org/conda-forge/jarvis-tools) (\ud83d\udce5 77K \u00b7 \u23f1\ufe0f 07.09.2024):     <pre><code>conda install -c conda-forge jarvis-tools\n</code></pre> MAST-ML (\ud83e\udd4819 \u00b7  \u2b50 100) - MAterials Simulation Toolkit for Machine Learning (MAST-ML). <code>MIT</code>  - [GitHub](https://github.com/uw-cmg/MAST-ML) (\ud83d\udc68\u200d\ud83d\udcbb 18 \u00b7 \ud83d\udd00 58 \u00b7 \ud83d\udce5 120 \u00b7 \ud83d\udce6 43 \u00b7 \ud83d\udccb 220 - 14% open \u00b7 \u23f1\ufe0f 17.04.2024):      <pre><code>git clone https://github.com/uw-cmg/MAST-ML\n</code></pre> Scikit-Matter (\ud83e\udd4818 \u00b7  \u2b50 76) - A collection of scikit-learn compatible utilities that implement methods born out of the materials science and.. <code>BSD-3</code> <code>scikit-learn</code>  - [GitHub](https://github.com/scikit-learn-contrib/scikit-matter) (\ud83d\udc68\u200d\ud83d\udcbb 15 \u00b7 \ud83d\udd00 20 \u00b7 \ud83d\udce6 10 \u00b7 \ud83d\udccb 70 - 20% open \u00b7 \u23f1\ufe0f 06.08.2024):      <pre><code>git clone https://github.com/scikit-learn-contrib/scikit-matter\n</code></pre> - [PyPi](https://pypi.org/project/skmatter) (\ud83d\udce5 1.8K / month \u00b7 \u23f1\ufe0f 24.08.2023):     <pre><code>pip install skmatter\n</code></pre> - [Conda](https://anaconda.org/conda-forge/skmatter) (\ud83d\udce5 2.2K \u00b7 \u23f1\ufe0f 24.08.2023):     <pre><code>conda install -c conda-forge skmatter\n</code></pre> XenonPy (\ud83e\udd4816 \u00b7  \u2b50 130) - XenonPy is a Python Software for Materials Informatics. <code>BSD-3</code>  - [GitHub](https://github.com/yoshida-lab/XenonPy) (\ud83d\udc68\u200d\ud83d\udcbb 10 \u00b7 \ud83d\udd00 57 \u00b7 \ud83d\udce5 1.4K \u00b7 \ud83d\udccb 87 - 24% open \u00b7 \u23f1\ufe0f 21.04.2024):      <pre><code>git clone https://github.com/yoshida-lab/XenonPy\n</code></pre> - [PyPi](https://pypi.org/project/xenonpy) (\ud83d\udce5 590 / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 31.10.2022):     <pre><code>pip install xenonpy\n</code></pre> MLatom (\ud83e\udd4816 \u00b7  \u2b50 46) - AI-enhanced computational chemistry. <code>MIT</code> <code>UIP</code> <code>ML-IAP</code> <code>MD</code> <code>ML-DFT</code> <code>ML-ESM</code> <code>transfer-learning</code> <code>active-learning</code> <code>spectroscopy</code> <code>structure-optimization</code>  - [GitHub](https://github.com/dralgroup/mlatom) (\ud83d\udc68\u200d\ud83d\udcbb 3 \u00b7 \ud83d\udd00 9 \u00b7 \ud83d\udccb 4 - 25% open \u00b7 \u23f1\ufe0f 23.09.2024):      <pre><code>git clone https://github.com/dralgroup/mlatom\n</code></pre> - [PyPi](https://pypi.org/project/mlatom) (\ud83d\udce5 1.4K / month \u00b7 \u23f1\ufe0f 23.09.2024):     <pre><code>pip install mlatom\n</code></pre> Artificial Intelligence for Science (AIRS) (\ud83e\udd4913 \u00b7  \u2b50 490) - Artificial Intelligence Research for Science (AIRS). <code>GPL-3.0 license</code> <code>rep-learn</code> <code>generative</code> <code>ML-IAP</code> <code>MD</code> <code>ML-DFT</code> <code>ML-WFT</code> <code>biomolecules</code>  - [GitHub](https://github.com/divelab/AIRS) (\ud83d\udc68\u200d\ud83d\udcbb 29 \u00b7 \ud83d\udd00 58 \u00b7 \ud83d\udccb 15 - 6% open \u00b7 \u23f1\ufe0f 03.09.2024):      <pre><code>git clone https://github.com/divelab/AIRS\n</code></pre> Equisolve (\ud83e\udd496 \u00b7  \u2b50 5 \u00b7 \ud83d\udca4) - A ML toolkit package utilizing the metatensor data format to build models for the prediction of equivariant properties.. <code>BSD-3</code> <code>ML-IAP</code>  - [GitHub](https://github.com/lab-cosmo/equisolve) (\ud83d\udc68\u200d\ud83d\udcbb 6 \u00b7 \ud83d\udd00 1 \u00b7 \ud83d\udccb 23 - 82% open \u00b7 \u23f1\ufe0f 27.10.2023):      <pre><code>git clone https://github.com/lab-cosmo/equisolve\n</code></pre> Show 10 hidden projects...  - QML (\ud83e\udd4816 \u00b7  \u2b50 200 \u00b7 \ud83d\udc80) - QML: Quantum Machine Learning. <code>MIT</code> - Automatminer (\ud83e\udd4915 \u00b7  \u2b50 140 \u00b7 \ud83d\udc80) - An automatic engine for predicting materials properties. <code>Custom</code> <code>autoML</code> - AMPtorch (\ud83e\udd4911 \u00b7  \u2b50 59 \u00b7 \ud83d\udc80) - AMPtorch: Atomistic Machine Learning Package (AMP) - PyTorch. <code>GPL-3.0</code> - OpenChem (\ud83e\udd4910 \u00b7  \u2b50 670 \u00b7 \ud83d\udc80) - OpenChem: Deep Learning toolkit for Computational Chemistry and Drug Design Research. <code>MIT</code> - JAXChem (\ud83e\udd497 \u00b7  \u2b50 77 \u00b7 \ud83d\udc80) - JAXChem is a JAX-based deep learning library for complex and versatile chemical modeling. <code>MIT</code> - uncertainty_benchmarking (\ud83e\udd497 \u00b7  \u2b50 39 \u00b7 \ud83d\udc80) - Various code/notebooks to benchmark different ways we could estimate uncertainty in ML predictions. <code>Unlicensed</code> <code>benchmarking</code> <code>probabilistic</code> - torchchem (\ud83e\udd497 \u00b7  \u2b50 34 \u00b7 \ud83d\udc80) - An experimental repo for experimenting with PyTorch models. <code>MIT</code> - ACEatoms (\ud83e\udd494 \u00b7  \u2b50 2 \u00b7 \ud83d\udc80) - Generic code for modelling atomic properties using ACE. <code>Custom</code> <code>Julia</code> - Magpie (\ud83e\udd493) - Materials Agnostic Platform for Informatics and Exploration (Magpie). <code>MIT</code> <code>Java</code> - quantum-structure-ml (\ud83e\udd492 \u00b7  \u2b50 2 \u00b7 \ud83d\udc80) - Multi-class classification model for predicting the magnetic order of magnetic structures and a binary classification.. <code>Unlicensed</code> <code>magnetism</code> <code>benchmarking</code> <p></p>"},{"location":"ref/raw_md/ml_in_comp_mat/#generative-models","title":"Generative Models","text":"<p>Projects that implement generative models for atomistic ML.</p> GT4SD (\ud83e\udd4719 \u00b7  \u2b50 330) - GT4SD, an open-source library to accelerate hypothesis generation in the scientific discovery process. <code>MIT</code> <code>pretrained</code> <code>drug-discovery</code> <code>rep-learn</code>  - [GitHub](https://github.com/GT4SD/gt4sd-core) (\ud83d\udc68\u200d\ud83d\udcbb 20 \u00b7 \ud83d\udd00 68 \u00b7 \ud83d\udccb 110 - 12% open \u00b7 \u23f1\ufe0f 12.09.2024):      <pre><code>git clone https://github.com/GT4SD/gt4sd-core\n</code></pre> - [PyPi](https://pypi.org/project/gt4sd) (\ud83d\udce5 1.6K / month \u00b7 \u23f1\ufe0f 12.09.2024):     <pre><code>pip install gt4sd\n</code></pre> MoLeR (\ud83e\udd4715 \u00b7  \u2b50 260 \u00b7 \ud83d\udca4) - Implementation of MoLeR: a generative model of molecular graphs which supports scaffold-constrained generation. <code>MIT</code>  - [GitHub](https://github.com/microsoft/molecule-generation) (\ud83d\udc68\u200d\ud83d\udcbb 5 \u00b7 \ud83d\udd00 42 \u00b7 \ud83d\udccb 39 - 23% open \u00b7 \u23f1\ufe0f 03.01.2024):      <pre><code>git clone https://github.com/microsoft/molecule-generation\n</code></pre> - [PyPi](https://pypi.org/project/molecule-generation) (\ud83d\udce5 310 / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 05.01.2024):     <pre><code>pip install molecule-generation\n</code></pre> PMTransformer (\ud83e\udd4715 \u00b7  \u2b50 85) - Universal Transfer Learning in Porous Materials, including MOFs. <code>MIT</code> <code>transfer-learning</code> <code>pretrained</code> <code>transformer</code>  - [GitHub](https://github.com/hspark1212/MOFTransformer) (\ud83d\udc68\u200d\ud83d\udcbb 2 \u00b7 \ud83d\udd00 12 \u00b7 \ud83d\udce6 6 \u00b7 \u23f1\ufe0f 20.06.2024):      <pre><code>git clone https://github.com/hspark1212/MOFTransformer\n</code></pre> - [PyPi](https://pypi.org/project/moftransformer) (\ud83d\udce5 460 / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 20.06.2024):     <pre><code>pip install moftransformer\n</code></pre> SchNetPack G-SchNet (\ud83e\udd4814 \u00b7  \u2b50 46) - G-SchNet extension for SchNetPack. <code>MIT</code>  - [GitHub](https://github.com/atomistic-machine-learning/schnetpack-gschnet) (\ud83d\udc68\u200d\ud83d\udcbb 3 \u00b7 \ud83d\udd00 8 \u00b7 \u23f1\ufe0f 05.09.2024):      <pre><code>git clone https://github.com/atomistic-machine-learning/schnetpack-gschnet\n</code></pre> SiMGen (\ud83e\udd489 \u00b7  \u2b50 12 \u00b7 \ud83d\udca4) - Zero Shot Molecular Generation via Similarity Kernels. <code>MIT</code> <code>viz</code>  - [GitHub](https://github.com/RokasEl/simgen) (\ud83d\udc68\u200d\ud83d\udcbb 4 \u00b7 \ud83d\udd00 2 \u00b7 \ud83d\udce6 1 \u00b7 \ud83d\udccb 4 - 25% open \u00b7 \u23f1\ufe0f 15.02.2024):      <pre><code>git clone https://github.com/RokasEl/simgen\n</code></pre> - [PyPi](https://pypi.org/project/simgen) (\ud83d\udce5 38 / month \u00b7 \u23f1\ufe0f 14.02.2024):     <pre><code>pip install simgen\n</code></pre> COATI (\ud83e\udd495 \u00b7  \u2b50 98) - COATI: multi-modal contrastive pre-training for representing and traversing chemical space. <code>Apache-2</code> <code>drug-discovery</code> <code>multimodal</code> <code>pretrained</code> <code>rep-learn</code>  - [GitHub](https://github.com/terraytherapeutics/COATI) (\ud83d\udc68\u200d\ud83d\udcbb 5 \u00b7 \ud83d\udd00 5 \u00b7 \ud83d\udccb 3 - 33% open \u00b7 \u23f1\ufe0f 23.03.2024):      <pre><code>git clone https://github.com/terraytherapeutics/COATI\n</code></pre> Show 8 hidden projects...  - synspace (\ud83e\udd4813 \u00b7  \u2b50 35 \u00b7 \ud83d\udc80) - Synthesis generative model. <code>MIT</code> - EDM (\ud83e\udd489 \u00b7  \u2b50 430 \u00b7 \ud83d\udc80) - E(3) Equivariant Diffusion Model for Molecule Generation in 3D. <code>MIT</code> - G-SchNet (\ud83e\udd498 \u00b7  \u2b50 130 \u00b7 \ud83d\udc80) - G-SchNet - a generative model for 3d molecular structures. <code>MIT</code> - bVAE-IM (\ud83e\udd498 \u00b7  \u2b50 11 \u00b7 \ud83d\udc80) - Implementation of Chemical Design with GPU-based Ising Machine. <code>MIT</code> <code>QML</code> <code>single-paper</code> - cG-SchNet (\ud83e\udd497 \u00b7  \u2b50 52 \u00b7 \ud83d\udc80) - cG-SchNet - a conditional generative neural network for 3d molecular structures. <code>MIT</code> - rxngenerator (\ud83e\udd497 \u00b7  \u2b50 11 \u00b7 \ud83d\udc80) - A generative model for molecular generation via multi-step chemical reactions. <code>MIT</code> - MolSLEPA (\ud83e\udd495 \u00b7  \u2b50 5 \u00b7 \ud83d\udc80) - Interpretable Fragment-based Molecule Design with Self-learning Entropic Population Annealing. <code>MIT</code> <code>XAI</code> - Mapping out phase diagrams with generative classifiers (\ud83e\udd494 \u00b7  \u2b50 7 \u00b7 \ud83d\udc80) - Repository for our ``Mapping out phase diagrams with generative models paper. <code>MIT</code> <code>phase-transition</code> <p></p>"},{"location":"ref/raw_md/ml_in_comp_mat/#interatomic-potentials-ml-iap","title":"Interatomic Potentials (ML-IAP)","text":"<p>Machine learning interatomic potentials (aka ML-IAP, MLIAP, MLIP, MLP) and force fields (ML-FF) for molecular dynamics.</p> DeePMD-kit (\ud83e\udd4727 \u00b7  \u2b50 1.5K) - A deep learning package for many-body potential energy representation and molecular dynamics. <code>LGPL-3.0</code> <code>C++</code>  - [GitHub](https://github.com/deepmodeling/deepmd-kit) (\ud83d\udc68\u200d\ud83d\udcbb 69 \u00b7 \ud83d\udd00 500 \u00b7 \ud83d\udce5 40K \u00b7 \ud83d\udce6 16 \u00b7 \ud83d\udccb 780 - 12% open \u00b7 \u23f1\ufe0f 17.09.2024):      <pre><code>git clone https://github.com/deepmodeling/deepmd-kit\n</code></pre> - [PyPi](https://pypi.org/project/deepmd-kit) (\ud83d\udce5 2.9K / month \u00b7 \ud83d\udce6 4 \u00b7 \u23f1\ufe0f 25.09.2024):     <pre><code>pip install deepmd-kit\n</code></pre> - [Conda](https://anaconda.org/deepmodeling/deepmd-kit) (\ud83d\udce5 1.3K \u00b7 \u23f1\ufe0f 06.04.2024):     <pre><code>conda install -c deepmodeling deepmd-kit\n</code></pre> - [Docker Hub](https://hub.docker.com/r/deepmodeling/deepmd-kit) (\ud83d\udce5 2.9K \u00b7 \u2b50 1 \u00b7 \u23f1\ufe0f 27.07.2024):     <pre><code>docker pull deepmodeling/deepmd-kit\n</code></pre> NequIP (\ud83e\udd4724 \u00b7  \u2b50 610) - NequIP is a code for building E(3)-equivariant interatomic potentials. <code>MIT</code>  - [GitHub](https://github.com/mir-group/nequip) (\ud83d\udc68\u200d\ud83d\udcbb 11 \u00b7 \ud83d\udd00 130 \u00b7 \ud83d\udce6 25 \u00b7 \ud83d\udccb 92 - 28% open \u00b7 \u23f1\ufe0f 09.07.2024):      <pre><code>git clone https://github.com/mir-group/nequip\n</code></pre> - [PyPi](https://pypi.org/project/nequip) (\ud83d\udce5 2.3K / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 09.07.2024):     <pre><code>pip install nequip\n</code></pre> - [Conda](https://anaconda.org/conda-forge/nequip) (\ud83d\udce5 5.9K \u00b7 \u23f1\ufe0f 10.07.2024):     <pre><code>conda install -c conda-forge nequip\n</code></pre> TorchANI (\ud83e\udd4724 \u00b7  \u2b50 460 \u00b7 \ud83d\udca4) - Accurate Neural Network Potential on PyTorch. <code>MIT</code>  - [GitHub](https://github.com/aiqm/torchani) (\ud83d\udc68\u200d\ud83d\udcbb 19 \u00b7 \ud83d\udd00 130 \u00b7 \ud83d\udce6 42 \u00b7 \ud83d\udccb 170 - 13% open \u00b7 \u23f1\ufe0f 14.11.2023):      <pre><code>git clone https://github.com/aiqm/torchani\n</code></pre> - [PyPi](https://pypi.org/project/torchani) (\ud83d\udce5 2.9K / month \u00b7 \ud83d\udce6 4 \u00b7 \u23f1\ufe0f 14.11.2023):     <pre><code>pip install torchani\n</code></pre> - [Conda](https://anaconda.org/conda-forge/torchani) (\ud83d\udce5 480K \u00b7 \u23f1\ufe0f 11.09.2024):     <pre><code>conda install -c conda-forge torchani\n</code></pre> MACE (\ud83e\udd4722 \u00b7  \u2b50 490) - MACE - Fast and accurate machine learning interatomic potentials with higher order equivariant message passing. <code>MIT</code>  - [GitHub](https://github.com/ACEsuit/mace) (\ud83d\udc68\u200d\ud83d\udcbb 39 \u00b7 \ud83d\udd00 180 \u00b7 \ud83d\udccb 270 - 26% open \u00b7 \u23f1\ufe0f 18.09.2024):      <pre><code>git clone https://github.com/ACEsuit/mace\n</code></pre> TorchMD-NET (\ud83e\udd4722 \u00b7  \u2b50 320 \u00b7 \ud83d\udcc9) - Training neural network potentials. <code>MIT</code> <code>MD</code> <code>rep-learn</code> <code>transformer</code> <code>pretrained</code>  - [GitHub](https://github.com/torchmd/torchmd-net) (\ud83d\udc68\u200d\ud83d\udcbb 16 \u00b7 \ud83d\udd00 71 \u00b7 \ud83d\udccb 120 - 28% open \u00b7 \u23f1\ufe0f 28.08.2024):      <pre><code>git clone https://github.com/torchmd/torchmd-net\n</code></pre> - [Conda](https://anaconda.org/conda-forge/torchmd-net) (\ud83d\udce5 170K \u00b7 \u23f1\ufe0f 12.09.2024):     <pre><code>conda install -c conda-forge torchmd-net\n</code></pre> DP-GEN (\ud83e\udd4722 \u00b7  \u2b50 300) - The deep potential generator to generate a deep-learning based model of interatomic potential energy and force field. <code>LGPL-3.0</code> <code>workflows</code>  - [GitHub](https://github.com/deepmodeling/dpgen) (\ud83d\udc68\u200d\ud83d\udcbb 64 \u00b7 \ud83d\udd00 170 \u00b7 \ud83d\udce5 1.8K \u00b7 \ud83d\udce6 6 \u00b7 \ud83d\udccb 300 - 11% open \u00b7 \u23f1\ufe0f 10.04.2024):      <pre><code>git clone https://github.com/deepmodeling/dpgen\n</code></pre> - [PyPi](https://pypi.org/project/dpgen) (\ud83d\udce5 650 / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 10.04.2024):     <pre><code>pip install dpgen\n</code></pre> - [Conda](https://anaconda.org/deepmodeling/dpgen) (\ud83d\udce5 210 \u00b7 \u23f1\ufe0f 16.06.2023):     <pre><code>conda install -c deepmodeling dpgen\n</code></pre> GPUMD (\ud83e\udd4821 \u00b7  \u2b50 450 \u00b7 \ud83d\udcc9) - GPUMD is a highly efficient general-purpose molecular dynamic (MD) package and enables machine-learned potentials.. <code>GPL-3.0</code> <code>MD</code> <code>C++</code> <code>electrostatics</code>  - [GitHub](https://github.com/brucefan1983/GPUMD) (\ud83d\udc68\u200d\ud83d\udcbb 34 \u00b7 \ud83d\udd00 110 \u00b7 \ud83d\udccb 190 - 12% open \u00b7 \u23f1\ufe0f 21.09.2024):      <pre><code>git clone https://github.com/brucefan1983/GPUMD\n</code></pre> fairchem (\ud83e\udd4819 \u00b7  \u2b50 770) - FAIR Chemistrys library of machine learning methods for chemistry. Formerly known as Open Catalyst Project (ocp). <code>Unlicensed</code> <code>pretrained</code> <code>rep-learn</code> <code>catalysis</code>  - [GitHub](https://github.com/FAIR-Chem/fairchem) (\ud83d\udc68\u200d\ud83d\udcbb 42 \u00b7 \ud83d\udd00 230 \u00b7 \ud83d\udccb 200 - 6% open \u00b7 \u23f1\ufe0f 24.09.2024):      <pre><code>git clone https://github.com/FAIR-Chem/fairchem\n</code></pre> apax (\ud83e\udd4818 \u00b7  \u2b50 15) - A flexible and performant framework for training machine learning potentials. <code>MIT</code>  - [GitHub](https://github.com/apax-hub/apax) (\ud83d\udc68\u200d\ud83d\udcbb 7 \u00b7 \ud83d\udd00 2 \u00b7 \ud83d\udce6 2 \u00b7 \ud83d\udccb 120 - 12% open \u00b7 \u23f1\ufe0f 26.09.2024):      <pre><code>git clone https://github.com/apax-hub/apax\n</code></pre> - [PyPi](https://pypi.org/project/apax) (\ud83d\udce5 240 / month \u00b7 \u23f1\ufe0f 17.09.2024):     <pre><code>pip install apax\n</code></pre> Neural Force Field (\ud83e\udd4817 \u00b7  \u2b50 230) - Neural Network Force Field based on PyTorch. <code>MIT</code> <code>pretrained</code>  - [GitHub](https://github.com/learningmatter-mit/NeuralForceField) (\ud83d\udc68\u200d\ud83d\udcbb 41 \u00b7 \ud83d\udd00 47 \u00b7 \ud83d\udccb 20 - 10% open \u00b7 \u23f1\ufe0f 24.09.2024):      <pre><code>git clone https://github.com/learningmatter-mit/NeuralForceField\n</code></pre> wfl (\ud83e\udd4816 \u00b7  \u2b50 31) - Workflow is a Python toolkit for building interatomic potential creation and atomistic simulation workflows. <code>GPL-2.0</code> <code>workflows</code> <code>HTC</code>  - [GitHub](https://github.com/libAtoms/workflow) (\ud83d\udc68\u200d\ud83d\udcbb 19 \u00b7 \ud83d\udd00 18 \u00b7 \ud83d\udce6 1 \u00b7 \ud83d\udccb 160 - 42% open \u00b7 \u23f1\ufe0f 03.09.2024):      <pre><code>git clone https://github.com/libAtoms/workflow\n</code></pre> Ultra-Fast Force Fields (UF3) (\ud83e\udd4815 \u00b7  \u2b50 59) - UF3: a python library for generating ultra-fast interatomic potentials. <code>Apache-2</code>  - [GitHub](https://github.com/uf3/uf3) (\ud83d\udc68\u200d\ud83d\udcbb 10 \u00b7 \ud83d\udd00 20 \u00b7 \ud83d\udce6 1 \u00b7 \ud83d\udccb 50 - 38% open \u00b7 \u23f1\ufe0f 06.09.2024):      <pre><code>git clone https://github.com/uf3/uf3\n</code></pre> - [PyPi](https://pypi.org/project/uf3) (\ud83d\udce5 45 / month \u00b7 \u23f1\ufe0f 27.10.2023):     <pre><code>pip install uf3\n</code></pre> PyXtalFF (\ud83e\udd4814 \u00b7  \u2b50 85 \u00b7 \ud83d\udca4) - Machine Learning Interatomic Potential Predictions. <code>MIT</code>  - [GitHub](https://github.com/MaterSim/PyXtal_FF) (\ud83d\udc68\u200d\ud83d\udcbb 9 \u00b7 \ud83d\udd00 23 \u00b7 \ud83d\udccb 63 - 19% open \u00b7 \u23f1\ufe0f 07.01.2024):      <pre><code>git clone https://github.com/MaterSim/PyXtal_FF\n</code></pre> - [PyPi](https://pypi.org/project/pyxtal_ff) (\ud83d\udce5 130 / month \u00b7 \u23f1\ufe0f 21.12.2022):     <pre><code>pip install pyxtal_ff\n</code></pre> So3krates (MLFF) (\ud83e\udd4814 \u00b7  \u2b50 76) - Build neural networks for machine learning force fields with JAX. <code>MIT</code>  - [GitHub](https://github.com/thorben-frank/mlff) (\ud83d\udc68\u200d\ud83d\udcbb 4 \u00b7 \ud83d\udd00 15 \u00b7 \ud83d\udccb 9 - 33% open \u00b7 \u23f1\ufe0f 23.08.2024):      <pre><code>git clone https://github.com/thorben-frank/mlff\n</code></pre> KLIFF (\ud83e\udd4814 \u00b7  \u2b50 34) - KIM-based Learning-Integrated Fitting Framework for interatomic potentials. <code>LGPL-2.1</code> <code>probabilistic</code> <code>workflows</code>  - [GitHub](https://github.com/openkim/kliff) (\ud83d\udc68\u200d\ud83d\udcbb 9 \u00b7 \ud83d\udd00 20 \u00b7 \ud83d\udce6 3 \u00b7 \ud83d\udccb 41 - 53% open \u00b7 \u23f1\ufe0f 06.07.2024):      <pre><code>git clone https://github.com/openkim/kliff\n</code></pre> - [PyPi](https://pypi.org/project/kliff) (\ud83d\udce5 280 / month \u00b7 \u23f1\ufe0f 17.12.2023):     <pre><code>pip install kliff\n</code></pre> - [Conda](https://anaconda.org/conda-forge/kliff) (\ud83d\udce5 100K \u00b7 \u23f1\ufe0f 10.09.2024):     <pre><code>conda install -c conda-forge kliff\n</code></pre> DMFF (\ud83e\udd4813 \u00b7  \u2b50 150 \u00b7 \ud83d\udca4) - DMFF (Differentiable Molecular Force Field) is a Jax-based python package that provides a full differentiable.. <code>LGPL-3.0</code>  - [GitHub](https://github.com/deepmodeling/DMFF) (\ud83d\udc68\u200d\ud83d\udcbb 14 \u00b7 \ud83d\udd00 41 \u00b7 \ud83d\udccb 26 - 38% open \u00b7 \u23f1\ufe0f 12.01.2024):      <pre><code>git clone https://github.com/deepmodeling/DMFF\n</code></pre> NNPOps (\ud83e\udd4813 \u00b7  \u2b50 81) - High-performance operations for neural network potentials. <code>MIT</code> <code>MD</code> <code>C++</code>  - [GitHub](https://github.com/openmm/NNPOps) (\ud83d\udc68\u200d\ud83d\udcbb 9 \u00b7 \ud83d\udd00 17 \u00b7 \ud83d\udccb 55 - 38% open \u00b7 \u23f1\ufe0f 10.07.2024):      <pre><code>git clone https://github.com/openmm/NNPOps\n</code></pre> - [Conda](https://anaconda.org/conda-forge/nnpops) (\ud83d\udce5 230K \u00b7 \u23f1\ufe0f 11.09.2024):     <pre><code>conda install -c conda-forge nnpops\n</code></pre> ANI-1 (\ud83e\udd4812 \u00b7  \u2b50 220) - ANI-1 neural net potential with python interface (ASE). <code>MIT</code>  - [GitHub](https://github.com/isayev/ASE_ANI) (\ud83d\udc68\u200d\ud83d\udcbb 6 \u00b7 \ud83d\udd00 55 \u00b7 \ud83d\udccb 37 - 43% open \u00b7 \u23f1\ufe0f 11.03.2024):      <pre><code>git clone https://github.com/isayev/ASE_ANI\n</code></pre> PiNN (\ud83e\udd4812 \u00b7  \u2b50 100) - A Python library for building atomic neural networks. <code>BSD-3</code>  - [GitHub](https://github.com/Teoroo-CMC/PiNN) (\ud83d\udc68\u200d\ud83d\udcbb 5 \u00b7 \ud83d\udd00 32 \u00b7 \ud83d\udccb 6 - 16% open \u00b7 \u23f1\ufe0f 27.06.2024):      <pre><code>git clone https://github.com/Teoroo-CMC/PiNN\n</code></pre> - [Docker Hub](https://hub.docker.com/r/teoroo/pinn) (\ud83d\udce5 240 \u00b7 \u23f1\ufe0f 27.06.2024):     <pre><code>docker pull teoroo/pinn\n</code></pre> Pacemaker (\ud83e\udd4812 \u00b7  \u2b50 69) - Python package for fitting atomic cluster expansion (ACE) potentials. <code>Custom</code>  - [GitHub](https://github.com/ICAMS/python-ace) (\ud83d\udc68\u200d\ud83d\udcbb 6 \u00b7 \ud83d\udd00 16 \u00b7 \ud83d\udccb 53 - 30% open \u00b7 \u23f1\ufe0f 06.09.2024):      <pre><code>git clone https://github.com/ICAMS/python-ace\n</code></pre> - [PyPi](https://pypi.org/project/python-ace) (\ud83d\udce5 14 / month \u00b7 \u23f1\ufe0f 24.10.2022):     <pre><code>pip install python-ace\n</code></pre> ACEfit (\ud83e\udd4812 \u00b7  \u2b50 7) -  <code>MIT</code> <code>Julia</code>  - [GitHub](https://github.com/ACEsuit/ACEfit.jl) (\ud83d\udc68\u200d\ud83d\udcbb 8 \u00b7 \ud83d\udd00 6 \u00b7 \ud83d\udccb 57 - 38% open \u00b7 \u23f1\ufe0f 14.09.2024):      <pre><code>git clone https://github.com/ACEsuit/ACEfit.jl\n</code></pre> tinker-hp (\ud83e\udd4811 \u00b7  \u2b50 80) - Tinker-HP: High-Performance Massively Parallel Evolution of Tinker on CPUs &amp; GPUs. <code>Custom</code>  - [GitHub](https://github.com/TinkerTools/tinker-hp) (\ud83d\udc68\u200d\ud83d\udcbb 12 \u00b7 \ud83d\udd00 22 \u00b7 \ud83d\udccb 20 - 15% open \u00b7 \u23f1\ufe0f 11.09.2024):      <pre><code>git clone https://github.com/TinkerTools/tinker-hp\n</code></pre> calorine (\ud83e\udd4811 \u00b7  \u2b50 12) - A Python package for constructing and sampling neuroevolution potential models. https://doi.org/10.21105/joss.06264. <code>Custom</code>  - [PyPi](https://pypi.org/project/calorine) (\ud83d\udce5 1.6K / month \u00b7 \ud83d\udce6 2 \u00b7 \u23f1\ufe0f 26.07.2024):     <pre><code>pip install calorine\n</code></pre> - [GitLab](https://gitlab.com/materials-modeling/calorine) (\ud83d\udd00 4 \u00b7 \ud83d\udccb 86 - 10% open \u00b7 \u23f1\ufe0f 26.07.2024):      <pre><code>git clone https://gitlab.com/materials-modeling/calorine\n</code></pre> CCS_fit (\ud83e\udd4811 \u00b7  \u2b50 8 \u00b7 \ud83d\udca4) - Curvature Constrained Splines. <code>GPL-3.0</code>  - [GitHub](https://github.com/Teoroo-CMC/CCS) (\ud83d\udc68\u200d\ud83d\udcbb 8 \u00b7 \ud83d\udd00 11 \u00b7 \ud83d\udce5 640 \u00b7 \ud83d\udccb 14 - 57% open \u00b7 \u23f1\ufe0f 16.02.2024):      <pre><code>git clone https://github.com/Teoroo-CMC/CCS\n</code></pre> - [PyPi](https://pypi.org/project/ccs_fit) (\ud83d\udce5 1K / month \u00b7 \u23f1\ufe0f 16.02.2024):     <pre><code>pip install ccs_fit\n</code></pre> DimeNet (\ud83e\udd499 \u00b7  \u2b50 290 \u00b7 \ud83d\udca4) - DimeNet and DimeNet++ models, as proposed in Directional Message Passing for Molecular Graphs (ICLR 2020) and Fast and.. <code>Custom</code>  - [GitHub](https://github.com/gasteigerjo/dimenet) (\ud83d\udc68\u200d\ud83d\udcbb 2 \u00b7 \ud83d\udd00 60 \u00b7 \ud83d\udce6 1 \u00b7 \ud83d\udccb 31 - 3% open \u00b7 \u23f1\ufe0f 03.10.2023):      <pre><code>git clone https://github.com/gasteigerjo/dimenet\n</code></pre> ACE.jl (\ud83e\udd499 \u00b7  \u2b50 65) - Parameterisation of Equivariant Properties of Particle Systems. <code>Custom</code> <code>Julia</code>  - [GitHub](https://github.com/ACEsuit/ACE.jl) (\ud83d\udc68\u200d\ud83d\udcbb 12 \u00b7 \ud83d\udd00 15 \u00b7 \ud83d\udccb 82 - 29% open \u00b7 \u23f1\ufe0f 31.08.2024):      <pre><code>git clone https://github.com/ACEsuit/ACE.jl\n</code></pre> GAP (\ud83e\udd499 \u00b7  \u2b50 40) - Gaussian Approximation Potential (GAP). <code>Custom</code>  - [GitHub](https://github.com/libAtoms/GAP) (\ud83d\udc68\u200d\ud83d\udcbb 13 \u00b7 \ud83d\udd00 20 \u00b7 \u23f1\ufe0f 17.08.2024):      <pre><code>git clone https://github.com/libAtoms/GAP\n</code></pre> ACE1.jl (\ud83e\udd499 \u00b7  \u2b50 20) - Atomic Cluster Expansion for Modelling Invariant Atomic Properties. <code>Custom</code> <code>Julia</code>  - [GitHub](https://github.com/ACEsuit/ACE1.jl) (\ud83d\udc68\u200d\ud83d\udcbb 9 \u00b7 \ud83d\udd00 7 \u00b7 \ud83d\udccb 46 - 47% open \u00b7 \u23f1\ufe0f 11.09.2024):      <pre><code>git clone https://github.com/ACEsuit/ACE1.jl\n</code></pre> Point Edge Transformer (PET) (\ud83e\udd499 \u00b7  \u2b50 18) - Point Edge Transformer. <code>MIT</code> <code>rep-learn</code> <code>transformer</code>  - [GitHub](https://github.com/spozdn/pet) (\ud83d\udc68\u200d\ud83d\udcbb 7 \u00b7 \ud83d\udd00 5 \u00b7 \u23f1\ufe0f 02.07.2024):      <pre><code>git clone https://github.com/spozdn/pet\n</code></pre> MACE-Jax (\ud83e\udd498 \u00b7  \u2b50 59 \u00b7 \ud83d\udca4) - Equivariant machine learning interatomic potentials in JAX. <code>MIT</code>  - [GitHub](https://github.com/ACEsuit/mace-jax) (\ud83d\udc68\u200d\ud83d\udcbb 2 \u00b7 \ud83d\udd00 5 \u00b7 \ud83d\udccb 7 - 42% open \u00b7 \u23f1\ufe0f 04.10.2023):      <pre><code>git clone https://github.com/ACEsuit/mace-jax\n</code></pre> SIMPLE-NN v2 (\ud83e\udd498 \u00b7  \u2b50 40 \u00b7 \ud83d\udca4) - SIMPLE-NN is an open package that constructs Behler-Parrinello-type neural-network interatomic potentials from ab.. <code>GPL-3.0</code>  - [GitHub](https://github.com/MDIL-SNU/SIMPLE-NN_v2) (\ud83d\udc68\u200d\ud83d\udcbb 13 \u00b7 \ud83d\udd00 17 \u00b7 \ud83d\udccb 13 - 30% open \u00b7 \u23f1\ufe0f 29.12.2023):      <pre><code>git clone https://github.com/MDIL-SNU/SIMPLE-NN_v2\n</code></pre> ALF (\ud83e\udd498 \u00b7  \u2b50 30) - A framework for performing active learning for training machine-learned interatomic potentials. <code>Custom</code> <code>active-learning</code>  - [GitHub](https://github.com/lanl/ALF) (\ud83d\udc68\u200d\ud83d\udcbb 5 \u00b7 \ud83d\udd00 12 \u00b7 \u23f1\ufe0f 08.08.2024):      <pre><code>git clone https://github.com/lanl/alf\n</code></pre> TurboGAP (\ud83e\udd498 \u00b7  \u2b50 16) - The TurboGAP code. <code>Custom</code> <code>Fortran</code>  - [GitHub](https://github.com/mcaroba/turbogap) (\ud83d\udc68\u200d\ud83d\udcbb 8 \u00b7 \ud83d\udd00 9 \u00b7 \ud83d\udccb 10 - 70% open \u00b7 \u23f1\ufe0f 11.09.2024):      <pre><code>git clone https://github.com/mcaroba/turbogap\n</code></pre> MLXDM (\ud83e\udd498 \u00b7  \u2b50 6) - A Neural Network Potential with Rigorous Treatment of Long-Range Dispersion https://doi.org/10.1039/D2DD00150K. <code>MIT</code> <code>long-range</code>  - [GitHub](https://github.com/RowleyGroup/MLXDM) (\ud83d\udc68\u200d\ud83d\udcbb 7 \u00b7 \ud83d\udd00 2 \u00b7 \u23f1\ufe0f 15.08.2024):      <pre><code>git clone https://github.com/RowleyGroup/MLXDM\n</code></pre> PyNEP (\ud83e\udd497 \u00b7  \u2b50 46) - A python interface of the machine learning potential NEP used in GPUMD. <code>MIT</code>  - [GitHub](https://github.com/bigd4/PyNEP) (\ud83d\udc68\u200d\ud83d\udcbb 7 \u00b7 \ud83d\udd00 16 \u00b7 \ud83d\udccb 11 - 36% open \u00b7 \u23f1\ufe0f 01.06.2024):      <pre><code>git clone https://github.com/bigd4/PyNEP\n</code></pre> TensorPotential (\ud83e\udd496 \u00b7  \u2b50 8) - Tensorpotential is a TensorFlow based tool for development, fitting ML interatomic potentials from electronic.. <code>Custom</code>  - [GitHub](https://github.com/ICAMS/TensorPotential) (\ud83d\udc68\u200d\ud83d\udcbb 4 \u00b7 \ud83d\udd00 4 \u00b7 \u23f1\ufe0f 12.09.2024):      <pre><code>git clone https://github.com/ICAMS/TensorPotential\n</code></pre> NequIP-JAX (\ud83e\udd495 \u00b7  \u2b50 17 \u00b7 \ud83d\udca4) - JAX implementation of the NequIP interatomic potential. <code>Unlicensed</code>  - [GitHub](https://github.com/mariogeiger/nequip-jax) (\ud83d\udc68\u200d\ud83d\udcbb 2 \u00b7 \ud83d\udd00 3 \u00b7 \u23f1\ufe0f 01.11.2023):      <pre><code>git clone https://github.com/mariogeiger/nequip-jax\n</code></pre> Allegro-JAX ( \u2b50 17) - JAX implementation of the Allegro interatomic potential. <code>Unlicensed</code>  - [GitHub](https://github.com/mariogeiger/allegro-jax) (\ud83d\udc68\u200d\ud83d\udcbb 2 \u00b7 \ud83d\udd00 2 \u00b7 \ud83d\udccb 2 - 50% open \u00b7 \u23f1\ufe0f 09.04.2024):      <pre><code>git clone https://github.com/mariogeiger/allegro-jax\n</code></pre> Show 32 hidden projects...  - MEGNet (\ud83e\udd4723 \u00b7  \u2b50 500 \u00b7 \ud83d\udc80) - Graph Networks as a Universal Machine Learning Framework for Molecules and Crystals. <code>BSD-3</code> <code>multifidelity</code> - sGDML (\ud83e\udd4816 \u00b7  \u2b50 140 \u00b7 \ud83d\udc80) - sGDML - Reference implementation of the Symmetric Gradient Domain Machine Learning model. <code>MIT</code> - n2p2 (\ud83e\udd4814 \u00b7  \u2b50 220 \u00b7 \ud83d\udc80) - n2p2 - A Neural Network Potential Package. <code>GPL-3.0</code> <code>C++</code> - TensorMol (\ud83e\udd4812 \u00b7  \u2b50 270 \u00b7 \ud83d\udc80) - Tensorflow + Molecules = TensorMol. <code>GPL-3.0</code> <code>single-paper</code> - SIMPLE-NN (\ud83e\udd4811 \u00b7  \u2b50 47 \u00b7 \ud83d\udc80) - SIMPLE-NN(SNU Interatomic Machine-learning PotentiaL packagE version Neural Network). <code>GPL-3.0</code> - Allegro (\ud83e\udd4910 \u00b7  \u2b50 330 \u00b7 \ud83d\udc80) - Allegro is an open-source code for building highly scalable and accurate equivariant deep learning interatomic.. <code>MIT</code> - NNsforMD (\ud83e\udd4910 \u00b7  \u2b50 10 \u00b7 \ud83d\udc80) - Neural network class for molecular dynamics to predict potential energy, forces and non-adiabatic couplings. <code>MIT</code> - SchNet (\ud83e\udd499 \u00b7  \u2b50 220 \u00b7 \ud83d\udc80) - SchNet - a deep learning architecture for quantum chemistry. <code>MIT</code> - GemNet (\ud83e\udd499 \u00b7  \u2b50 180 \u00b7 \ud83d\udc80) - GemNet model in PyTorch, as proposed in GemNet: Universal Directional Graph Neural Networks for Molecules (NeurIPS.. <code>Custom</code> - AIMNet (\ud83e\udd498 \u00b7  \u2b50 95 \u00b7 \ud83d\udc80) - Atoms In Molecules Neural Network Potential. <code>MIT</code> <code>single-paper</code> - SNAP (\ud83e\udd498 \u00b7  \u2b50 36 \u00b7 \ud83d\udc80) - Repository for spectral neighbor analysis potential (SNAP) model development. <code>BSD-3</code> - Atomistic Adversarial Attacks (\ud83e\udd498 \u00b7  \u2b50 31 \u00b7 \ud83d\udc80) - Code for performing adversarial attacks on atomistic systems using NN potentials. <code>MIT</code> <code>probabilistic</code> - MEGNetSparse (\ud83e\udd498 \u00b7  \u2b50 1 \u00b7 \ud83d\udc80) - A library imlementing a graph neural network with sparse representation from Code for Kazeev, N., Al-Maeeni, A.R.,.. <code>MIT</code> <code>material-defect</code> - PhysNet (\ud83e\udd497 \u00b7  \u2b50 88 \u00b7 \ud83d\udc80) - Code for training PhysNet models. <code>MIT</code> <code>electrostatics</code> - MLIP-3 (\ud83e\udd496 \u00b7  \u2b50 26 \u00b7 \ud83d\udc80) - MLIP-3: Active learning on atomic environments with Moment Tensor Potentials (MTP). <code>BSD-2</code> <code>C++</code> - testing-framework (\ud83e\udd496 \u00b7  \u2b50 11 \u00b7 \ud83d\udc80) - The purpose of this repository is to aid the testing of a large number of interatomic potentials for a variety of.. <code>Unlicensed</code> <code>benchmarking</code> - PANNA (\ud83e\udd496 \u00b7  \u2b50 9 \u00b7 \ud83d\udc80) - A package to train and validate all-to-all connected network models for BP[1] and modified-BP[2] type local atomic.. <code>MIT</code> <code>benchmarking</code> - Asparagus (\ud83e\udd496 \u00b7  \u2b50 4 \u00b7 \ud83d\udc23) - Program Package for Sampling, Training and Applying ML-based Potential models https://doi.org/10.48550/arXiv.2407.15175. <code>MIT</code> <code>workflows</code> <code>sampling</code> <code>MD</code> - GN-MM (\ud83e\udd495 \u00b7  \u2b50 10 \u00b7 \ud83d\udc80) - The Gaussian Moment Neural Network (GM-NN) package developed for large-scale atomistic simulations employing atomistic.. <code>MIT</code> <code>active-learning</code> <code>MD</code> <code>rep-eng</code> <code>magnetism</code> - Alchemical learning (\ud83e\udd495 \u00b7  \u2b50 2 \u00b7 \ud83d\udc80) - Code for the Modeling high-entropy transition metal alloys with alchemical compression article. <code>BSD-3</code> - ACE1Pack.jl (\ud83e\udd495 \u00b7  \u2b50 1 \u00b7 \ud83d\udc80) - Provides convenience functionality for the usage of ACE1.jl, ACEfit.jl, JuLIP.jl for fitting interatomic potentials.. <code>MIT</code> <code>Julia</code> - Allegro-Legato (\ud83e\udd494 \u00b7  \u2b50 19 \u00b7 \ud83d\udc80) - An extension of Allegro with enhanced robustness and time-to-failure. <code>MIT</code> <code>MD</code> - glp (\ud83e\udd494 \u00b7  \u2b50 17) - tools for graph-based machine-learning potentials in jax. <code>MIT</code> - ACE Workflows (\ud83e\udd494 \u00b7 \ud83d\udca4) - Workflow Examples for ACE Models. <code>Unlicensed</code> <code>Julia</code> <code>workflows</code> - PeriodicPotentials (\ud83e\udd494 \u00b7 \ud83d\udc80) - A Periodic table app that displays potentials based on the selected elements. <code>MIT</code> <code>community-resource</code> <code>viz</code> <code>JavaScript</code> - PyFLAME (\ud83e\udd493 \u00b7 \ud83d\udc80) - An automated approach for developing neural network interatomic potentials with FLAME.. <code>Unlicensed</code> <code>active-learning</code> <code>structure-prediction</code> <code>structure-optimization</code> <code>rep-eng</code> <code>Fortran</code> - SingleNN (\ud83e\udd492 \u00b7  \u2b50 8 \u00b7 \ud83d\udc80) - An efficient package for training and executing neural-network interatomic potentials. <code>Unlicensed</code> <code>C++</code> - AisNet (\ud83e\udd492 \u00b7  \u2b50 3 \u00b7 \ud83d\udc80) - A Universal Interatomic Potential Neural Network with Encoded Local Environment Features.. <code>MIT</code> - RuNNer (\ud83e\udd492) - The RuNNer Neural Network Energy Representation is a Fortran-based framework for the construction of Behler-.. <code>GPL-3.0</code> <code>Fortran</code> - nnp-pre-training (\ud83e\udd491 \u00b7  \u2b50 6 \u00b7 \ud83d\udca4) - Synthetic pre-training for neural-network interatomic potentials. <code>Unlicensed</code> <code>pretrained</code> <code>MD</code> - mag-ace (\ud83e\udd491 \u00b7  \u2b50 2 \u00b7 \ud83d\udca4) - Magnetic ACE potential. FORTRAN interface for LAMMPS SPIN package. <code>Unlicensed</code> <code>magnetism</code> <code>MD</code> <code>Fortran</code> - mlp (\ud83e\udd491 \u00b7  \u2b50 1 \u00b7 \ud83d\udc80) - Proper orthogonal descriptors for efficient and accurate interatomic potentials... <code>Unlicensed</code> <code>Julia</code> <p></p>"},{"location":"ref/raw_md/ml_in_comp_mat/#language-models","title":"Language Models","text":"<p>Projects that use (large) language models (LMs, LLMs) or natural language procesing (NLP) techniques for atomistic ML.</p> paper-qa (\ud83e\udd4729 \u00b7  \u2b50 5.9K) - High accuracy RAG for answering questions from scientific documents with citations. <code>Apache-2</code> <code>ai-agent</code>  - [GitHub](https://github.com/Future-House/paper-qa) (\ud83d\udc68\u200d\ud83d\udcbb 25 \u00b7 \ud83d\udd00 550 \u00b7 \ud83d\udce6 71 \u00b7 \ud83d\udccb 200 - 30% open \u00b7 \u23f1\ufe0f 26.09.2024):      <pre><code>git clone https://github.com/whitead/paper-qa\n</code></pre> - [PyPi](https://pypi.org/project/paper-qa) (\ud83d\udce5 15K / month \u00b7 \ud83d\udce6 8 \u00b7 \u23f1\ufe0f 24.09.2024):     <pre><code>pip install paper-qa\n</code></pre> OpenBioML ChemNLP (\ud83e\udd4717 \u00b7  \u2b50 150) - ChemNLP project. <code>MIT</code> <code>datasets</code>  - [GitHub](https://github.com/OpenBioML/chemnlp) (\ud83d\udc68\u200d\ud83d\udcbb 27 \u00b7 \ud83d\udd00 46 \u00b7 \ud83d\udccb 250 - 44% open \u00b7 \u23f1\ufe0f 19.08.2024):      <pre><code>git clone https://github.com/OpenBioML/chemnlp\n</code></pre> - [PyPi](https://pypi.org/project/chemnlp) (\ud83d\udce5 97 / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 07.08.2023):     <pre><code>pip install chemnlp\n</code></pre> ChemCrow (\ud83e\udd4815 \u00b7  \u2b50 590) - Open source package for the accurate solution of reasoning-intensive chemical tasks. <code>MIT</code> <code>ai-agent</code>  - [GitHub](https://github.com/ur-whitelab/chemcrow-public) (\ud83d\udc68\u200d\ud83d\udcbb 3 \u00b7 \ud83d\udd00 84 \u00b7 \ud83d\udce6 5 \u00b7 \ud83d\udccb 20 - 30% open \u00b7 \u23f1\ufe0f 27.03.2024):      <pre><code>git clone https://github.com/ur-whitelab/chemcrow-public\n</code></pre> - [PyPi](https://pypi.org/project/chemcrow) (\ud83d\udce5 530 / month \u00b7 \u23f1\ufe0f 27.03.2024):     <pre><code>pip install chemcrow\n</code></pre> AtomGPT (\ud83e\udd4813 \u00b7  \u2b50 22) - AtomGPT: Atomistic Generative Pretrained Transformer for Forward and Inverse Materials Design. <code>Custom</code> <code>generative</code> <code>pretrained</code> <code>transformer</code>  - [GitHub](https://github.com/usnistgov/atomgpt) (\ud83d\udc68\u200d\ud83d\udcbb 2 \u00b7 \ud83d\udd00 3 \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 22.09.2024):      <pre><code>git clone https://github.com/usnistgov/atomgpt\n</code></pre> - [PyPi](https://pypi.org/project/atomgpt) (\ud83d\udce5 230 / month \u00b7 \u23f1\ufe0f 22.09.2024):     <pre><code>pip install atomgpt\n</code></pre> gptchem (\ud83e\udd4812 \u00b7  \u2b50 220 \u00b7 \ud83d\udca4) - Use GPT-3 to solve chemistry problems. <code>MIT</code>  - [GitHub](https://github.com/kjappelbaum/gptchem) (\ud83d\udc68\u200d\ud83d\udcbb 4 \u00b7 \ud83d\udd00 41 \u00b7 \ud83d\udccb 21 - 90% open \u00b7 \u23f1\ufe0f 04.10.2023):      <pre><code>git clone https://github.com/kjappelbaum/gptchem\n</code></pre> - [PyPi](https://pypi.org/project/gptchem) (\ud83d\udce5 94 / month \u00b7 \u23f1\ufe0f 04.10.2023):     <pre><code>pip install gptchem\n</code></pre> NIST ChemNLP (\ud83e\udd4811 \u00b7  \u2b50 70) - ChemNLP: A Natural Language Processing based Library for Materials Chemistry Text Data. <code>MIT</code> <code>literature-data</code>  - [GitHub](https://github.com/usnistgov/chemnlp) (\ud83d\udc68\u200d\ud83d\udcbb 2 \u00b7 \ud83d\udd00 16 \u00b7 \ud83d\udce6 3 \u00b7 \u23f1\ufe0f 19.08.2024):      <pre><code>git clone https://github.com/usnistgov/chemnlp\n</code></pre> - [PyPi](https://pypi.org/project/chemnlp) (\ud83d\udce5 97 / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 07.08.2023):     <pre><code>pip install chemnlp\n</code></pre> ChatMOF (\ud83e\udd4811 \u00b7  \u2b50 57) - Predict and Inverse design for metal-organic framework with large-language models (llms). <code>MIT</code> <code>generative</code>  - [GitHub](https://github.com/Yeonghun1675/ChatMOF) (\ud83d\udc68\u200d\ud83d\udcbb 1 \u00b7 \ud83d\udd00 8 \u00b7 \ud83d\udce6 2 \u00b7 \u23f1\ufe0f 01.07.2024):      <pre><code>git clone https://github.com/Yeonghun1675/ChatMOF\n</code></pre> - [PyPi](https://pypi.org/project/chatmof) (\ud83d\udce5 340 / month \u00b7 \u23f1\ufe0f 01.07.2024):     <pre><code>pip install chatmof\n</code></pre> LLaMP (\ud83e\udd4910 \u00b7  \u2b50 59) - A web app and Python API for multi-modal RAG framework to ground LLMs on high-fidelity materials informatics. An.. <code>BSD-3</code> <code>materials-discovery</code> <code>cheminformatics</code> <code>generative</code> <code>MD</code> <code>multimodal</code> <code>language-models</code> <code>Python</code> <code>general-tool</code>  - [GitHub](https://github.com/chiang-yuan/llamp) (\ud83d\udc68\u200d\ud83d\udcbb 6 \u00b7 \ud83d\udd00 7 \u00b7 \ud83d\udccb 25 - 32% open \u00b7 \u23f1\ufe0f 10.09.2024):      <pre><code>git clone https://github.com/chiang-yuan/llamp\n</code></pre> MoLFormer (\ud83e\udd499 \u00b7  \u2b50 250 \u00b7 \ud83d\udca4) - Repository for MolFormer. <code>Apache-2</code> <code>transformer</code> <code>pretrained</code> <code>drug-discovery</code>  - [GitHub](https://github.com/IBM/molformer) (\ud83d\udc68\u200d\ud83d\udcbb 5 \u00b7 \ud83d\udd00 41 \u00b7 \ud83d\udccb 19 - 47% open \u00b7 \u23f1\ufe0f 16.10.2023):      <pre><code>git clone https://github.com/IBM/molformer\n</code></pre> MolSkill (\ud83e\udd499 \u00b7  \u2b50 100 \u00b7 \ud83d\udca4) - Extracting medicinal chemistry intuition via preference machine learning. <code>MIT</code> <code>drug-discovery</code> <code>recommender</code>  - [GitHub](https://github.com/microsoft/molskill) (\ud83d\udc68\u200d\ud83d\udcbb 4 \u00b7 \ud83d\udd00 9 \u00b7 \ud83d\udccb 6 - 33% open \u00b7 \u23f1\ufe0f 31.10.2023):      <pre><code>git clone https://github.com/microsoft/molskill\n</code></pre> - [Conda](https://anaconda.org/msr-ai4science/molskill) (\ud83d\udce5 300 \u00b7 \u23f1\ufe0f 18.06.2023):     <pre><code>conda install -c msr-ai4science molskill\n</code></pre> chemlift (\ud83e\udd497 \u00b7  \u2b50 31 \u00b7 \ud83d\udca4) - Language-interfaced fine-tuning for chemistry. <code>MIT</code>  - [GitHub](https://github.com/lamalab-org/chemlift) (\ud83d\udc68\u200d\ud83d\udcbb 2 \u00b7 \ud83d\udd00 3 \u00b7 \ud83d\udccb 18 - 61% open \u00b7 \u23f1\ufe0f 14.10.2023):      <pre><code>git clone https://github.com/lamalab-org/chemlift\n</code></pre> LLM-Prop (\ud83e\udd497 \u00b7  \u2b50 27) - A repository for the LLM-Prop implementation. <code>MIT</code>  - [GitHub](https://github.com/vertaix/LLM-Prop) (\ud83d\udc68\u200d\ud83d\udcbb 6 \u00b7 \ud83d\udd00 5 \u00b7 \ud83d\udccb 2 - 50% open \u00b7 \u23f1\ufe0f 26.04.2024):      <pre><code>git clone https://github.com/vertaix/LLM-Prop\n</code></pre> crystal-text-llm (\ud83e\udd495 \u00b7  \u2b50 67) - Large language models to generate stable crystals. <code>CC-BY-NC-4.0</code> <code>materials-discovery</code>  - [GitHub](https://github.com/facebookresearch/crystal-text-llm) (\ud83d\udc68\u200d\ud83d\udcbb 3 \u00b7 \ud83d\udd00 12 \u00b7 \ud83d\udccb 9 - 77% open \u00b7 \u23f1\ufe0f 18.06.2024):      <pre><code>git clone https://github.com/facebookresearch/crystal-text-llm\n</code></pre> SciBot (\ud83e\udd495 \u00b7  \u2b50 28) - SciBot is a simple demo of building a domain-specific chatbot for science. <code>Unlicensed</code> <code>ai-agent</code>  - [GitHub](https://github.com/CFN-softbio/SciBot) (\ud83d\udc68\u200d\ud83d\udcbb 1 \u00b7 \ud83d\udd00 8 \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 03.09.2024):      <pre><code>git clone https://github.com/CFN-softbio/SciBot\n</code></pre> MAPI_LLM (\ud83e\udd495 \u00b7  \u2b50 9) - A LLM application developed during the LLM March MADNESS Hackathon https://doi.org/10.1039/D3DD00113J. <code>MIT</code> <code>ai-agent</code> <code>dataset</code>  - [GitHub](https://github.com/maykcaldas/MAPI_LLM) (\ud83d\udc68\u200d\ud83d\udcbb 2 \u00b7 \ud83d\udd00 2 \u00b7 \u23f1\ufe0f 11.04.2024):      <pre><code>git clone https://github.com/maykcaldas/MAPI_LLM\n</code></pre> Cephalo (\ud83e\udd495 \u00b7  \u2b50 6 \u00b7 \ud83d\udc23) - Multimodal Vision-Language Models for Bio-Inspired Materials Analysis and Design. <code>Apache-2</code> <code>generative</code> <code>multimodal</code> <code>pretrained</code>  - [GitHub](https://github.com/lamm-mit/Cephalo) (\ud83d\udd00 1 \u00b7 \u23f1\ufe0f 23.07.2024):      <pre><code>git clone https://github.com/lamm-mit/Cephalo\n</code></pre> Show 6 hidden projects...  - ChemDataExtractor (\ud83e\udd4716 \u00b7  \u2b50 300 \u00b7 \ud83d\udc80) - Automatically extract chemical information from scientific documents. <code>MIT</code> <code>literature-data</code> - mat2vec (\ud83e\udd4812 \u00b7  \u2b50 620 \u00b7 \ud83d\udc80) - Supplementary Materials for Tshitoyan et al. Unsupervised word embeddings capture latent knowledge from materials.. <code>MIT</code> <code>rep-learn</code> - nlcc (\ud83e\udd4812 \u00b7  \u2b50 44 \u00b7 \ud83d\udc80) - Natural language computational chemistry command line interface. <code>MIT</code> <code>single-paper</code> - BERT-PSIE-TC (\ud83e\udd495 \u00b7  \u2b50 12 \u00b7 \ud83d\udc80) - A dataset of Curie temperatures automatically extracted from scientific literature with the use of the BERT-PSIE.. <code>MIT</code> <code>magnetism</code> - ChemDataWriter (\ud83e\udd494 \u00b7  \u2b50 14 \u00b7 \ud83d\udca4) - ChemDataWriter is a transformer-based library for automatically generating research books in the chemistry area. <code>MIT</code> <code>literature-data</code> - CatBERTa (\ud83e\udd493 \u00b7  \u2b50 19) - Large Language Model for Catalyst Property Prediction. <code>Unlicensed</code> <code>transformer</code> <code>catalysis</code> <p></p>"},{"location":"ref/raw_md/ml_in_comp_mat/#materials-discovery","title":"Materials Discovery","text":"<p>Projects that implement materials discovery methods using atomistic ML.</p> <p>\ud83d\udd17\u00a0MatterGen  - A generative model for inorganic materials design https://doi.org/10.48550/arXiv.2312.03687. <code>generative</code> <code>proprietary</code></p> aviary (\ud83e\udd4715 \u00b7  \u2b50 47) - The Wren sits on its Roost in the Aviary. <code>MIT</code>  - [GitHub](https://github.com/CompRhys/aviary) (\ud83d\udc68\u200d\ud83d\udcbb 4 \u00b7 \ud83d\udd00 11 \u00b7 \ud83d\udccb 29 - 13% open \u00b7 \u23f1\ufe0f 10.09.2024):      <pre><code>git clone https://github.com/CompRhys/aviary\n</code></pre> BOSS (\ud83e\udd4713 \u00b7  \u2b50 20) - Bayesian Optimization Structure Search (BOSS). <code>Apache-2</code> <code>probabilistic</code>  - [PyPi](https://pypi.org/project/aalto-boss) (\ud83d\udce5 4K / month \u00b7 \u23f1\ufe0f 20.07.2024):     <pre><code>pip install aalto-boss\n</code></pre> - [GitLab](https://gitlab.com/cest-group/boss) (\ud83d\udd00 11 \u00b7 \ud83d\udccb 30 - 3% open \u00b7 \u23f1\ufe0f 20.07.2024):      <pre><code>git clone https://gitlab.com/cest-group/boss\n</code></pre> AGOX (\ud83e\udd4810 \u00b7  \u2b50 13) - AGOX is a package for global optimization of atomic system using e.g. the energy calculated from density functional.. <code>GPL-3.0</code> <code>structure-optimization</code>  - [PyPi](https://pypi.org/project/agox) (\ud83d\udce5 230 / month \u00b7 \u23f1\ufe0f 26.08.2024):     <pre><code>pip install agox\n</code></pre> - [GitLab](https://gitlab.com/agox/agox) (\ud83d\udd00 5 \u00b7 \ud83d\udccb 24 - 54% open \u00b7 \u23f1\ufe0f 26.08.2024):      <pre><code>git clone https://gitlab.com/agox/agox\n</code></pre> Materials Discovery: GNoME (\ud83e\udd489 \u00b7  \u2b50 870) - Graph Networks for Materials Science (GNoME) and dataset of 381,000 novel stable materials. <code>Apache-2</code> <code>UIP</code> <code>datasets</code> <code>rep-learn</code> <code>proprietary</code>  - [GitHub](https://github.com/google-deepmind/materials_discovery) (\ud83d\udc68\u200d\ud83d\udcbb 2 \u00b7 \ud83d\udd00 140 \u00b7 \ud83d\udccb 22 - 81% open \u00b7 \u23f1\ufe0f 04.09.2024):      <pre><code>git clone https://github.com/google-deepmind/materials_discovery\n</code></pre> CSPML (crystal structure prediction with machine learning-based element substitution) (\ud83e\udd487 \u00b7  \u2b50 20) - Original implementation of CSPML. <code>MIT</code> <code>structure-prediction</code>  - [GitHub](https://github.com/Minoru938/CSPML) (\ud83d\udd00 9 \u00b7 \ud83d\udccb 3 - 66% open \u00b7 \u23f1\ufe0f 25.09.2024):      <pre><code>git clone https://github.com/minoru938/cspml\n</code></pre> Show 6 hidden projects...  - Computational Autonomy for Materials Discovery (CAMD) (\ud83e\udd496 \u00b7  \u2b50 1 \u00b7 \ud83d\udc80) - Agent-based sequential learning software for materials discovery. <code>Apache-2</code> - MAGUS (\ud83e\udd494 \u00b7  \u2b50 60 \u00b7 \ud83d\udc80) - Machine learning And Graph theory assisted Universal structure Searcher. <code>Unlicensed</code> <code>structure-prediction</code> <code>active-learning</code> - SPINNER (\ud83e\udd494 \u00b7  \u2b50 12 \u00b7 \ud83d\udc80) - SPINNER (Structure Prediction of Inorganic crystals using Neural Network potentials with Evolutionary and Random.. <code>GPL-3.0</code> <code>C++</code> <code>structure-prediction</code> - ML-atomate (\ud83e\udd494 \u00b7  \u2b50 4 \u00b7 \ud83d\udca4) - Machine learning-assisted Atomate code for autonomous computational materials screening. <code>GPL-3.0</code> <code>active-learning</code> <code>workflows</code> - closed-loop-acceleration-benchmarks (\ud83e\udd494 \u00b7 \ud83d\udc80) - Data and scripts in support of the publication By how much can closed-loop frameworks accelerate computational.. <code>MIT</code> <code>materials-discovery</code> <code>active-learning</code> <code>single-paper</code> - sl_discovery (\ud83e\udd493 \u00b7  \u2b50 5 \u00b7 \ud83d\udc80) - Data processing and models related to Quantifying the performance of machine learning models in materials discovery. <code>Apache-2</code> <code>materials-discovery</code> <code>single-paper</code> <p></p>"},{"location":"ref/raw_md/ml_in_comp_mat/#mathematical-tools","title":"Mathematical tools","text":"<p>Projects that implement mathematical objects used in atomistic machine learning.</p> KFAC-JAX (\ud83e\udd4719 \u00b7  \u2b50 230) - Second Order Optimization and Curvature Estimation with K-FAC in JAX. <code>Apache-2</code>  - [GitHub](https://github.com/google-deepmind/kfac-jax) (\ud83d\udc68\u200d\ud83d\udcbb 15 \u00b7 \ud83d\udd00 18 \u00b7 \ud83d\udce6 10 \u00b7 \ud83d\udccb 19 - 47% open \u00b7 \u23f1\ufe0f 25.09.2024):      <pre><code>git clone https://github.com/google-deepmind/kfac-jax\n</code></pre> - [PyPi](https://pypi.org/project/kfac-jax) (\ud83d\udce5 1K / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 04.04.2024):     <pre><code>pip install kfac-jax\n</code></pre> gpax (\ud83e\udd4717 \u00b7  \u2b50 200) - Gaussian Processes for Experimental Sciences. <code>MIT</code> <code>probabilistic</code> <code>active-learning</code>  - [GitHub](https://github.com/ziatdinovmax/gpax) (\ud83d\udc68\u200d\ud83d\udcbb 6 \u00b7 \ud83d\udd00 24 \u00b7 \ud83d\udce6 2 \u00b7 \ud83d\udccb 40 - 20% open \u00b7 \u23f1\ufe0f 21.05.2024):      <pre><code>git clone https://github.com/ziatdinovmax/gpax\n</code></pre> - [PyPi](https://pypi.org/project/gpax) (\ud83d\udce5 320 / month \u00b7 \u23f1\ufe0f 20.03.2024):     <pre><code>pip install gpax\n</code></pre> SpheriCart (\ud83e\udd4717 \u00b7  \u2b50 69) - Multi-language library for the calculation of spherical harmonics in Cartesian coordinates. <code>MIT</code>  - [GitHub](https://github.com/lab-cosmo/sphericart) (\ud83d\udc68\u200d\ud83d\udcbb 10 \u00b7 \ud83d\udd00 11 \u00b7 \ud83d\udce5 85 \u00b7 \ud83d\udce6 3 \u00b7 \ud83d\udccb 41 - 56% open \u00b7 \u23f1\ufe0f 07.09.2024):      <pre><code>git clone https://github.com/lab-cosmo/sphericart\n</code></pre> - [PyPi](https://pypi.org/project/sphericart) (\ud83d\udce5 1K / month \u00b7 \u23f1\ufe0f 04.09.2024):     <pre><code>pip install sphericart\n</code></pre> Polynomials4ML.jl (\ud83e\udd4813 \u00b7  \u2b50 12) - Polynomials for ML: fast evaluation, batching, differentiation. <code>MIT</code> <code>Julia</code>  - [GitHub](https://github.com/ACEsuit/Polynomials4ML.jl) (\ud83d\udc68\u200d\ud83d\udcbb 10 \u00b7 \ud83d\udd00 5 \u00b7 \ud83d\udccb 51 - 33% open \u00b7 \u23f1\ufe0f 22.06.2024):      <pre><code>git clone https://github.com/ACEsuit/Polynomials4ML.jl\n</code></pre> GElib (\ud83e\udd498 \u00b7  \u2b50 19) - C++/CUDA library for SO(3) equivariant operations. <code>MPL-2.0</code> <code>C++</code>  - [GitHub](https://github.com/risi-kondor/GElib) (\ud83d\udc68\u200d\ud83d\udcbb 4 \u00b7 \ud83d\udd00 3 \u00b7 \ud83d\udccb 8 - 50% open \u00b7 \u23f1\ufe0f 27.07.2024):      <pre><code>git clone https://github.com/risi-kondor/GElib\n</code></pre> EquivariantOperators.jl (\ud83e\udd496 \u00b7  \u2b50 19 \u00b7 \ud83d\udca4) - This package is deprecated. Functionalities are migrating to Porcupine.jl. <code>MIT</code> <code>Julia</code>  - [GitHub](https://github.com/aced-differentiate/EquivariantOperators.jl) (\u23f1\ufe0f 27.09.2023):      <pre><code>git clone https://github.com/aced-differentiate/EquivariantOperators.jl\n</code></pre> COSMO Toolbox (\ud83e\udd496 \u00b7  \u2b50 7) - Assorted libraries and utilities for atomistic simulation analysis. <code>Unlicensed</code> <code>C++</code>  - [GitHub](https://github.com/lab-cosmo/toolbox) (\ud83d\udc68\u200d\ud83d\udcbb 9 \u00b7 \ud83d\udd00 6 \u00b7 \u23f1\ufe0f 19.03.2024):      <pre><code>git clone https://github.com/lab-cosmo/toolbox\n</code></pre> Show 4 hidden projects...  - lie-nn (\ud83e\udd489 \u00b7  \u2b50 26 \u00b7 \ud83d\udc80) - Tools for building equivariant polynomials on reductive Lie groups. <code>MIT</code> <code>rep-learn</code> - cnine (\ud83e\udd496 \u00b7  \u2b50 4) - Cnine tensor library. <code>Unlicensed</code> <code>C++</code> - torch_spex (\ud83e\udd493 \u00b7  \u2b50 3) - Spherical expansions in PyTorch. <code>Unlicensed</code> - Wigner Kernels (\ud83e\udd491 \u00b7  \u2b50 2 \u00b7 \ud83d\udc80) - Collection of programs to benchmark Wigner kernels. <code>Unlicensed</code> <code>benchmarking</code> <p></p>"},{"location":"ref/raw_md/ml_in_comp_mat/#molecular-dynamics","title":"Molecular Dynamics","text":"<p>Projects that simplify the integration of molecular dynamics and atomistic machine learning.</p> JAX-MD (\ud83e\udd4726 \u00b7  \u2b50 1.2K) - Differentiable, Hardware Accelerated, Molecular Dynamics. <code>Apache-2</code>  - [GitHub](https://github.com/jax-md/jax-md) (\ud83d\udc68\u200d\ud83d\udcbb 34 \u00b7 \ud83d\udd00 190 \u00b7 \ud83d\udce6 56 \u00b7 \ud83d\udccb 150 - 46% open \u00b7 \u23f1\ufe0f 05.09.2024):      <pre><code>git clone https://github.com/jax-md/jax-md\n</code></pre> - [PyPi](https://pypi.org/project/jax-md) (\ud83d\udce5 3.3K / month \u00b7 \ud83d\udce6 3 \u00b7 \u23f1\ufe0f 09.08.2023):     <pre><code>pip install jax-md\n</code></pre> FitSNAP (\ud83e\udd4818 \u00b7  \u2b50 150) - Software for generating machine-learning interatomic potentials for LAMMPS. <code>GPL-2.0</code>  - [GitHub](https://github.com/FitSNAP/FitSNAP) (\ud83d\udc68\u200d\ud83d\udcbb 24 \u00b7 \ud83d\udd00 51 \u00b7 \ud83d\udce5 11 \u00b7 \ud83d\udce6 2 \u00b7 \ud83d\udccb 73 - 21% open \u00b7 \u23f1\ufe0f 19.09.2024):      <pre><code>git clone https://github.com/FitSNAP/FitSNAP\n</code></pre> - [Conda](https://anaconda.org/conda-forge/fitsnap3) (\ud83d\udce5 8.4K \u00b7 \u23f1\ufe0f 16.06.2023):     <pre><code>conda install -c conda-forge fitsnap3\n</code></pre> mlcolvar (\ud83e\udd4817 \u00b7  \u2b50 91) - A unified framework for machine learning collective variables for enhanced sampling simulations. <code>MIT</code> <code>sampling</code>  - [GitHub](https://github.com/luigibonati/mlcolvar) (\ud83d\udc68\u200d\ud83d\udcbb 8 \u00b7 \ud83d\udd00 24 \u00b7 \ud83d\udce6 2 \u00b7 \ud83d\udccb 72 - 19% open \u00b7 \u23f1\ufe0f 23.09.2024):      <pre><code>git clone https://github.com/luigibonati/mlcolvar\n</code></pre> - [PyPi](https://pypi.org/project/mlcolvar) (\ud83d\udce5 190 / month \u00b7 \u23f1\ufe0f 12.06.2024):     <pre><code>pip install mlcolvar\n</code></pre> openmm-torch (\ud83e\udd4816 \u00b7  \u2b50 180) - OpenMM plugin to define forces with neural networks. <code>Custom</code> <code>ML-IAP</code> <code>C++</code>  - [GitHub](https://github.com/openmm/openmm-torch) (\ud83d\udc68\u200d\ud83d\udcbb 8 \u00b7 \ud83d\udd00 23 \u00b7 \ud83d\udccb 92 - 28% open \u00b7 \u23f1\ufe0f 23.08.2024):      <pre><code>git clone https://github.com/openmm/openmm-torch\n</code></pre> - [Conda](https://anaconda.org/conda-forge/openmm-torch) (\ud83d\udce5 460K \u00b7 \u23f1\ufe0f 03.06.2024):     <pre><code>conda install -c conda-forge openmm-torch\n</code></pre> OpenMM-ML (\ud83e\udd4913 \u00b7  \u2b50 80) - High level API for using machine learning models in OpenMM simulations. <code>MIT</code> <code>ML-IAP</code>  - [GitHub](https://github.com/openmm/openmm-ml) (\ud83d\udc68\u200d\ud83d\udcbb 5 \u00b7 \ud83d\udd00 19 \u00b7 \ud83d\udccb 55 - 36% open \u00b7 \u23f1\ufe0f 06.08.2024):      <pre><code>git clone https://github.com/openmm/openmm-ml\n</code></pre> - [Conda](https://anaconda.org/conda-forge/openmm-ml) (\ud83d\udce5 5.2K \u00b7 \u23f1\ufe0f 07.06.2024):     <pre><code>conda install -c conda-forge openmm-ml\n</code></pre> pair_nequip (\ud83e\udd4910 \u00b7  \u2b50 41) - LAMMPS pair style for NequIP. <code>MIT</code> <code>ML-IAP</code> <code>rep-learn</code>  - [GitHub](https://github.com/mir-group/pair_nequip) (\ud83d\udc68\u200d\ud83d\udcbb 3 \u00b7 \ud83d\udd00 12 \u00b7 \ud83d\udccb 30 - 33% open \u00b7 \u23f1\ufe0f 05.06.2024):      <pre><code>git clone https://github.com/mir-group/pair_nequip\n</code></pre> PACE (\ud83e\udd4910 \u00b7  \u2b50 24 \u00b7 \ud83d\udca4) - The LAMMPS ML-IAP `pair_style pace`, aka Atomic Cluster Expansion (ACE), aka ML-PACE,.. <code>Custom</code>  - [GitHub](https://github.com/ICAMS/lammps-user-pace) (\ud83d\udc68\u200d\ud83d\udcbb 6 \u00b7 \ud83d\udd00 10 \u00b7 \ud83d\udccb 8 - 25% open \u00b7 \u23f1\ufe0f 27.11.2023):      <pre><code>git clone https://github.com/ICAMS/lammps-user-pace\n</code></pre> pair_allegro (\ud83e\udd498 \u00b7  \u2b50 34) - LAMMPS pair style for Allegro deep learning interatomic potentials with parallelization support. <code>MIT</code> <code>ML-IAP</code> <code>rep-learn</code>  - [GitHub](https://github.com/mir-group/pair_allegro) (\ud83d\udc68\u200d\ud83d\udcbb 2 \u00b7 \ud83d\udd00 8 \u00b7 \ud83d\udccb 30 - 40% open \u00b7 \u23f1\ufe0f 05.06.2024):      <pre><code>git clone https://github.com/mir-group/pair_allegro\n</code></pre> SOMD (\ud83e\udd495 \u00b7  \u2b50 12) - Molecular dynamics package designed for the SIESTA DFT code. <code>AGPL-3.0</code> <code>ML-IAP</code> <code>active-learning</code>  - [GitHub](https://github.com/initqp/somd) (\ud83d\udd00 2 \u00b7 \u23f1\ufe0f 17.08.2024):      <pre><code>git clone https://github.com/initqp/somd\n</code></pre> Show 1 hidden projects...  - interface-lammps-mlip-3 (\ud83e\udd493 \u00b7  \u2b50 5 \u00b7 \ud83d\udc80) - An interface between LAMMPS and MLIP (version 3). <code>GPL-2.0</code> <p></p>"},{"location":"ref/raw_md/ml_in_comp_mat/#reinforcement-learning","title":"Reinforcement Learning","text":"<p>Projects that focus on reinforcement learning for atomistic ML.</p> Show 2 hidden projects...  - ReLeaSE (\ud83e\udd4711 \u00b7  \u2b50 350 \u00b7 \ud83d\udc80) - Deep Reinforcement Learning for de-novo Drug Design. <code>MIT</code> <code>drug-discovery</code> - CatGym (\ud83e\udd496 \u00b7  \u2b50 11 \u00b7 \ud83d\udc80) - Surface segregation using Deep Reinforcement Learning. <code>GPL</code> <p></p>"},{"location":"ref/raw_md/ml_in_comp_mat/#representation-engineering","title":"Representation Engineering","text":"<p>Projects that offer implementations of representations aka descriptors, fingerprints of atomistic systems, and models built with them, aka feature engineering.</p> cdk (\ud83e\udd4726 \u00b7  \u2b50 490) - The Chemistry Development Kit. <code>LGPL-2.1</code> <code>cheminformatics</code> <code>Java</code>  - [GitHub](https://github.com/cdk/cdk) (\ud83d\udc68\u200d\ud83d\udcbb 160 \u00b7 \ud83d\udd00 160 \u00b7 \ud83d\udce5 22K \u00b7 \ud83d\udccb 290 - 10% open \u00b7 \u23f1\ufe0f 19.09.2024):      <pre><code>git clone https://github.com/cdk/cdk\n</code></pre> - [Maven](https://search.maven.org/artifact/org.openscience.cdk/cdk-bundle) (\ud83d\udce6 16 \u00b7 \u23f1\ufe0f 21.08.2023):     <pre><code>&lt;dependency&gt;\n    &lt;groupId&gt;org.openscience.cdk&lt;/groupId&gt;\n    &lt;artifactId&gt;cdk-bundle&lt;/artifactId&gt;\n    &lt;version&gt;[VERSION]&lt;/version&gt;\n&lt;/dependency&gt;\n</code></pre> DScribe (\ud83e\udd4725 \u00b7  \u2b50 400) - DScribe is a python package for creating machine learning descriptors for atomistic systems. <code>Apache-2</code>  - [GitHub](https://github.com/SINGROUP/dscribe) (\ud83d\udc68\u200d\ud83d\udcbb 18 \u00b7 \ud83d\udd00 87 \u00b7 \ud83d\udce6 200 \u00b7 \ud83d\udccb 100 - 11% open \u00b7 \u23f1\ufe0f 28.05.2024):      <pre><code>git clone https://github.com/SINGROUP/dscribe\n</code></pre> - [PyPi](https://pypi.org/project/dscribe) (\ud83d\udce5 22K / month \u00b7 \ud83d\udce6 35 \u00b7 \u23f1\ufe0f 28.05.2024):     <pre><code>pip install dscribe\n</code></pre> - [Conda](https://anaconda.org/conda-forge/dscribe) (\ud83d\udce5 140K \u00b7 \u23f1\ufe0f 28.05.2024):     <pre><code>conda install -c conda-forge dscribe\n</code></pre> MODNet (\ud83e\udd4716 \u00b7  \u2b50 77) - MODNet: a framework for machine learning materials properties. <code>MIT</code> <code>pretrained</code> <code>small-data</code> <code>transfer-learning</code>  - [GitHub](https://github.com/ppdebreuck/modnet) (\ud83d\udc68\u200d\ud83d\udcbb 10 \u00b7 \ud83d\udd00 32 \u00b7 \ud83d\udce6 9 \u00b7 \ud83d\udccb 53 - 49% open \u00b7 \u23f1\ufe0f 24.09.2024):      <pre><code>git clone https://github.com/ppdebreuck/modnet\n</code></pre> SISSO (\ud83e\udd4814 \u00b7  \u2b50 240) - A data-driven method combining symbolic regression and compressed sensing for accurate &amp; interpretable models. <code>Apache-2</code> <code>Fortran</code>  - [GitHub](https://github.com/rouyang2017/SISSO) (\ud83d\udc68\u200d\ud83d\udcbb 3 \u00b7 \ud83d\udd00 77 \u00b7 \ud83d\udccb 76 - 23% open \u00b7 \u23f1\ufe0f 20.09.2024):      <pre><code>git clone https://github.com/rouyang2017/SISSO\n</code></pre> GlassPy (\ud83e\udd4814 \u00b7  \u2b50 26 \u00b7 \ud83d\udca4) - Python module for scientists working with glass materials. <code>GPL-3.0</code>  - [GitHub](https://github.com/drcassar/glasspy) (\ud83d\udc68\u200d\ud83d\udcbb 1 \u00b7 \ud83d\udd00 7 \u00b7 \ud83d\udce6 6 \u00b7 \ud83d\udccb 13 - 53% open \u00b7 \u23f1\ufe0f 21.01.2024):      <pre><code>git clone https://github.com/drcassar/glasspy\n</code></pre> - [PyPi](https://pypi.org/project/glasspy) (\ud83d\udce5 760 / month \u00b7 \u23f1\ufe0f 05.09.2024):     <pre><code>pip install glasspy\n</code></pre> Librascal (\ud83e\udd4813 \u00b7  \u2b50 80 \u00b7 \ud83d\udca4) - A scalable and versatile library to generate representations for atomic-scale learning. <code>LGPL-2.1</code>  - [GitHub](https://github.com/lab-cosmo/librascal) (\ud83d\udc68\u200d\ud83d\udcbb 30 \u00b7 \ud83d\udd00 20 \u00b7 \ud83d\udccb 250 - 46% open \u00b7 \u23f1\ufe0f 30.11.2023):      <pre><code>git clone https://github.com/lab-cosmo/librascal\n</code></pre> Rascaline (\ud83e\udd4812 \u00b7  \u2b50 44) - Computing representations for atomistic machine learning. <code>BSD-3</code> <code>Rust</code> <code>C++</code>  - [GitHub](https://github.com/Luthaf/rascaline) (\ud83d\udc68\u200d\ud83d\udcbb 14 \u00b7 \ud83d\udd00 13 \u00b7 \ud83d\udccb 69 - 46% open \u00b7 \u23f1\ufe0f 26.09.2024):      <pre><code>git clone https://github.com/Luthaf/rascaline\n</code></pre> fplib (\ud83e\udd4910 \u00b7  \u2b50 7 \u00b7 \ud83d\udcc8) - libfp is a library for calculating crystalline fingerprints and measuring similarities of materials. <code>MIT</code> <code>C-lang</code> <code>single-paper</code>  - [GitHub](https://github.com/Rutgers-ZRG/libfp) (\ud83d\udd00 1 \u00b7 \u23f1\ufe0f 26.09.2024):      <pre><code>git clone https://github.com/zhuligs/fplib\n</code></pre> NICE (\ud83e\udd497 \u00b7  \u2b50 12) - NICE (N-body Iteratively Contracted Equivariants) is a set of tools designed for the calculation of invariant and.. <code>MIT</code>  - [GitHub](https://github.com/lab-cosmo/nice) (\ud83d\udc68\u200d\ud83d\udcbb 4 \u00b7 \ud83d\udd00 3 \u00b7 \ud83d\udccb 3 - 66% open \u00b7 \u23f1\ufe0f 15.04.2024):      <pre><code>git clone https://github.com/lab-cosmo/nice\n</code></pre> SA-GPR (\ud83e\udd496 \u00b7  \u2b50 19) - Public repository for symmetry-adapted Gaussian Process Regression (SA-GPR). <code>LGPL-3.0</code> <code>C-lang</code>  - [GitHub](https://github.com/dilkins/TENSOAP) (\ud83d\udc68\u200d\ud83d\udcbb 5 \u00b7 \ud83d\udd00 13 \u00b7 \ud83d\udccb 7 - 28% open \u00b7 \u23f1\ufe0f 23.07.2024):      <pre><code>git clone https://github.com/dilkins/TENSOAP\n</code></pre> milad (\ud83e\udd495 \u00b7  \u2b50 30) - Moment Invariants Local Atomic Descriptor. <code>GPL-3.0</code> <code>generative</code>  - [GitHub](https://github.com/muhrin/milad) (\ud83d\udc68\u200d\ud83d\udcbb 1 \u00b7 \ud83d\udd00 1 \u00b7 \ud83d\udce6 2 \u00b7 \u23f1\ufe0f 20.08.2024):      <pre><code>git clone https://github.com/muhrin/milad\n</code></pre> Show 14 hidden projects...  - CatLearn (\ud83e\udd4716 \u00b7  \u2b50 100 \u00b7 \ud83d\udc80) -  <code>GPL-3.0</code> <code>surface-science</code> - CBFV (\ud83e\udd4812 \u00b7  \u2b50 25 \u00b7 \ud83d\udc80) - Tool to quickly create a composition-based feature vector. <code>Unlicensed</code> - BenchML (\ud83e\udd4812 \u00b7  \u2b50 15 \u00b7 \ud83d\udc80) - ML benchmarking and pipeling framework. <code>Apache-2</code> <code>benchmarking</code> - cmlkit (\ud83e\udd4911 \u00b7  \u2b50 34 \u00b7 \ud83d\udc80) - tools for machine learning in condensed matter physics and quantum chemistry. <code>MIT</code> <code>benchmarking</code> - SkipAtom (\ud83e\udd499 \u00b7  \u2b50 24 \u00b7 \ud83d\udc80) - Distributed representations of atoms, inspired by the Skip-gram model. <code>MIT</code> - SOAPxx (\ud83e\udd496 \u00b7  \u2b50 7 \u00b7 \ud83d\udc80) - A SOAP implementation. <code>GPL-2.0</code> <code>C++</code> - soap_turbo (\ud83e\udd496 \u00b7  \u2b50 5 \u00b7 \ud83d\udc80) - soap_turbo comprises a series of libraries to be used in combination with QUIP/GAP and TurboGAP. <code>Custom</code> <code>Fortran</code> - pyLODE (\ud83e\udd496 \u00b7  \u2b50 3 \u00b7 \ud83d\udc80) - Pythonic implementation of LOng Distance Equivariants. <code>Apache-2</code> <code>electrostatics</code> - AMP (\ud83e\udd496 \u00b7 \ud83d\udc80) - Amp is an open-source package designed to easily bring machine-learning to atomistic calculations. <code>Unlicensed</code> - MXenes4HER (\ud83e\udd495 \u00b7  \u2b50 6 \u00b7 \ud83d\udc80) - Predicting hydrogen evolution (HER) activity over 4500 MXene materials https://doi.org/10.1039/D3TA00344B. <code>GPL-3.0</code> <code>materials-discovery</code> <code>catalysis</code> <code>scikit-learn</code> <code>single-paper</code> - SISSO++ (\ud83e\udd495 \u00b7  \u2b50 3 \u00b7 \ud83d\udc80) - C++ Implementation of SISSO with python bindings. <code>Apache-2</code> <code>C++</code> - automl-materials (\ud83e\udd494 \u00b7  \u2b50 5 \u00b7 \ud83d\udc80) - AutoML for Regression Tasks on Small Tabular Data in Materials Design. <code>MIT</code> <code>autoML</code> <code>benchmarking</code> <code>single-paper</code> - magnetism-prediction (\ud83e\udd494 \u00b7  \u2b50 1 \u00b7 \ud83d\udc80) - DFT-aided Machine Learning Search for Magnetism in Fe-based Bimetallic Chalcogenides. <code>Apache-2</code> <code>magnetism</code> <code>single-paper</code> - ML-for-CurieTemp-Predictions (\ud83e\udd493 \u00b7  \u2b50 1 \u00b7 \ud83d\udc80) - Machine Learning Predictions of High-Curie-Temperature Materials. <code>MIT</code> <code>single-paper</code> <code>magnetism</code> <p></p>"},{"location":"ref/raw_md/ml_in_comp_mat/#representation-learning","title":"Representation Learning","text":"<p>General models that learn a representations aka embeddings of atomistic systems, such as message-passing neural networks (MPNN).</p> Deep Graph Library (DGL) (\ud83e\udd4739 \u00b7  \u2b50 13K) - Python package built to ease deep learning on graph, on top of existing DL frameworks. <code>Apache-2</code>  - [GitHub](https://github.com/dmlc/dgl) (\ud83d\udc68\u200d\ud83d\udcbb 300 \u00b7 \ud83d\udd00 3K \u00b7 \ud83d\udce6 300 \u00b7 \ud83d\udccb 2.9K - 18% open \u00b7 \u23f1\ufe0f 25.09.2024):      <pre><code>git clone https://github.com/dmlc/dgl\n</code></pre> - [PyPi](https://pypi.org/project/dgl) (\ud83d\udce5 110K / month \u00b7 \ud83d\udce6 150 \u00b7 \u23f1\ufe0f 13.05.2024):     <pre><code>pip install dgl\n</code></pre> - [Conda](https://anaconda.org/dglteam/dgl) (\ud83d\udce5 370K \u00b7 \u23f1\ufe0f 03.09.2024):     <pre><code>conda install -c dglteam dgl\n</code></pre> PyG Models (\ud83e\udd4735 \u00b7  \u2b50 21K) - Representation learning models implemented in PyTorch Geometric. <code>MIT</code> <code>general-ml</code>  - [GitHub](https://github.com/pyg-team/pytorch_geometric) (\ud83d\udc68\u200d\ud83d\udcbb 520 \u00b7 \ud83d\udd00 3.6K \u00b7 \ud83d\udce6 6.5K \u00b7 \ud83d\udccb 3.7K - 27% open \u00b7 \u23f1\ufe0f 24.09.2024):      <pre><code>git clone https://github.com/pyg-team/pytorch_geometric\n</code></pre> e3nn (\ud83e\udd4728 \u00b7  \u2b50 950) - A modular framework for neural networks with Euclidean symmetry. <code>MIT</code>  - [GitHub](https://github.com/e3nn/e3nn) (\ud83d\udc68\u200d\ud83d\udcbb 31 \u00b7 \ud83d\udd00 140 \u00b7 \ud83d\udce6 300 \u00b7 \ud83d\udccb 160 - 14% open \u00b7 \u23f1\ufe0f 25.08.2024):      <pre><code>git clone https://github.com/e3nn/e3nn\n</code></pre> - [PyPi](https://pypi.org/project/e3nn) (\ud83d\udce5 94K / month \u00b7 \ud83d\udce6 4 \u00b7 \u23f1\ufe0f 13.04.2022):     <pre><code>pip install e3nn\n</code></pre> - [Conda](https://anaconda.org/conda-forge/e3nn) (\ud83d\udce5 22K \u00b7 \u23f1\ufe0f 18.06.2023):     <pre><code>conda install -c conda-forge e3nn\n</code></pre> SchNetPack (\ud83e\udd4728 \u00b7  \u2b50 770) - SchNetPack - Deep Neural Networks for Atomistic Systems. <code>MIT</code>  - [GitHub](https://github.com/atomistic-machine-learning/schnetpack) (\ud83d\udc68\u200d\ud83d\udcbb 36 \u00b7 \ud83d\udd00 210 \u00b7 \ud83d\udce6 90 \u00b7 \ud83d\udccb 250 - 2% open \u00b7 \u23f1\ufe0f 24.09.2024):      <pre><code>git clone https://github.com/atomistic-machine-learning/schnetpack\n</code></pre> - [PyPi](https://pypi.org/project/schnetpack) (\ud83d\udce5 1.4K / month \u00b7 \ud83d\udce6 4 \u00b7 \u23f1\ufe0f 05.09.2024):     <pre><code>pip install schnetpack\n</code></pre> MatGL (Materials Graph Library) (\ud83e\udd4724 \u00b7  \u2b50 250) - Graph deep learning library for materials. <code>BSD-3</code> <code>multifidelity</code>  - [GitHub](https://github.com/materialsvirtuallab/matgl) (\ud83d\udc68\u200d\ud83d\udcbb 17 \u00b7 \ud83d\udd00 59 \u00b7 \ud83d\udce6 46 \u00b7 \ud83d\udccb 97 - 7% open \u00b7 \u23f1\ufe0f 26.09.2024):      <pre><code>git clone https://github.com/materialsvirtuallab/matgl\n</code></pre> - [PyPi](https://pypi.org/project/m3gnet) (\ud83d\udce5 1.7K / month \u00b7 \ud83d\udce6 5 \u00b7 \u23f1\ufe0f 17.11.2022):     <pre><code>pip install m3gnet\n</code></pre> e3nn-jax (\ud83e\udd4822 \u00b7  \u2b50 180) - jax library for E3 Equivariant Neural Networks. <code>Apache-2</code>  - [GitHub](https://github.com/e3nn/e3nn-jax) (\ud83d\udc68\u200d\ud83d\udcbb 7 \u00b7 \ud83d\udd00 18 \u00b7 \ud83d\udce6 38 \u00b7 \ud83d\udccb 22 - 4% open \u00b7 \u23f1\ufe0f 14.08.2024):      <pre><code>git clone https://github.com/e3nn/e3nn-jax\n</code></pre> - [PyPi](https://pypi.org/project/e3nn-jax) (\ud83d\udce5 3.4K / month \u00b7 \ud83d\udce6 13 \u00b7 \u23f1\ufe0f 14.08.2024):     <pre><code>pip install e3nn-jax\n</code></pre> NVIDIA Deep Learning Examples for Tensor Cores (\ud83e\udd4821 \u00b7  \u2b50 13K) - State-of-the-Art Deep Learning scripts organized by models - easy to train and deploy with reproducible accuracy and.. <code>Custom</code> <code>educational</code> <code>drug-discovery</code>  - [GitHub](https://github.com/NVIDIA/DeepLearningExamples) (\ud83d\udc68\u200d\ud83d\udcbb 120 \u00b7 \ud83d\udd00 3.1K \u00b7 \ud83d\udccb 880 - 35% open \u00b7 \u23f1\ufe0f 04.04.2024):      <pre><code>git clone https://github.com/NVIDIA/DeepLearningExamples\n</code></pre> DIG: Dive into Graphs (\ud83e\udd4821 \u00b7  \u2b50 1.9K \u00b7 \ud83d\udca4) - A library for graph deep learning research. <code>GPL-3.0</code>  - [GitHub](https://github.com/divelab/DIG) (\ud83d\udc68\u200d\ud83d\udcbb 50 \u00b7 \ud83d\udd00 280 \u00b7 \ud83d\udccb 210 - 16% open \u00b7 \u23f1\ufe0f 04.02.2024):      <pre><code>git clone https://github.com/divelab/DIG\n</code></pre> - [PyPi](https://pypi.org/project/dive-into-graphs) (\ud83d\udce5 540 / month \u00b7 \u23f1\ufe0f 27.06.2022):     <pre><code>pip install dive-into-graphs\n</code></pre> ALIGNN (\ud83e\udd4821 \u00b7  \u2b50 220) - Atomistic Line Graph Neural Network https://scholar.google.com/citations?user=9Q-tNnwAAAAJ&amp;hl=en. <code>Custom</code>  - [GitHub](https://github.com/usnistgov/alignn) (\ud83d\udc68\u200d\ud83d\udcbb 7 \u00b7 \ud83d\udd00 79 \u00b7 \ud83d\udce6 14 \u00b7 \ud83d\udccb 64 - 62% open \u00b7 \u23f1\ufe0f 09.09.2024):      <pre><code>git clone https://github.com/usnistgov/alignn\n</code></pre> - [PyPi](https://pypi.org/project/alignn) (\ud83d\udce5 2.7K / month \u00b7 \ud83d\udce6 6 \u00b7 \u23f1\ufe0f 09.09.2024):     <pre><code>pip install alignn\n</code></pre> Uni-Mol (\ud83e\udd4818 \u00b7  \u2b50 670) - Official Repository for the Uni-Mol Series Methods. <code>MIT</code> <code>pretrained</code>  - [GitHub](https://github.com/deepmodeling/Uni-Mol) (\ud83d\udc68\u200d\ud83d\udcbb 17 \u00b7 \ud83d\udd00 120 \u00b7 \ud83d\udce5 15K \u00b7 \ud83d\udccb 160 - 40% open \u00b7 \u23f1\ufe0f 26.09.2024):      <pre><code>git clone https://github.com/deepmodeling/Uni-Mol\n</code></pre> kgcnn (\ud83e\udd4818 \u00b7  \u2b50 110) - Graph convolutions in Keras with TensorFlow, PyTorch or Jax. <code>MIT</code>  - [GitHub](https://github.com/aimat-lab/gcnn_keras) (\ud83d\udc68\u200d\ud83d\udcbb 7 \u00b7 \ud83d\udd00 29 \u00b7 \ud83d\udce6 18 \u00b7 \ud83d\udccb 86 - 13% open \u00b7 \u23f1\ufe0f 06.05.2024):      <pre><code>git clone https://github.com/aimat-lab/gcnn_keras\n</code></pre> - [PyPi](https://pypi.org/project/kgcnn) (\ud83d\udce5 570 / month \u00b7 \ud83d\udce6 3 \u00b7 \u23f1\ufe0f 27.02.2024):     <pre><code>pip install kgcnn\n</code></pre> matsciml (\ud83e\udd4817 \u00b7  \u2b50 140) - Open MatSci ML Toolkit is a framework for prototyping and scaling out deep learning models for materials discovery.. <code>MIT</code> <code>workflows</code> <code>benchmarking</code>  - [GitHub](https://github.com/IntelLabs/matsciml) (\ud83d\udc68\u200d\ud83d\udcbb 12 \u00b7 \ud83d\udd00 19 \u00b7 \ud83d\udccb 59 - 35% open \u00b7 \u23f1\ufe0f 26.09.2024):      <pre><code>git clone https://github.com/IntelLabs/matsciml\n</code></pre> Graphormer (\ud83e\udd4816 \u00b7  \u2b50 2.1K) - Graphormer is a general-purpose deep learning backbone for molecular modeling. <code>MIT</code> <code>transformer</code> <code>pretrained</code>  - [GitHub](https://github.com/microsoft/Graphormer) (\ud83d\udc68\u200d\ud83d\udcbb 14 \u00b7 \ud83d\udd00 330 \u00b7 \ud83d\udccb 160 - 58% open \u00b7 \u23f1\ufe0f 28.05.2024):      <pre><code>git clone https://github.com/microsoft/Graphormer\n</code></pre> escnn (\ud83e\udd4816 \u00b7  \u2b50 350) - Equivariant Steerable CNNs Library for Pytorch https://quva-lab.github.io/escnn/. <code>Custom</code>  - [GitHub](https://github.com/QUVA-Lab/escnn) (\ud83d\udc68\u200d\ud83d\udcbb 10 \u00b7 \ud83d\udd00 44 \u00b7 \ud83d\udccb 75 - 50% open \u00b7 \u23f1\ufe0f 18.09.2024):      <pre><code>git clone https://github.com/QUVA-Lab/escnn\n</code></pre> - [PyPi](https://pypi.org/project/escnn) (\ud83d\udce5 970 / month \u00b7 \ud83d\udce6 6 \u00b7 \u23f1\ufe0f 01.04.2022):     <pre><code>pip install escnn\n</code></pre> HydraGNN (\ud83e\udd4814 \u00b7  \u2b50 61) - Distributed PyTorch implementation of multi-headed graph convolutional neural networks. <code>BSD-3</code>  - [GitHub](https://github.com/ORNL/HydraGNN) (\ud83d\udc68\u200d\ud83d\udcbb 14 \u00b7 \ud83d\udd00 26 \u00b7 \ud83d\udce6 1 \u00b7 \ud83d\udccb 49 - 34% open \u00b7 \u23f1\ufe0f 21.09.2024):      <pre><code>git clone https://github.com/ORNL/HydraGNN\n</code></pre> Compositionally-Restricted Attention-Based Network (CrabNet) (\ud83e\udd4813 \u00b7  \u2b50 12) - Predict materials properties using only the composition information!. <code>MIT</code>  - [GitHub](https://github.com/sparks-baird/CrabNet) (\ud83d\udc68\u200d\ud83d\udcbb 6 \u00b7 \ud83d\udd00 5 \u00b7 \ud83d\udce6 13 \u00b7 \ud83d\udccb 18 - 83% open \u00b7 \u23f1\ufe0f 09.09.2024):      <pre><code>git clone https://github.com/sparks-baird/CrabNet\n</code></pre> - [PyPi](https://pypi.org/project/crabnet) (\ud83d\udce5 390 / month \u00b7 \ud83d\udce6 2 \u00b7 \u23f1\ufe0f 10.01.2023):     <pre><code>pip install crabnet\n</code></pre> hippynn (\ud83e\udd4812 \u00b7  \u2b50 67) - python library for atomistic machine learning. <code>Custom</code> <code>workflows</code>  - [GitHub](https://github.com/lanl/hippynn) (\ud83d\udc68\u200d\ud83d\udcbb 14 \u00b7 \ud83d\udd00 23 \u00b7 \ud83d\udce6 1 \u00b7 \ud83d\udccb 18 - 33% open \u00b7 \u23f1\ufe0f 20.09.2024):      <pre><code>git clone https://github.com/lanl/hippynn\n</code></pre> Atom2Vec (\ud83e\udd4810 \u00b7  \u2b50 35 \u00b7 \ud83d\udca4) - Atom2Vec: a simple way to describe atoms for machine learning. <code>MIT</code>  - [GitHub](https://github.com/idocx/Atom2Vec) (\ud83d\udc68\u200d\ud83d\udcbb 1 \u00b7 \ud83d\udd00 9 \u00b7 \ud83d\udce6 2 \u00b7 \ud83d\udccb 3 - 66% open \u00b7 \u23f1\ufe0f 23.02.2024):      <pre><code>git clone https://github.com/idocx/Atom2Vec\n</code></pre> - [PyPi](https://pypi.org/project/atom2vec) (\ud83d\udce5 93 / month \u00b7 \u23f1\ufe0f 23.02.2024):     <pre><code>pip install atom2vec\n</code></pre> FAENet (\ud83e\udd4810 \u00b7  \u2b50 33 \u00b7 \ud83d\udca4) - Frame Averaging Equivariant GNN for materials modeling. <code>MIT</code>  - [GitHub](https://github.com/vict0rsch/faenet) (\ud83d\udc68\u200d\ud83d\udcbb 3 \u00b7 \ud83d\udd00 2 \u00b7 \ud83d\udce6 2 \u00b7 \u23f1\ufe0f 12.10.2023):      <pre><code>git clone https://github.com/vict0rsch/faenet\n</code></pre> - [PyPi](https://pypi.org/project/faenet) (\ud83d\udce5 95 / month \u00b7 \u23f1\ufe0f 14.09.2023):     <pre><code>pip install faenet\n</code></pre> Equiformer (\ud83e\udd499 \u00b7  \u2b50 200) - [ICLR 2023 Spotlight] Equiformer: Equivariant Graph Attention Transformer for 3D Atomistic Graphs. <code>MIT</code> <code>transformer</code>  - [GitHub](https://github.com/atomicarchitects/equiformer) (\ud83d\udc68\u200d\ud83d\udcbb 2 \u00b7 \ud83d\udd00 38 \u00b7 \ud83d\udccb 14 - 42% open \u00b7 \u23f1\ufe0f 18.07.2024):      <pre><code>git clone https://github.com/atomicarchitects/equiformer\n</code></pre> EquiformerV2 (\ud83e\udd499 \u00b7  \u2b50 200) - [ICLR 2024] EquiformerV2: Improved Equivariant Transformer for Scaling to Higher-Degree Representations. <code>MIT</code>  - [GitHub](https://github.com/atomicarchitects/equiformer_v2) (\ud83d\udc68\u200d\ud83d\udcbb 2 \u00b7 \ud83d\udd00 26 \u00b7 \ud83d\udccb 18 - 83% open \u00b7 \u23f1\ufe0f 16.07.2024):      <pre><code>git clone https://github.com/atomicarchitects/equiformer_v2\n</code></pre> ai4material_design (\ud83e\udd499 \u00b7  \u2b50 6 \u00b7 \ud83d\udca4) - Code for Kazeev, N., Al-Maeeni, A.R., Romanov, I. et al. Sparse representation for machine learning the properties of.. <code>Apache-2</code> <code>pretrained</code> <code>material-defect</code>  - [GitHub](https://github.com/HSE-LAMBDA/ai4material_design) (\ud83d\udc68\u200d\ud83d\udcbb 11 \u00b7 \ud83d\udd00 3 \u00b7 \u23f1\ufe0f 21.11.2023):      <pre><code>git clone https://github.com/HSE-LAMBDA/ai4material_design\n</code></pre> graphite (\ud83e\udd498 \u00b7  \u2b50 58) - A repository for implementing graph network models based on atomic structures. <code>MIT</code>  - [GitHub](https://github.com/LLNL/graphite) (\ud83d\udc68\u200d\ud83d\udcbb 2 \u00b7 \ud83d\udd00 9 \u00b7 \ud83d\udce6 11 \u00b7 \ud83d\udccb 4 - 75% open \u00b7 \u23f1\ufe0f 08.08.2024):      <pre><code>git clone https://github.com/llnl/graphite\n</code></pre> DeeperGATGNN (\ud83e\udd498 \u00b7  \u2b50 46 \u00b7 \ud83d\udca4) - Scalable graph neural networks for materials property prediction. <code>MIT</code>  - [GitHub](https://github.com/usccolumbia/deeperGATGNN) (\ud83d\udc68\u200d\ud83d\udcbb 3 \u00b7 \ud83d\udd00 8 \u00b7 \ud83d\udccb 12 - 33% open \u00b7 \u23f1\ufe0f 19.01.2024):      <pre><code>git clone https://github.com/usccolumbia/deeperGATGNN\n</code></pre> Show 34 hidden projects...  - dgl-lifesci (\ud83e\udd4723 \u00b7  \u2b50 710 \u00b7 \ud83d\udc80) - Python package for graph neural networks in chemistry and biology. <code>Apache-2</code> - benchmarking-gnns (\ud83e\udd4814 \u00b7  \u2b50 2.5K \u00b7 \ud83d\udc80) - Repository for benchmarking graph neural networks. <code>MIT</code> <code>single-paper</code> <code>benchmarking</code> - Crystal Graph Convolutional Neural Networks (CGCNN) (\ud83e\udd4812 \u00b7  \u2b50 640 \u00b7 \ud83d\udc80) - Crystal graph convolutional neural networks for predicting material properties. <code>MIT</code> - Neural fingerprint (nfp) (\ud83e\udd4812 \u00b7  \u2b50 57 \u00b7 \ud83d\udc80) - Keras layers for end-to-end learning with rdkit and pymatgen. <code>Custom</code> - pretrained-gnns (\ud83e\udd4810 \u00b7  \u2b50 960 \u00b7 \ud83d\udc80) - Strategies for Pre-training Graph Neural Networks. <code>MIT</code> <code>pretrained</code> - GDC (\ud83e\udd4810 \u00b7  \u2b50 260 \u00b7 \ud83d\udc80) - Graph Diffusion Convolution, as proposed in Diffusion Improves Graph Learning (NeurIPS 2019). <code>MIT</code> <code>generative</code> - SE(3)-Transformers (\ud83e\udd499 \u00b7  \u2b50 480 \u00b7 \ud83d\udc80) - code for the SE3 Transformers paper: https://arxiv.org/abs/2006.10503. <code>MIT</code> <code>single-paper</code> <code>transformer</code> - GATGNN: Global Attention Graph Neural Network (\ud83e\udd499 \u00b7  \u2b50 69 \u00b7 \ud83d\udc80) - Pytorch Repository for our work: Graph convolutional neural networks with global attention for improved materials.. <code>MIT</code> - molecularGNN_smiles (\ud83e\udd498 \u00b7  \u2b50 290 \u00b7 \ud83d\udc80) - The code of a graph neural network (GNN) for molecules, which is based on learning representations of r-radius.. <code>Apache-2</code> - CGAT (\ud83e\udd498 \u00b7  \u2b50 25 \u00b7 \ud83d\udc80) - Crystal graph attention neural networks for materials prediction. <code>MIT</code> - UVVisML (\ud83e\udd498 \u00b7  \u2b50 22 \u00b7 \ud83d\udc80) - Predict optical properties of molecules with machine learning. <code>MIT</code> <code>optical-properties</code> <code>single-paper</code> <code>probabilistic</code> - T-e3nn (\ud83e\udd498 \u00b7  \u2b50 8 \u00b7 \ud83d\udc80) - Time-reversal Euclidean neural networks based on e3nn. <code>MIT</code> <code>magnetism</code> - tensorfieldnetworks (\ud83e\udd497 \u00b7  \u2b50 150 \u00b7 \ud83d\udc80) - Rotation- and translation-equivariant neural networks for 3D point clouds. <code>MIT</code> - DTNN (\ud83e\udd497 \u00b7  \u2b50 76 \u00b7 \ud83d\udc80) - Deep Tensor Neural Network. <code>MIT</code> - Cormorant (\ud83e\udd497 \u00b7  \u2b50 59 \u00b7 \ud83d\udc80) - Codebase for Cormorant Neural Networks. <code>Custom</code> - AdsorbML (\ud83e\udd497 \u00b7  \u2b50 35 \u00b7 \ud83d\udc80) -  <code>MIT</code> <code>surface-science</code> <code>single-paper</code> - escnn_jax (\ud83e\udd497 \u00b7  \u2b50 26 \u00b7 \ud83d\udc80) - Equivariant Steerable CNNs Library for Pytorch https://quva-lab.github.io/escnn/. <code>Custom</code> - ML4pXRDs (\ud83e\udd497 \u00b7 \ud83d\udc80) - Contains code to train neural networks based on simulated powder XRDs from synthetic crystals. <code>MIT</code> <code>XRD</code> <code>single-paper</code> - MACE-Layer (\ud83e\udd496 \u00b7  \u2b50 33 \u00b7 \ud83d\udc80) - Higher order equivariant graph neural networks for 3D point clouds. <code>MIT</code> - charge_transfer_nnp (\ud83e\udd496 \u00b7  \u2b50 29 \u00b7 \ud83d\udc80) - Graph neural network potential with charge transfer. <code>MIT</code> <code>electrostatics</code> - GLAMOUR (\ud83e\udd496 \u00b7  \u2b50 21 \u00b7 \ud83d\udc80) - Graph Learning over Macromolecule Representations. <code>MIT</code> <code>single-paper</code> - Autobahn (\ud83e\udd495 \u00b7  \u2b50 30 \u00b7 \ud83d\udc80) - Repository for Autobahn: Automorphism Based Graph Neural Networks. <code>MIT</code> - FieldSchNet (\ud83e\udd495 \u00b7  \u2b50 17 \u00b7 \ud83d\udc80) - Deep neural network for molecules in external fields. <code>MIT</code> - SCFNN (\ud83e\udd495 \u00b7  \u2b50 15 \u00b7 \ud83d\udc80) - Self-consistent determination of long-range electrostatics in neural network potentials. <code>MIT</code> <code>C++</code> <code>electrostatics</code> <code>single-paper</code> - CraTENet (\ud83e\udd495 \u00b7  \u2b50 13 \u00b7 \ud83d\udc80) - An attention-based deep neural network for thermoelectric transport properties. <code>MIT</code> <code>transport-phenomena</code> - EGraFFBench (\ud83e\udd495 \u00b7  \u2b50 8 \u00b7 \ud83d\udca4) -  <code>Unlicensed</code> <code>single-paper</code> <code>benchmarking</code> <code>ML-IAP</code> - Per-Site CGCNN (\ud83e\udd495 \u00b7  \u2b50 1 \u00b7 \ud83d\udc80) - Crystal graph convolutional neural networks for predicting material properties. <code>MIT</code> <code>pretrained</code> <code>single-paper</code> - Per-site PAiNN (\ud83e\udd495 \u00b7  \u2b50 1 \u00b7 \ud83d\udc80) - Fork of PaiNN for PerovskiteOrderingGCNNs. <code>MIT</code> <code>probabilistic</code> <code>pretrained</code> <code>single-paper</code> - Graph Transport Network (\ud83e\udd494 \u00b7  \u2b50 16 \u00b7 \ud83d\udc80) - Graph transport network (GTN), as proposed in Scalable Optimal Transport in High Dimensions for Graph Distances,.. <code>Custom</code> <code>transport-phenomena</code> - gkx: Green-Kubo Method in JAX (\ud83e\udd494 \u00b7  \u2b50 4) - Green-Kubo + JAX + MLPs = Anharmonic Thermal Conductivities Done Fast. <code>MIT</code> <code>transport-phenomena</code> - atom_by_atom (\ud83e\udd493 \u00b7  \u2b50 7 \u00b7 \ud83d\udca4) - Atom-by-atom design of metal oxide catalysts for the oxygen evolution reaction with Machine Learning. <code>Unlicensed</code> <code>surface-science</code> <code>single-paper</code> - Element encoder (\ud83e\udd493 \u00b7  \u2b50 6 \u00b7 \ud83d\udc80) - Autoencoder neural network to compress properties of atomic species into a vector representation. <code>GPL-3.0</code> <code>single-paper</code> - Point Edge Transformer (\ud83e\udd492) - Smooth, exact rotational symmetrization for deep learning on point clouds. <code>CC-BY-4.0</code> - SphericalNet (\ud83e\udd491 \u00b7  \u2b50 3 \u00b7 \ud83d\udc80) - Implementation of Clebsch-Gordan Networks (CGnet: https://arxiv.org/pdf/1806.09231.pdf) by GElib &amp; cnine libraries in.. <code>Unlicensed</code> <p></p>"},{"location":"ref/raw_md/ml_in_comp_mat/#universal-potentials","title":"Universal Potentials","text":"<p>Machine-learned interatomic potentials (ML-IAP) that have been trained on large, chemically and structural diverse datasets. For materials, this means e.g. datasets that include a majority of the periodic table.</p> <p>\ud83d\udd17\u00a0TeaNet  - Universal neural network interatomic potential inspired by iterative electronic relaxations.. <code>ML-IAP</code></p> <p>\ud83d\udd17\u00a0PreFerred Potential (PFP)  - Universal neural network potential for material discovery https://doi.org/10.1038/s41467-022-30687-9. <code>ML-IAP</code> <code>proprietary</code></p> <p>\ud83d\udd17\u00a0MatterSim  - A Deep Learning Atomistic Model Across Elements, Temperatures and Pressures https://doi.org/10.48550/arXiv.2405.04967. <code>ML-IAP</code> <code>active-learning</code> <code>proprietary</code></p> DPA-2 (\ud83e\udd4726 \u00b7  \u2b50 1.5K) - Towards a universal large atomic model for molecular and material simulation https://doi.org/10.48550/arXiv.2312.15492. <code>LGPL-3.0</code> <code>ML-IAP</code> <code>pretrained</code> <code>workflows</code> <code>datasets</code>  - [GitHub](https://github.com/deepmodeling/deepmd-kit) (\ud83d\udc68\u200d\ud83d\udcbb 69 \u00b7 \ud83d\udd00 500 \u00b7 \ud83d\udce5 40K \u00b7 \ud83d\udce6 16 \u00b7 \ud83d\udccb 780 - 12% open \u00b7 \u23f1\ufe0f 17.09.2024):      <pre><code>git clone https://github.com/deepmodeling/deepmd-kit\n</code></pre> CHGNet (\ud83e\udd4823 \u00b7  \u2b50 230) - Pretrained universal neural network potential for charge-informed atomistic modeling https://chgnet.lbl.gov. <code>Custom</code> <code>ML-IAP</code> <code>MD</code> <code>pretrained</code> <code>electrostatics</code> <code>magnetism</code> <code>structure-relaxation</code>  - [GitHub](https://github.com/CederGroupHub/chgnet) (\ud83d\udc68\u200d\ud83d\udcbb 9 \u00b7 \ud83d\udd00 62 \u00b7 \ud83d\udce6 32 \u00b7 \ud83d\udccb 59 - 5% open \u00b7 \u23f1\ufe0f 16.09.2024):      <pre><code>git clone https://github.com/CederGroupHub/chgnet\n</code></pre> - [PyPi](https://pypi.org/project/chgnet) (\ud83d\udce5 29K / month \u00b7 \ud83d\udce6 21 \u00b7 \u23f1\ufe0f 16.09.2024):     <pre><code>pip install chgnet\n</code></pre> MACE-MP (\ud83e\udd4819 \u00b7  \u2b50 460) - Pretrained foundation models for materials chemistry. <code>MIT</code> <code>ML-IAP</code> <code>pretrained</code> <code>rep-learn</code> <code>MD</code>  - [GitHub](https://github.com/ACEsuit/mace-mp) (\ud83d\udc68\u200d\ud83d\udcbb 2 \u00b7 \ud83d\udd00 170 \u00b7 \ud83d\udce5 26K \u00b7 \ud83d\udccb 9 - 22% open \u00b7 \u23f1\ufe0f 24.04.2024):      <pre><code>git clone https://github.com/ACEsuit/mace-mp\n</code></pre> - [PyPi](https://pypi.org/project/mace-torch) (\ud83d\udce5 9.3K / month \u00b7 \ud83d\udce6 14 \u00b7 \u23f1\ufe0f 16.07.2024):     <pre><code>pip install mace-torch\n</code></pre> SevenNet (\ud83e\udd4915 \u00b7  \u2b50 110) - SevenNet (Scalable EquiVariance Enabled Neural Network) is a graph neural network interatomic potential package that.. <code>GPL-3.0</code> <code>ML-IAP</code> <code>MD</code> <code>pretrained</code>  - [GitHub](https://github.com/MDIL-SNU/SevenNet) (\ud83d\udc68\u200d\ud83d\udcbb 11 \u00b7 \ud83d\udd00 13 \u00b7 \ud83d\udce6 3 \u00b7 \ud83d\udccb 21 - 52% open \u00b7 \u23f1\ufe0f 18.09.2024):      <pre><code>git clone https://github.com/MDIL-SNU/SevenNet\n</code></pre> Orb Models (\ud83e\udd4914 \u00b7  \u2b50 150 \u00b7 \ud83d\udc23) - ORB forcefield models from Orbital Materials. <code>Custom</code> <code>ML-IAP</code> <code>pretrained</code>  - [GitHub](https://github.com/orbital-materials/orb-models) (\ud83d\udc68\u200d\ud83d\udcbb 6 \u00b7 \ud83d\udd00 18 \u00b7 \ud83d\udce6 1 \u00b7 \ud83d\udccb 10 - 20% open \u00b7 \u23f1\ufe0f 26.09.2024):      <pre><code>git clone https://github.com/orbital-materials/orb-models\n</code></pre> - [PyPi](https://pypi.org/project/orb-models) (\ud83d\udce5 1.3K / month \u00b7 \u23f1\ufe0f 13.09.2024):     <pre><code>pip install orb-models\n</code></pre> Joint Multidomain Pre-Training (JMP) (\ud83e\udd495 \u00b7  \u2b50 38 \u00b7 \ud83d\udc23) - Code for From Molecules to Materials Pre-training Large Generalizable Models for Atomic Property Prediction. <code>CC-BY-NC-4.0</code> <code>pretrained</code> <code>ML-IAP</code> <code>general-tool</code>  - [GitHub](https://github.com/facebookresearch/JMP) (\ud83d\udc68\u200d\ud83d\udcbb 1 \u00b7 \ud83d\udd00 5 \u00b7 \u23f1\ufe0f 07.05.2024):      <pre><code>git clone https://github.com/facebookresearch/JMP\n</code></pre> Show 1 hidden projects...  - M3GNet (\ud83e\udd4819 \u00b7  \u2b50 230 \u00b7 \ud83d\udc80) - Materials graph network with 3-body interactions featuring a DFT surrogate crystal relaxer and a state-of-the-art.. <code>BSD-3</code> <code>ML-IAP</code> <code>pretrained</code> <p></p>"},{"location":"ref/raw_md/ml_in_comp_mat/#unsupervised-learning","title":"Unsupervised Learning","text":"<p>Projects that focus on unsupervised learning (USL) for atomistic ML, such as dimensionality reduction, clustering and visualization.</p> DADApy (\ud83e\udd4719 \u00b7  \u2b50 100) - Distance-based Analysis of DAta-manifolds in python. <code>Apache-2</code>  - [GitHub](https://github.com/sissa-data-science/DADApy) (\ud83d\udc68\u200d\ud83d\udcbb 20 \u00b7 \ud83d\udd00 18 \u00b7 \ud83d\udce6 8 \u00b7 \ud83d\udccb 36 - 25% open \u00b7 \u23f1\ufe0f 16.09.2024):      <pre><code>git clone https://github.com/sissa-data-science/DADApy\n</code></pre> - [PyPi](https://pypi.org/project/dadapy) (\ud83d\udce5 200 / month \u00b7 \u23f1\ufe0f 02.07.2024):     <pre><code>pip install dadapy\n</code></pre> ASAP (\ud83e\udd4811 \u00b7  \u2b50 140) - ASAP is a package that can quickly analyze and visualize datasets of crystal or molecular structures. <code>MIT</code>  - [GitHub](https://github.com/BingqingCheng/ASAP) (\ud83d\udc68\u200d\ud83d\udcbb 6 \u00b7 \ud83d\udd00 28 \u00b7 \ud83d\udce6 6 \u00b7 \ud83d\udccb 25 - 24% open \u00b7 \u23f1\ufe0f 27.06.2024):      <pre><code>git clone https://github.com/BingqingCheng/ASAP\n</code></pre> Show 5 hidden projects...  - Sketchmap (\ud83e\udd488 \u00b7  \u2b50 44 \u00b7 \ud83d\udc80) - Suite of programs to perform non-linear dimensionality reduction -- sketch-map in particular. <code>GPL-3.0</code> <code>C++</code> - Coarse-Graining-Auto-encoders (\ud83e\udd495 \u00b7  \u2b50 21 \u00b7 \ud83d\udc80) - Implementation of coarse-graining Autoencoders. <code>Unlicensed</code> <code>single-paper</code> - paper-ml-robustness-material-property (\ud83e\udd495 \u00b7  \u2b50 4 \u00b7 \ud83d\udc80) - A critical examination of robustness and generalizability of machine learning prediction of materials properties. <code>BSD-3</code> <code>datasets</code> <code>single-paper</code> - KmdPlus (\ud83e\udd494 \u00b7  \u2b50 3) - This module contains a class for treating kernel mean descriptor (KMD), and a function for generating descriptors with.. <code>MIT</code> - Descriptor Embedding and Clustering for Atomisitic-environment Framework (DECAF) ( \u2b50 2) - Provides a workflow to obtain clustering of local environments in dataset of structures. <code>Unlicensed</code> <p></p>"},{"location":"ref/raw_md/ml_in_comp_mat/#visualization","title":"Visualization","text":"<p>Projects that focus on visualization (viz.) for atomistic ML.</p> Crystal Toolkit (\ud83e\udd4723 \u00b7  \u2b50 150) - Crystal Toolkit is a framework for building web apps for materials science and is currently powering the new Materials.. <code>MIT</code>  - [GitHub](https://github.com/materialsproject/crystaltoolkit) (\ud83d\udc68\u200d\ud83d\udcbb 28 \u00b7 \ud83d\udd00 57 \u00b7 \ud83d\udce6 38 \u00b7 \ud83d\udccb 110 - 47% open \u00b7 \u23f1\ufe0f 20.09.2024):      <pre><code>git clone https://github.com/materialsproject/crystaltoolkit\n</code></pre> - [PyPi](https://pypi.org/project/crystal-toolkit) (\ud83d\udce5 1.6K / month \u00b7 \ud83d\udce6 8 \u00b7 \u23f1\ufe0f 04.09.2024):     <pre><code>pip install crystal-toolkit\n</code></pre> pymatviz (\ud83e\udd4821 \u00b7  \u2b50 160 \u00b7 \ud83d\udcc9) - A toolkit for visualizations in materials informatics. <code>MIT</code> <code>general-tool</code> <code>probabilistic</code>  - [GitHub](https://github.com/janosh/pymatviz) (\ud83d\udc68\u200d\ud83d\udcbb 7 \u00b7 \ud83d\udd00 13 \u00b7 \ud83d\udce6 8 \u00b7 \ud83d\udccb 45 - 24% open \u00b7 \u23f1\ufe0f 24.09.2024):      <pre><code>git clone https://github.com/janosh/pymatviz\n</code></pre> - [PyPi](https://pypi.org/project/pymatviz) (\ud83d\udce5 3.7K / month \u00b7 \ud83d\udce6 2 \u00b7 \u23f1\ufe0f 01.09.2024):     <pre><code>pip install pymatviz\n</code></pre> Chemiscope (\ud83e\udd4819 \u00b7  \u2b50 130) - An interactive structure/property explorer for materials and molecules. <code>BSD-3</code> <code>JavaScript</code>  - [GitHub](https://github.com/lab-cosmo/chemiscope) (\ud83d\udc68\u200d\ud83d\udcbb 22 \u00b7 \ud83d\udd00 32 \u00b7 \ud83d\udce5 310 \u00b7 \ud83d\udce6 6 \u00b7 \ud83d\udccb 120 - 29% open \u00b7 \u23f1\ufe0f 26.09.2024):      <pre><code>git clone https://github.com/lab-cosmo/chemiscope\n</code></pre> - [npm](https://www.npmjs.com/package/chemiscope) (\ud83d\udce5 23 / month \u00b7 \ud83d\udce6 3 \u00b7 \u23f1\ufe0f 15.03.2023):     <pre><code>npm install chemiscope\n</code></pre> ZnDraw (\ud83e\udd4819 \u00b7  \u2b50 30) - A powerful tool for visualizing, modifying, and analysing atomistic systems. <code>EPL-2.0</code> <code>MD</code> <code>generative</code> <code>JavaScript</code>  - [GitHub](https://github.com/zincware/ZnDraw) (\ud83d\udc68\u200d\ud83d\udcbb 7 \u00b7 \ud83d\udd00 3 \u00b7 \ud83d\udce6 4 \u00b7 \ud83d\udccb 320 - 31% open \u00b7 \u23f1\ufe0f 17.09.2024):      <pre><code>git clone https://github.com/zincware/ZnDraw\n</code></pre> - [PyPi](https://pypi.org/project/zndraw) (\ud83d\udce5 880 / month \u00b7 \ud83d\udce6 2 \u00b7 \u23f1\ufe0f 26.08.2024):     <pre><code>pip install zndraw\n</code></pre> Elementari (\ud83e\udd4912 \u00b7  \u2b50 130) - Interactive browser visualizations for materials science: periodic tables, 3d crystal structures, Bohr atoms, nuclei,.. <code>MIT</code> <code>JavaScript</code>  - [GitHub](https://github.com/janosh/elementari) (\ud83d\udc68\u200d\ud83d\udcbb 2 \u00b7 \ud83d\udd00 12 \u00b7 \ud83d\udce6 3 \u00b7 \ud83d\udccb 7 - 28% open \u00b7 \u23f1\ufe0f 19.07.2024):      <pre><code>git clone https://github.com/janosh/elementari\n</code></pre> - [npm](https://www.npmjs.com/package/elementari) (\ud83d\udce5 140 / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 15.01.2024):     <pre><code>npm install elementari\n</code></pre> Show 1 hidden projects...  - Atomvision (\ud83e\udd4912 \u00b7  \u2b50 29 \u00b7 \ud83d\udc80) - Deep learning framework for atomistic image data. <code>Custom</code> <code>computer-vision</code> <code>experimental-data</code> <code>rep-learn</code> <p></p>"},{"location":"ref/raw_md/ml_in_comp_mat/#wavefunction-methods-ml-wft","title":"Wavefunction methods (ML-WFT)","text":"<p>Projects and models that focus on quantities of wavefunction theory methods, such as Monte Carlo techniques like deep learning variational Monte Carlo (DL-VMC), quantum chemistry methods, etc.</p> DeepQMC (\ud83e\udd4720 \u00b7  \u2b50 340 \u00b7 \ud83d\udcc8) - Deep learning quantum Monte Carlo for electrons in real space. <code>MIT</code>  - [GitHub](https://github.com/deepqmc/deepqmc) (\ud83d\udc68\u200d\ud83d\udcbb 13 \u00b7 \ud83d\udd00 58 \u00b7 \ud83d\udce6 2 \u00b7 \ud83d\udccb 46 - 8% open \u00b7 \u23f1\ufe0f 24.09.2024):      <pre><code>git clone https://github.com/deepqmc/deepqmc\n</code></pre> - [PyPi](https://pypi.org/project/deepqmc) (\ud83d\udce5 210 / month \u00b7 \u23f1\ufe0f 24.09.2024):     <pre><code>pip install deepqmc\n</code></pre> FermiNet (\ud83e\udd4815 \u00b7  \u2b50 720) - An implementation of the Fermionic Neural Network for ab-initio electronic structure calculations. <code>Apache-2</code> <code>transformer</code>  - [GitHub](https://github.com/google-deepmind/ferminet) (\ud83d\udc68\u200d\ud83d\udcbb 18 \u00b7 \ud83d\udd00 120 \u00b7 \ud83d\udccb 50 - 2% open \u00b7 \u23f1\ufe0f 24.09.2024):      <pre><code>git clone https://github.com/google-deepmind/ferminet\n</code></pre> DeepErwin (\ud83e\udd498 \u00b7  \u2b50 47) - DeepErwin is a python 3.8+ package that implements and optimizes JAX 2.x wave function models for numerical solutions.. <code>Custom</code>  - [GitHub](https://github.com/mdsunivie/deeperwin) (\ud83d\udc68\u200d\ud83d\udcbb 7 \u00b7 \ud83d\udd00 6 \u00b7 \ud83d\udce5 10 \u00b7 \u23f1\ufe0f 07.06.2024):      <pre><code>git clone https://github.com/mdsunivie/deeperwin\n</code></pre> - [PyPi](https://pypi.org/project/deeperwin) (\ud83d\udce5 73 / month \u00b7 \u23f1\ufe0f 14.12.2021):     <pre><code>pip install deeperwin\n</code></pre> Show 2 hidden projects...  - ACEpsi.jl (\ud83e\udd496 \u00b7  \u2b50 2 \u00b7 \ud83d\udca4) - ACE wave function parameterizations. <code>MIT</code> <code>rep-eng</code> <code>Julia</code> - SchNOrb (\ud83e\udd495 \u00b7  \u2b50 59 \u00b7 \ud83d\udc80) - Unifying machine learning and quantum chemistry with a deep neural network for molecular wavefunctions. <code>MIT</code> <p></p>"},{"location":"ref/raw_md/ml_in_comp_mat/#others","title":"Others","text":"Show 1 hidden projects..."},{"location":"ref/raw_md/ml_in_comp_mat/#contribution","title":"Contribution","text":"<p>Contributions are encouraged and always welcome! If you like to add or update projects, choose one of the following ways:</p> <ul> <li>Open an issue by selecting one of the provided categories from the issue page and fill in the requested information.</li> <li>Modify the projects.yaml with your additions or changes, and submit a pull request. This can also be done directly via the Github UI.</li> </ul> <p>If you like to contribute to or share suggestions regarding the project metadata collection or markdown generation, please refer to the best-of-generator repository. If you like to create your own best-of list, we recommend to follow this guide.</p> <p>For more information on how to add or update projects, please read the contribution guidelines. By participating in this project, you agree to abide by its Code of Conduct.</p>"},{"location":"ref/raw_md/ml_in_comp_mat/#license","title":"License","text":""},{"location":"ref/reading/2_Mech_Terminologies/","title":"Terminologies in Mechanics","text":""},{"location":"ref/reading/2_Mech_Terminologies/#toughness-vs-resilience","title":"Toughness vs Resilience","text":"<ul> <li>Toughness is the ability of a material to absorb energy and plastically deform without fracturing. Other definition, is the amount of energy per unit volume that a material can absorb before rupturing. It is the energy of mechanical deformation per unit volume prior to fracture.</li> </ul> \\[ Toughness = \\frac{energy} {volume} = \\int_0^{\\epsilon_{rupture}} \\sigma d\\epsilon \\] <ul> <li>To be tough, a material must be both strong (high UTS) and ductile. Eg., brittle materials (like ceramics) that are strong but with limited ductility are not tough; conversely, very ductile materials with low strengths are also not tough.</li> <li>If the upper limit of integration up to the yield point is restricted, the energy absorbed per unit volume is known as the modulus of resilience.</li> <li>NOTE, this toughness is DIFFERENCE with fracture toughness, which describes load bearing capabilities of materials with flaws.</li> </ul>"},{"location":"ref/reading/2_Mech_Terminologies/#strength-vs-stifness","title":"Strength vs stifness","text":""},{"location":"ref/reading/6_Tracking/","title":"Visitor","text":"<p>Live MapsLive MapsSEO audit tools</p> <p>Flag CounterFlag CounterSEO audit tools</p> <p>Website CounterWebsite Counter</p>"},{"location":"ref/reading/basic_science/","title":"Basic Science","text":""},{"location":"ref/reading/basic_science/#basic-sciences","title":"Basic Sciences","text":""},{"location":"ref/reading/basic_science/#mechanics","title":"Mechanics","text":""},{"location":"ref/reading/basic_science/#basic-mechanics","title":"Basic Mechanics","text":"Engineering Mechanics 1: Statics D. Gross pdf Engineering Mechanics 2: Mechanics of Materials D. Gross pdf Statics and Mechanics of Materials F.P. Beer pdf Mechanics of Materials F.P. Beer pdf Mechanics of Materials R.C. Hibbeler pdf Engineering Themordynamics Rajput pdf Fundamentals of Engineering Themordynamics J. Moran pdf Refrigeration and Air Conditioning pdf Fundamentals of Heat and Mass Transfer pdf Learn Multibody Dynamics html"},{"location":"ref/reading/basic_science/#advanced-mechanics","title":"Advanced Mechanics","text":"<ul> <li>Advanced Engineering Dynamics - Harrison - pdf </li> <li>Fundamentals of Protein Structure and Function - pdf </li> <li>Equilibrium Thermodynamics - pdf </li> <li>Quantum Mechanics: Concepts and applications - pdf </li> <li>Quantum Theory and Statistical Thermodynamics - pdf </li> </ul>"},{"location":"ref/reading/basic_science/#physics","title":"Physics","text":"<ul> <li>Chemistry - html </li> <li>Physic 1 - html </li> <li>Physic 2 - html </li> <li>Physic 3 - html </li> <li>Theoretical Physics - html </li> <li>Statistical Physics - html </li> <li>Physics Notebook - html </li> </ul>"},{"location":"ref/reading/basic_science/#mathematics","title":"Mathematics","text":"<ul> <li>Jupyter Guide to Linear Algebra Notebook</li> <li>Tensor_Vertor_Note - pdf</li> <li>Advanced Engineering Mathematics - E. Kreyszig - pdf </li> <li>Understanding Engineering Mathematics - pdf </li> <li>Vector Calculus - pdf </li> <li>A CONCISE HANDBOOK OF MATHEMATICS, PHYSICS, AND ENGINEERING SCIENCES - pdf </li> <li>MINIMUM MATHEMATICS - pdf </li> <li>Introduction to Tensor Calculus - pdf </li> <li>Statistics - G\u00fcl - Notebook </li> </ul>"},{"location":"ref/reading/computational/","title":"Computational","text":""},{"location":"ref/reading/computational/#computational","title":"Computational","text":""},{"location":"ref/reading/computational/#thangs-note","title":"Thang's Note","text":"<ul> <li>Computational Mechanics &amp; Multiscale methods    \u00a0  Notebook</li> <li>Modelling with DFT    \u00a0  Notebook</li> <li>Modelling with MD    \u00a0  Notebook</li> <li>Thang Note for ML    \u00a0  Notebook</li> <li>Learn code    \u00a0  Notebook</li> </ul>"},{"location":"ref/reading/computational/#methods","title":"Methods","text":""},{"location":"ref/reading/computational/#multiscale","title":"Multiscale","text":"<ul> <li>Lecture Multiscale Methods in Computational Mechanics   \u00a0    Notebook</li> </ul>"},{"location":"ref/reading/computational/#dft","title":"DFT","text":"<ul> <li> <p>Modeling materials using density functional theory  \u00a0  html, pdf</p> </li> <li> <p>Computational Chemistry from Laptop to HPC - eChem team \u00a0  Notebook</p> </li> </ul>"},{"location":"ref/reading/computational/#md","title":"MD","text":"<ul> <li>Understanding Molecular Simulation - D. Frenkel  \u00a0   pdf</li> <li> <p>Molecular Modelling: Priciples and Applications - \u00a0   pdf</p> </li> <li> <p>Theory and Modeling of Polymer Nanocomposites - \u00a0   pdf</p> </li> <li>Introduction to Materials Informatics - \u00a0   notebook</li> </ul>"},{"location":"ref/reading/computational/#enhanced-sampling","title":"Enhanced Sampling","text":"<ul> <li>Enhanced sampling methods for molecular dynamics simulations - \u00a0   pdf</li> <li>Hands-on tutorials: Advanced sampling methods using GROMACS - \u00a0 html</li> </ul>"},{"location":"ref/reading/computational/#fem","title":"FEM","text":"<ul> <li>Introduction FEM - Lecture note \u00a0  pdf</li> <li>A first Course in Finite Elements - J. Fish \u00a0   pdf</li> <li>An Indtroduction to The Finite Element Method - J.N. Reddy \u00a0  pdf</li> <li>Computational Mechanics - \u00a0 Notebook, Github</li> </ul>"},{"location":"ref/reading/computational/#machine-learning","title":"Machine Learning","text":""},{"location":"ref/reading/computational/#ml-in-computational","title":"ML in Computational","text":"<ul> <li>Machine learning in Computational fluid mechanics \u00a0 Notebook,  Github</li> <li>Deep Learning in Computational Mechanics \u00a0 pdf</li> <li>Deep Learning for Particle Physicists \u00a0 Notebook</li> <li>Deep Learning for Molecules and Materials \u00a0 Notebook</li> </ul>"},{"location":"ref/reading/computational/#ml-basic","title":"ML Basic","text":"<ul> <li>PyTorch for Deep Learning - D.Bourke  \u00a0 Notebook</li> <li>Tensorflow for Deep Learning - D.Bourke  \u00a0 Notebook</li> <li>Zero to Mastery Machine Learning - D.Bourke  \u00a0 Repo</li> <li> <p>Learn Transformers - D.Bourke  \u00a0 Repo</p> </li> <li> <p>Natural Language Processing - HuggingFace html</p> </li> <li> <p>Physics-based Deep Learning - N. Thuerey \u00a0 pdf,  Notebook</p> </li> <li>An Introduction to Machine Learning  - \u00a0  pdf</li> <li>Introduction to Machine Learning with Python - \u00a0  pdf</li> <li>Thoughtful Machine Learning with Python - \u00a0 pdf</li> <li>Practical Python AI Projects - \u00a0 pdf</li> <li>Fundamentals of Deep Learning - \u00a0 pdf</li> <li>Deep Learning - \u00a0 pdf</li> <li>Hands-On Machine Learning with Scikit-Learn and TensorFlow|| Notebook|</li> <li>NoteBooks-Statistics-and-MachineLearning - \u00a0 Notebook|</li> <li>Introduction to machine learning with Jupyter notebooks|| Notebook|</li> </ul>"},{"location":"ref/reading/computational/#natural-language-processing-npl","title":"Natural Language Processing (NPL)","text":"<ul> <li>A Complete LangChain Guide - Nanonets \u00a0 html</li> </ul>"},{"location":"ref/reading/computational/#programming","title":"Programming","text":""},{"location":"ref/reading/computational/#python","title":"Python","text":"<ul> <li>Python Programming for Data Science - notebook</li> <li>A Primer on Scientific Programming withPython - pdf</li> <li>Python Data Science Handbook - notebook</li> <li>Scientific Computing for Chemists with Python - notebook = Numerical Analysis with Applications in Python - Notebook</li> </ul>"},{"location":"ref/reading/computational/#cpp","title":"CPP","text":"<ul> <li>CPP for python programmers  - html</li> <li>learn C++   - Link</li> <li>The problem solver's guide to coding - pdf</li> </ul>"},{"location":"ref/reading/computational/#others","title":"others","text":"<ul> <li>The Linux Command Line   - pdf</li> <li>Introduction to Algorithms - pdf</li> <li>Understanding Regular Expressions (Regex) - Link</li> <li>Data Science from Scratch -  pdf</li> <li>Software engineering and systems engineering - course |   notebook</li> </ul>"},{"location":"ref/reading/mechanic_solid/","title":"Mechanics of solid","text":""},{"location":"ref/reading/mechanic_solid/#elasticity","title":"Elasticity","text":"<ul> <li>Lecture Notes on The Mechanics of Elastic Solids (MIT) \u00a0  html</li> <li>Vol1. A Brief Review of Some Mathematical Preliminaries \u00a0  pdf</li> <li>Vol2. Continuum Mechanics \u00a0  pdf</li> <li>Vol3. An Introduction to Finite Elasticity \u00a0  pdf</li> </ul> <p>Read more</p>"},{"location":"ref/video/1_research_ethic/","title":"Researh Ethics","text":""},{"location":"ref/video/1_research_ethic/#research-ethic","title":"Research Ethic","text":"<p>More about research ethics</p> The Predator Effect - Understanding the past, present and future \u00f2 deceptive academic journals pdf An Editor\u2019s Perspective: From submission to decision pdf"},{"location":"ref/video/2_calculus_essence/","title":"The essence of calculus","text":""},{"location":"research/publication/","title":"Publication","text":""},{"location":"research/publication/#publications","title":"PUBLICATIONS","text":"<p>Articles in my ORCID profile  Articles in my Google Scholar profile </p>"},{"location":"research/publication/#journal-articles","title":"Journal Articles","text":"<p> Hide Graphical Abstract </p> <p>2022</p> <p>Hydrogenated Graphene with Tunable Poisson\u2019s Ratio Using Machine Learning: Implication for Wearable Devices and Strain Sensors </p> <p>Ho, Viet Hung*; Nguyen, Cao Thang*; Nguyen, Hoang D.*; Oh, Hyun Suk; Shin, Myoungsu; Kim, Sung Youb </p> <p>ACS Applied Nano Materials (2022), DOI: 10.1021/acsanm.2c01950 </p> <p>* equal contribution </p> Abstract <p>The Poisson\u2019s ratio of two-dimensional materials such as graphene can be tailored by surface hydrogenation. The density and distribution of hydrogenation may significantly affect the Poisson\u2019s ratio of the graphene structure. Therefore, optimization of the distribution of hydrogenation is useful to achieve the structure with a targeted Poisson\u2019s ratio. For this purpose, we developed an inverse design algorithm based on machine learning using the XGBoost method to reveal the relationship between the Poisson\u2019s ratio and distribution of hydrogenation. Based on this relationship, we can optimize the hydrogenated graphene structure to have a low Poisson\u2019s ratio. Instead of performing molecular dynamic simulations for all possible structures, we could find the optimal structures using the search algorithm and save significant computational resources. This algorithm could successfully discover structures with low Poisson\u2019s ratios around \u22120.5 after only 1600 simulations in a large design space of approximately 5.2 \u00d7 106\u00a0possible configurations. Moreover, the optimal structures were found to exhibit excellent flexibility under compression of around \u221265% without failure and can be used in many applications such as flexible strain sensors. Our results demonstrate the applicability of machine learning to the efficient development of new metamaterials with desired properties.</p> <p>2022</p> <p>Negative out-of-plane Poisson's ratio of bilayer graphane </p> <p>Ho, Viet Hung; Ho, Duc Tam; Nguyen, Cao Thang; Kim, Sung Youb </p> <p>Nanotechnology 33 (25) (2022), DOI: 10.1088/1361-6528/ac5da0 </p> Abstract <p>With its excellent mechanical and thermal properties, bilayer graphane is a promising material for realizing future nanoelectromechanical systems. In this study, we focus on the auxetic behavior of bilayer graphane under external loading along various directions through atomistic simulations. We numerically and theoretically reveal the mechanism of the auxeticity in terms of intrinsic interactions between carbon atoms by constructing bilayer graphane. Given that the origin of the auxeticity is intrinsic rather than extrinsic, the work provides a novel technique to control the dimensions of nanoscale bilayer graphane by simply changing the external conditions without the requirement of complex structural design of the material.</p> <p>2019</p> <p>Pattern transformation induced by elastic instability of metallic porous structures </p> <p>Nguyen, Cao Thang*; Ho, Duc Tam*; Choi, Seung Tae; Chun, Doo-Man; Kim, Sung Youb </p> <p>Computational Materials Science 157 (2019), DOI: 10.1016/j.commatsci.2018.10.023 </p> <p>* equal contribution </p> Abstract <p>Uniform pattern transformation can be observed in some structures with periodic arrays of pores at a critical compressive load because of buckling of the constituents of the structures. This pattern transformation can be exploited to design structures for various potential applications. Previous studies have focused on the instability of periodic porous structures of which the base materials were elastomers, and applications of these structures may be narrow because of the elastomer limitations of low melting temperature and stiffness. In addition, material failures such as plasticity and fracture were rarely discussed in previous studies. Here, we introduce metals as the base materials for some periodic metallic porous nanostructures (PMPNs). Our molecular dynamics simulation results show that PMPNs can exhibit pattern transformation at a critical strain because of buckling. In addition, we develop a simple formulation by incorporating the effect of surface on the Euler\u2013Bernoulli beam theory to predict the critical load for the buckling of nanostructures. The prediction of our model is in good agreement with the molecular dynamics simulation results. When the applied strain is sufficiently large, the nanoscale metals experience dislocation-medicated plasticity. We also show that the pore shape of the PMPNs strongly affects the characteristics of the periodic metallic structures including the effective Young\u2019s modulus, critical strain for micro-buckling, and critical strain for plasticity.</p> <p>2019</p> <p>Auxeticity in Metals and Periodic Metallic Porous Structures Induced by Elastic Instabilities </p> <p>Ho, Duc Tam*; Nguyen, Cao Thang*; Kwon, Soon-Yong; Kim, Sung Youb </p> <p>physica status solidi (b) 256 (1) (2019), DOI: 10.1002/pssb.201800122 </p> <p>* equal contribution </p> Abstract <p>Materials with a negative Poisson's ratio (auxetics) are counter intuitive because their mechanical response is unusual. On the other hand, instabilities are usually regarded as deleterious phenomena and thus their prevention is needed. Here, numerical and theoretical evidences have been provided to show that two different elastic instabilities are, rather than deleterious, useful phenomena that cause auxeticity. It has been shown that a negative Poisson's ratio can be found in some face-centered cubic (FCC) single crystals at a finite strain as they are under uniaxial stress along the [100]-direction. The auxeticity is associated with a phase transformation induced by the Born\u2013Hill's elastic instability, i.e., an elastic material instability. In addition, it has been found that periodic metallic porous structures can also show a negative Poisson's ratio at finite compressive strain. In this case, buckling of the micro-structure of the porous structures, which is an elastic and geometric instability, is respondent for the auxeticity.</p> <p>2019</p> <p>Auxeticity in Metals and Periodic Metallic Porous Structures Induced by Elastic Instabilities (Phys. Status Solidi B 1/2019) </p> <p>Ho, Duc Tam*; Nguyen, Cao Thang*; Kwon, Soon-Yong; Kim, Sung Youb </p> <p>physica status solidi (b) 256 (1) (2019), DOI: 10.1002/pssb.201970010 </p> <p>* equal contribution </p> Abstract <p>The search for new auxetic mechanisms and more auxetic materials are two important research directions in the study of auxeticity. It is well known that instabilities are usually regarded as deleterious phenomena and thus their prevention is needed. However, the work of Sung Youb Kim and his research group (article no. 1800122) shows that some elastic instabilities act as mechanisms for auxeticity in several metals and periodic metallic porous structures. The upper part of the cover figure shows that the Born\u2013Hill's elastic instability, i.e., an elastic material instability, causes a phase transformation leading to auxeticity in a facecentered cubic metal. The lower part of the figure describes another elastic instability, i.e., buckling of the microstructure of a periodic metallic porous structure, that induces a pattern transformation causing auxeticity in the structure. Details of relevant numerical results can be found in the article.</p>"},{"location":"research/publication/#manuscripts","title":"Manuscripts","text":"<p>2022</p> <p>Fast fabrication technique for high-quality van der Waals heterostructures using inert shielding gas environment </p> <p>Nguyen, Van Huy; Kim, Minwook; Nguyen, Cao Thang; Suleman, Muhammad; Nguyen, Dinh Cong </p> <p>Private arXiv  (2022)</p> <p>2022</p> <p>Origami-inspired Graphene/PMMA composite with tunable auxetic property </p> <p>Nguyen, Cao Thang; Kim, Sung Youb </p> <p>Private arXiv  (2022)</p> <p>2022</p> <p>An enhanced sampling approach for computing the temperature-dependent free energy </p> <p>Nguyen, Cao Thang; Kim, Sung Youb </p> <p>Private arXiv  (2022)</p> <p>2021</p> <p>Coalescence-enhanced melting in the incipient stage of surface melting </p> <p>Nguyen, Cao Thang; Ho, Duc Tam; Kim, Sung Youb </p> <p>Private arXiv  (2021)</p> <p>2021</p> <p>Mechanical vs. thermodynamic melting of metals from the mean-force dynamics calculation </p> <p>Nguyen, Cao Thang; Kim, Sung Youb </p> <p>Private arXiv  (2021)</p> <p>2020</p> <p>Finite-size effect on the thermodynamics melting predicted by free energy approach </p> <p>Nguyen, Cao Thang; Ho, Viet Hung; Kim, Sung Youb </p> <p>Private arXiv  (2020)</p>"},{"location":"research/publication/#codestools","title":"Codes/Tools","text":"<p>2021</p> <p>thatool: an object-oriented Python package for pre-processing and post-processing data from MD simulations. </p> <p>Nguyen, Cao Thang </p> <p>Documentation  (2021)</p> <p>\\\\ This package is available for Pip and Conda repositories.</p> <p>2020</p> <p>mediaLib: an OOP Python package for working with media files </p> <p>Nguyen, Cao Thang </p> <p>Documentation  (2020)</p> <p>\\\\ This package is available for Pip and Conda repositories.</p>"},{"location":"research/publication_nofig/","title":"Publication nofig","text":""},{"location":"research/publication_nofig/#publications","title":"PUBLICATIONS","text":"<p>Articles in my ORCID profile  Articles in my Google Scholar profile </p>"},{"location":"research/publication_nofig/#journal-articles","title":"Journal Articles","text":"<p> Show Graphical Abstract </p> <p>2022</p> <p>Hydrogenated Graphene with Tunable Poisson\u2019s Ratio Using Machine Learning: Implication for Wearable Devices and Strain Sensors </p> <p>Ho, Viet Hung*; Nguyen, Cao Thang*; Nguyen, Hoang D.*; Oh, Hyun Suk; Shin, Myoungsu; Kim, Sung Youb </p> <p>ACS Applied Nano Materials (2022), DOI: 10.1021/acsanm.2c01950 </p> <p>* equal contribution </p> Abstract <p>The Poisson\u2019s ratio of two-dimensional materials such as graphene can be tailored by surface hydrogenation. The density and distribution of hydrogenation may significantly affect the Poisson\u2019s ratio of the graphene structure. Therefore, optimization of the distribution of hydrogenation is useful to achieve the structure with a targeted Poisson\u2019s ratio. For this purpose, we developed an inverse design algorithm based on machine learning using the XGBoost method to reveal the relationship between the Poisson\u2019s ratio and distribution of hydrogenation. Based on this relationship, we can optimize the hydrogenated graphene structure to have a low Poisson\u2019s ratio. Instead of performing molecular dynamic simulations for all possible structures, we could find the optimal structures using the search algorithm and save significant computational resources. This algorithm could successfully discover structures with low Poisson\u2019s ratios around \u22120.5 after only 1600 simulations in a large design space of approximately 5.2 \u00d7 106\u00a0possible configurations. Moreover, the optimal structures were found to exhibit excellent flexibility under compression of around \u221265% without failure and can be used in many applications such as flexible strain sensors. Our results demonstrate the applicability of machine learning to the efficient development of new metamaterials with desired properties.</p> <p>2022</p> <p>Negative out-of-plane Poisson's ratio of bilayer graphane </p> <p>Ho, Viet Hung; Ho, Duc Tam; Nguyen, Cao Thang; Kim, Sung Youb </p> <p>Nanotechnology 33 (25) (2022), DOI: 10.1088/1361-6528/ac5da0 </p> Abstract <p>With its excellent mechanical and thermal properties, bilayer graphane is a promising material for realizing future nanoelectromechanical systems. In this study, we focus on the auxetic behavior of bilayer graphane under external loading along various directions through atomistic simulations. We numerically and theoretically reveal the mechanism of the auxeticity in terms of intrinsic interactions between carbon atoms by constructing bilayer graphane. Given that the origin of the auxeticity is intrinsic rather than extrinsic, the work provides a novel technique to control the dimensions of nanoscale bilayer graphane by simply changing the external conditions without the requirement of complex structural design of the material.</p> <p>2019</p> <p>Pattern transformation induced by elastic instability of metallic porous structures </p> <p>Nguyen, Cao Thang*; Ho, Duc Tam*; Choi, Seung Tae; Chun, Doo-Man; Kim, Sung Youb </p> <p>Computational Materials Science 157 (2019), DOI: 10.1016/j.commatsci.2018.10.023 </p> <p>* equal contribution </p> Abstract <p>Uniform pattern transformation can be observed in some structures with periodic arrays of pores at a critical compressive load because of buckling of the constituents of the structures. This pattern transformation can be exploited to design structures for various potential applications. Previous studies have focused on the instability of periodic porous structures of which the base materials were elastomers, and applications of these structures may be narrow because of the elastomer limitations of low melting temperature and stiffness. In addition, material failures such as plasticity and fracture were rarely discussed in previous studies. Here, we introduce metals as the base materials for some periodic metallic porous nanostructures (PMPNs). Our molecular dynamics simulation results show that PMPNs can exhibit pattern transformation at a critical strain because of buckling. In addition, we develop a simple formulation by incorporating the effect of surface on the Euler\u2013Bernoulli beam theory to predict the critical load for the buckling of nanostructures. The prediction of our model is in good agreement with the molecular dynamics simulation results. When the applied strain is sufficiently large, the nanoscale metals experience dislocation-medicated plasticity. We also show that the pore shape of the PMPNs strongly affects the characteristics of the periodic metallic structures including the effective Young\u2019s modulus, critical strain for micro-buckling, and critical strain for plasticity.</p> <p>2019</p> <p>Auxeticity in Metals and Periodic Metallic Porous Structures Induced by Elastic Instabilities </p> <p>Ho, Duc Tam*; Nguyen, Cao Thang*; Kwon, Soon-Yong; Kim, Sung Youb </p> <p>physica status solidi (b) 256 (1) (2019), DOI: 10.1002/pssb.201800122 </p> <p>* equal contribution </p> Abstract <p>Materials with a negative Poisson's ratio (auxetics) are counter intuitive because their mechanical response is unusual. On the other hand, instabilities are usually regarded as deleterious phenomena and thus their prevention is needed. Here, numerical and theoretical evidences have been provided to show that two different elastic instabilities are, rather than deleterious, useful phenomena that cause auxeticity. It has been shown that a negative Poisson's ratio can be found in some face-centered cubic (FCC) single crystals at a finite strain as they are under uniaxial stress along the [100]-direction. The auxeticity is associated with a phase transformation induced by the Born\u2013Hill's elastic instability, i.e., an elastic material instability. In addition, it has been found that periodic metallic porous structures can also show a negative Poisson's ratio at finite compressive strain. In this case, buckling of the micro-structure of the porous structures, which is an elastic and geometric instability, is respondent for the auxeticity.</p> <p>2019</p> <p>Auxeticity in Metals and Periodic Metallic Porous Structures Induced by Elastic Instabilities (Phys. Status Solidi B 1/2019) </p> <p>Ho, Duc Tam*; Nguyen, Cao Thang*; Kwon, Soon-Yong; Kim, Sung Youb </p> <p>physica status solidi (b) 256 (1) (2019), DOI: 10.1002/pssb.201970010 </p> <p>* equal contribution </p> Abstract <p>The search for new auxetic mechanisms and more auxetic materials are two important research directions in the study of auxeticity. It is well known that instabilities are usually regarded as deleterious phenomena and thus their prevention is needed. However, the work of Sung Youb Kim and his research group (article no. 1800122) shows that some elastic instabilities act as mechanisms for auxeticity in several metals and periodic metallic porous structures. The upper part of the cover figure shows that the Born\u2013Hill's elastic instability, i.e., an elastic material instability, causes a phase transformation leading to auxeticity in a facecentered cubic metal. The lower part of the figure describes another elastic instability, i.e., buckling of the microstructure of a periodic metallic porous structure, that induces a pattern transformation causing auxeticity in the structure. Details of relevant numerical results can be found in the article.</p>"},{"location":"research/publication_nofig/#manuscripts","title":"Manuscripts","text":"<p>2022</p> <p>Fast fabrication technique for high-quality van der Waals heterostructures using inert shielding gas environment </p> <p>Nguyen, Van Huy; Kim, Minwook; Nguyen, Cao Thang; Suleman, Muhammad; Nguyen, Dinh Cong </p> <p>Private arXiv  (2022)</p> <p>2022</p> <p>Origami-inspired Graphene/PMMA composite with tunable auxetic property </p> <p>Nguyen, Cao Thang; Kim, Sung Youb </p> <p>Private arXiv  (2022)</p> <p>2022</p> <p>An enhanced sampling approach for computing the temperature-dependent free energy </p> <p>Nguyen, Cao Thang; Kim, Sung Youb </p> <p>Private arXiv  (2022)</p> <p>2021</p> <p>Coalescence-enhanced melting in the incipient stage of surface melting </p> <p>Nguyen, Cao Thang; Ho, Duc Tam; Kim, Sung Youb </p> <p>Private arXiv  (2021)</p> <p>2021</p> <p>Mechanical vs. thermodynamic melting of metals from the mean-force dynamics calculation </p> <p>Nguyen, Cao Thang; Kim, Sung Youb </p> <p>Private arXiv  (2021)</p> <p>2020</p> <p>Finite-size effect on the thermodynamics melting predicted by free energy approach </p> <p>Nguyen, Cao Thang; Ho, Viet Hung; Kim, Sung Youb </p> <p>Private arXiv  (2020)</p>"},{"location":"research/publication_nofig/#codestools","title":"Codes/Tools","text":"<p>2021</p> <p>thatool: an object-oriented Python package for pre-processing and post-processing data from MD simulations. </p> <p>Nguyen, Cao Thang </p> <p>Documentation  (2021)</p> <p>\\\\ This package is available for Pip and Conda repositories.</p> <p>2020</p> <p>mediaLib: an OOP Python package for working with media files </p> <p>Nguyen, Cao Thang </p> <p>Documentation  (2020)</p> <p>\\\\ This package is available for Pip and Conda repositories.</p>"},{"location":"blog/archive/2024/","title":"2024","text":""},{"location":"blog/archive/2022/","title":"2022","text":""},{"location":"blog/category/science/","title":"Science","text":""},{"location":"blog/category/latex/","title":"Latex","text":""},{"location":"blog/category/ml/","title":"ML","text":""}]}